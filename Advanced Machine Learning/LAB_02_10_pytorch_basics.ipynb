{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuomydktArWz"
      },
      "source": [
        "## Tensor basics\n",
        "\n",
        "Source:https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html\n",
        "\n",
        "### What is a tensor?\n",
        "\n",
        "<div>\n",
        "<img src=\"https://i.redd.it/zmnq16y5hw381.png\" width=\"350\" height=\"400\"/>\n",
        "</div>\n",
        "\n",
        "Tensors are a specialized data structure that are **very similar to arrays and matrices**. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the modelâ€™s parameters.\n",
        "\n",
        "Let's go through some of the basics of tensors ðŸ˜‰\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIK8bEVhG5eU"
      },
      "source": [
        "### Tensors creation and initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moMGq2bEDeJv",
        "outputId": "7d92651f-d348-47e3-c29c-bc327a537505"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Importing libraries and setting device\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgICF1NqDySn",
        "outputId": "df4b0fb2-5002-4890-8def-60cff79cdd92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3, 4]) \n",
            " tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]]) \n",
            "\n",
            "tensor([1, 2, 3, 4]) \n",
            " tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# From standard python types\n",
        "\n",
        "one_dimensional_list = [1, 2, 3, 4]\n",
        "two_dimensional_list = [[1,2], [3,4], [5,6]]\n",
        "\n",
        "one_dimensional_tensor_from_list = torch.tensor(one_dimensional_list)\n",
        "two_dimensional_tensor_from_list = torch.tensor(two_dimensional_list)\n",
        "print(one_dimensional_tensor_from_list, \"\\n\", two_dimensional_tensor_from_list, \"\\n\")\n",
        "\n",
        "one_dimensional_tuple = (1,2,3,4)\n",
        "two_dimensional_tuple = ((1,2), (3,4), (5,6))\n",
        "\n",
        "one_dimensional_tensor_from_tuple = torch.tensor(one_dimensional_tuple)\n",
        "two_dimensional_tensor_from_tuple = torch.tensor(two_dimensional_tuple)\n",
        "print(one_dimensional_tensor_from_tuple, \"\\n\", two_dimensional_tensor_from_tuple, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-TqGdD4Gr2T",
        "outputId": "4b2b783a-6194-4bfe-8bfc-e875aaca9396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]]) \n",
            "\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# From numpy ndarrays\n",
        "\n",
        "# TIP: being explicit is better!\n",
        "np_array = np.array([[1,2], [3,4], [5,6]])\n",
        "\n",
        "two_dimensional_tensor_from_np_array_a = torch.tensor(np_array) #implicit cast\n",
        "print(two_dimensional_tensor_from_np_array_a, \"\\n\")\n",
        "\n",
        "two_dimensional_tensor_from_np_array_b = torch.from_numpy(np_array) #explicit conversion\n",
        "print(two_dimensional_tensor_from_np_array_b, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTVSbSszGx6D",
        "outputId": "81c587f5-fabc-427d-ae36-d70f65253396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]]) \n",
            "\n",
            "tensor([[1, 1],\n",
            "        [1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "tensor([[0.6544, 0.3800],\n",
            "        [0.1131, 0.2214],\n",
            "        [0.9927, 0.3718]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# From other tensors\n",
        "\n",
        "print(two_dimensional_tensor_from_np_array_a, \"\\n\")\n",
        "\n",
        "new_tensor = torch.ones_like(two_dimensional_tensor_from_np_array_a) #same with torch.zeros_like()\n",
        "print(new_tensor, \"\\n\")\n",
        "\n",
        "new_tensor = torch.rand_like(two_dimensional_tensor_from_np_array_a, dtype=torch.float)\n",
        "print(new_tensor, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fZlK3HxNacz",
        "outputId": "c28542a0-b496-4078-b971-e3419a8c6787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.1229, 0.8420, 0.2862],\n",
            "        [0.6064, 0.1870, 0.6453]]) \n",
            "\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]]) \n",
            "\n",
            "zeros(): argument 'size' (position 1) must be tuple of ints, but found element of type list at pos 0\n"
          ]
        }
      ],
      "source": [
        "# With random or constant values\n",
        "\n",
        "shape = (2,3) #shape can be a tuple\n",
        "random_tensor = torch.rand(shape)\n",
        "print(random_tensor, \"\\n\")\n",
        "\n",
        "shape = [2, 3] #shape can be a list\n",
        "ones_tensor = torch.ones(shape)\n",
        "print(ones_tensor, \"\\n\")\n",
        "\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "print(zeros_tensor, \"\\n\")\n",
        "\n",
        "shape = [[2,3],[2,3]] #shape cannot be a multi-dimensional list!\n",
        "try:\n",
        "  zeros_tensor = torch.zeros(shape)\n",
        "except TypeError as te:\n",
        "  print(te)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln6cF4ZaLZVG",
        "outputId": "fedf9c04-80b5-4350-91be-147d57850a77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2) tensor([3.1382e+12, 3.2894e-41])\n",
            "tensor([]) \n",
            "\n",
            "tensor() missing 1 required positional arguments: \"data\"\n",
            "tensor([1, 2]) tensor([1., 2.])\n"
          ]
        }
      ],
      "source": [
        "# Be careful!\n",
        "# torch.tensor != torch.Tensor\n",
        "# see: https://discuss.pytorch.org/t/difference-between-torch-tensor-and-torch-tensor/106816/4\n",
        "\n",
        "a = torch.tensor(2) #create tensor from input\n",
        "b = torch.Tensor(2) #create un-initialised tensor of two elements\n",
        "print(a, b)\n",
        "\n",
        "a = torch.Tensor() #ok!\n",
        "print(a, \"\\n\")\n",
        "\n",
        "try:\n",
        "  b = torch.tensor() #error!\n",
        "except TypeError as te:\n",
        "  print(te)\n",
        "\n",
        "a = torch.tensor([1,2])\n",
        "b = torch.Tensor([1,2]) #internally casts as float!\n",
        "print(a, b)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhawNCAfG9rb"
      },
      "source": [
        "### Tensor attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHKnq1bmRS_U",
        "outputId": "cfb81547-3861-4d5a-aaf4-ace7061ad032"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.9822, 0.4493, 0.7408, 0.7619],\n",
            "        [0.7334, 0.8853, 0.2400, 0.6332],\n",
            "        [0.6285, 0.8299, 0.9621, 0.4045]]) \n",
            "\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "# Basic tensor attributes\n",
        "\n",
        "tensor = torch.rand(3,4)\n",
        "print(tensor, \"\\n\")\n",
        "\n",
        "# shape\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "\n",
        "# dtype\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "\n",
        "#device\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3RDijSETFkd",
        "outputId": "a38d96d9-c621-44fd-b511-54f888dfe056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor([1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "# Importance of dtype\n",
        "\n",
        "# specifying the dtype will force a cast in the specified dtype\n",
        "# the dtype is best specified using torch.dtype, e.g. torch.float32\n",
        "# all info at: https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype\n",
        "\n",
        "a = torch.tensor([1, 2, 3], dtype=torch.float32) #casts to float\n",
        "print(a)\n",
        "\n",
        "b = torch.tensor([1, 2, 3], dtype=torch.int64) #casts to int\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGFsnanSU8W7",
        "outputId": "6a8d2d53-e3e8-4719-9b11-91214a1829d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([False,  True,  True])\n"
          ]
        }
      ],
      "source": [
        "# Sometimes casting will have unexpected results\n",
        "c = torch.tensor([0, 2, 3], dtype=torch.bool) #conversion to bool is always true unless the input is 0!\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55jbOO-3U_sd",
        "outputId": "73ccb863-efb5-45cc-9ec8-8066439302ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.2561, 3.0000, 4.0000], dtype=torch.float64)\n",
            "tensor([1.2561, 3.0000, 4.0000])\n",
            "tensor([False,  True,  True])\n"
          ]
        }
      ],
      "source": [
        "# Different dtypes will have different precisions\n",
        "\n",
        "# TIP: precision can matter! be careful...\n",
        "d = torch.tensor([1.2561312312312313, 3.0, 4], dtype=torch.double) #casts to double/float64\n",
        "print(d)\n",
        "\n",
        "e = torch.tensor([1.2561312312312313, 3.0, 4], dtype=torch.float32) #casts to float\n",
        "print(e)\n",
        "\n",
        "print(d == e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Micb1oYRG_6Y"
      },
      "source": [
        "### Tensor operations\n",
        "\n",
        "For a complete list of operations, see https://pytorch.org/docs/stable/torch.html\n",
        "\n",
        "This operations include (but are not limited to):\n",
        "- stacking and concatenating tensors (e.g. concatenate, stack, vstack, hstack...)\n",
        "- replicating tensor dimensions (e.g. repeat)\n",
        "- matrix multiplications (bmm, mm, etc)\n",
        "\n",
        "And so on...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LZv6IxfWo05",
        "outputId": "6fd3d36f-e557-4101-9e13-f5dd09e417ab"
      },
      "outputs": [],
      "source": [
        "# Moving tensor to gpu (when available)\n",
        "\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "multi_dimensional_tensor = torch.tensor([[1,2],[3,4]])\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to(device)\n",
        "  multi_dimensional_tensor = multi_dimensional_tensor.to(device)\n",
        "  print(f\"Tensors stored on: {tensor.device} and {multi_dimensional_tensor.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVrdwpA8W5QD",
        "outputId": "443c1832-0d58-4a2f-cb86-2094f932401d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3]) \n",
            "\n",
            "tensor(2) \n",
            "\n",
            "tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            "\n",
            "tensor(4) \n",
            "\n",
            "tensor([2, 4]) \n",
            "\n",
            "tensor([3, 4]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Indexing and slicing\n",
        "\n",
        "print(tensor, \"\\n\")\n",
        "\n",
        "n = tensor[1]\n",
        "print(n, \"\\n\")\n",
        "\n",
        "print(multi_dimensional_tensor, \"\\n\")\n",
        "\n",
        "n = multi_dimensional_tensor[1,1]\n",
        "print(n, \"\\n\")\n",
        "\n",
        "n = multi_dimensional_tensor[:,1]\n",
        "print(n, \"\\n\")\n",
        "\n",
        "n = multi_dimensional_tensor[1,:]\n",
        "print(n, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPZIwYMehwsu",
        "outputId": "b2900fa3-f172-48e6-b614-db0aed4020ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            "\n",
            "tensor([3, 4])\n",
            "tensor([0.1877, 0.2131, 0.1009, 0.1666]) \n",
            "\n",
            "torch.Size([4, 3]) \n",
            " tensor([[0.4705, 0.7633, 0.9667],\n",
            "        [0.6733, 0.1942, 0.4804],\n",
            "        [0.4002, 0.3804, 0.1156],\n",
            "        [0.4143, 0.6471, 0.9513]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# More advanced slicing\n",
        "\n",
        "print(multi_dimensional_tensor, \"\\n\")\n",
        "\n",
        "# slicing with ellipsis\n",
        "n = multi_dimensional_tensor[1, ...]\n",
        "print(n)\n",
        "\n",
        "# will this work?\n",
        "# try to guess...and then uncomment\n",
        "# n = multi_dimensional_tensor[..., 1, :, ...]\n",
        "\n",
        "# ranged slicing\n",
        "big_tensor = torch.rand(100)\n",
        "indexes = range(0, big_tensor.shape[0], 25)\n",
        "n = big_tensor[indexes]\n",
        "print(n, \"\\n\")\n",
        "\n",
        "# multidimensional ranged_slicing\n",
        "big_tensor = torch.rand(100, 90)\n",
        "indexes_a = range(0, big_tensor.shape[0], 25)\n",
        "indexes_b = range(0, big_tensor.shape[1], 30)\n",
        "n = big_tensor[indexes_a][:, indexes_b]\n",
        "print(n.shape, \"\\n\", n, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgp47SC5iVT-",
        "outputId": "c8887829-a596-4304-8554-5b11dd150ae1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) \n",
            "\n",
            "tensor([5., 5., 5., 5., 5., 5., 5., 5., 5., 5.])\n"
          ]
        }
      ],
      "source": [
        "# In place operations\n",
        "\n",
        "# In place operations are marked with an underscore at the end\n",
        "# They require less memory but will cause issues with backpropagation\n",
        "# so their use is generally not recommended if you need gradients.\n",
        "\n",
        "tensor = torch.zeros(10)\n",
        "print(tensor, \"\\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmZP1mZid6P_"
      },
      "source": [
        "### Numpy bridging\n",
        "\n",
        "Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yBAbXE_genlk",
        "outputId": "2e3fead8-9e6c-4bab-e37d-3dd008671ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.] \n",
            "\n",
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.] \n",
            "\n",
            "With cloning: \n",
            " t: tensor([1., 1., 1., 1., 1.])\n",
            "n: tensor([1., 1., 1., 1., 1.]) \n",
            "\n",
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: tensor([1., 1., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n} \\n\")\n",
        "\n",
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n} \\n\")\n",
        "\n",
        "# the opposite is also true, i.e. when creating a tensor with torch.from_numpy\n",
        "# to avoid sharing memory between two variables, create a copy!\n",
        "# this is necessary if for instance you need to log something that\n",
        "# also is part of a gradient computation\n",
        "\n",
        "t = torch.ones(5)\n",
        "print(f\"With cloning: \\n t: {t}\")\n",
        "n = torch.from_numpy(t.clone().numpy()) #NOTE: fix add .cpu() if the tensors are on the GPU!\n",
        "print(f\"n: {n} \\n\")\n",
        "\n",
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xptkTurCgX3y"
      },
      "source": [
        "## A gentle introduction to automatic gradients\n",
        "\n",
        "Source: https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
        "\n",
        "### What is autograd?\n",
        "\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1-uEz6hkaeOl70KqDhnmpJmJKrXEfcsQf\" width=\"500\" height=\"450\">\n",
        "</div>\n",
        "\n",
        "Backpropagation is the process that we use to optimize neural networks.\n",
        "Doing it manually is very complex and would be unfeasible for very large networks.\n",
        "\n",
        "Luckily, torch's **autograd** implementation will handle most of the complexity for us!\n",
        "\n",
        "But what are we backpropagating through?\n",
        "\n",
        "<details>\n",
        "The computational graph!\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtcHF8lAlg73"
      },
      "source": [
        "### How does autograd work\n",
        "\n",
        "Conceptually, autograd keeps a record of data (tensors) & all executed operations (along with the resulting new tensors) in a directed acyclic graph (DAG) consisting of Function objects. This is called a **computation graph**.\n",
        "\n",
        "In this DAG, leaves are the input tensors, roots are the output tensors. By tracing this graph from roots to leaves, you can automatically compute the gradients using the chain rule.\n",
        "\n",
        "In a forward pass, autograd does two things simultaneously:\n",
        "\n",
        "  - run the requested operation to compute a resulting tensor, and\n",
        "\n",
        "  - maintain the operationâ€™s gradient function in the DAG.\n",
        "\n",
        "The backward pass kicks off when .backward() is called on the DAG root. autograd then:\n",
        "\n",
        "  - computes the gradients from each .grad_fn (functions participating in the gradients computation),\n",
        "\n",
        "  - accumulates them in the respective tensorâ€™s .grad attribute, and\n",
        "\n",
        "  - using the chain rule, propagates all the way to the leaf tensors.\n",
        "\n",
        "\n",
        "Let's see this in practice with a visual explanation, computing the DAG of the following expression: $Q = 3a^3 - b^2$. Assume that $a, b$ are two tensors, and that we want to compute their gradient w.r.t to $Q$.\n",
        "\n",
        "**NOTE**: In this example $Q$ is a vector resulting from the above expression. Most of the time, you'll deal with expressions that have a single scalar as output, such as a loss function.\n",
        "\n",
        "Below is a visual representation of the DAG of this expression. In the graph, the arrows are in the direction of the forward pass. The nodes represent the backward functions of each operation in the forward pass. The leaf nodes in blue represent our leaf tensors a and b.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://pytorch.org/tutorials/_images/dag_autograd.png\" width=\"400\" height=\"400\"/>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4PIX9nrtghPO"
      },
      "outputs": [],
      "source": [
        "device = \"cpu\" #this tutorial only works on cpu!\n",
        "\n",
        "# let's the elements of our expression\n",
        "\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)\n",
        "\n",
        "# and compute it\n",
        "\n",
        "Q = 3*a**3 - b**2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbpk9pS4qyra"
      },
      "source": [
        "### Computing gradient manually\n",
        "\n",
        "Let's manually compute the gradient for this expression and see if it matches with autograd's computation:\n",
        "- for $a$ the $\\frac{\\partial Q }{\\partial a}$ is $9a^2$\n",
        "- for $b$ the $\\frac{\\partial Q }{\\partial b}$ is $-2b$.\n",
        "\n",
        "In this case, the gradient should be\n",
        "- $9 \\cdot [2,3]^2 = 9 \\cdot [4, 9] = [36, 81]$\n",
        "- $-2 \\cdot [6,4] = [-12, -8]$\n",
        "\n",
        "Let's verify it with code!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya4TtALPr1MW",
        "outputId": "594bb05c-423e-4334-b3fe-4a0c5547b2b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grad can be implicitly created only for scalar outputs\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  grad = Q.backward()\n",
        "except RuntimeError as rt:\n",
        "  print(rt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft7uMlFsxnWH"
      },
      "source": [
        "Oops! Unless $Q$ is a scalar, we need to explicitly pass a gradient argument in `Q.backward()` because it is a vector. `gradient` is a tensor of the same shape as $Q$, and it represents the gradient of $Q$ w.r.t. itself, i.e. $\\frac{\\partial Q}{\\partial Q} = 1$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32aUiEhdxGeh",
        "outputId": "b4e15d71-7bd5-4461-91a7-b5e387ae51ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient of Q w.r.t Q is tensor([1., 1.])\n"
          ]
        }
      ],
      "source": [
        "external_grad = torch.tensor([1. , 1.])\n",
        "Q.backward(gradient=external_grad)\n",
        "print(f\"Gradient of Q w.r.t Q is {external_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsRUuVcDyi4U"
      },
      "source": [
        "We can now manually verify that the gradients of $a$ and $b$ match!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1jltW_gymEI",
        "outputId": "6fd680e7-f4af-4b63-9dc2-fcb8252d5707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([36., 81.])\n",
            "tensor([True, True]) \n",
            "\n",
            "tensor([-12.,  -8.])\n",
            "tensor([True, True])\n"
          ]
        }
      ],
      "source": [
        "print(a.grad)\n",
        "print(a.grad == 9*a**2, \"\\n\")\n",
        "print(b.grad)\n",
        "print(b.grad == -2*b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrSJLqd4zN7B"
      },
      "source": [
        "Mh...what if we called `backward()` on Q  a second time? What would happen?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3yvB7iJzNfS",
        "outputId": "595e92bc-ab35-4d26-8fb6-e2ad405692b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  Q.backward(gradient=external_grad)\n",
        "except RuntimeError as rt:\n",
        "  print(rt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejM3sRgIy2NJ"
      },
      "source": [
        "### Dynamic DAG\n",
        "\n",
        "In pytorch the graph is recreated **from scratch**; after each .backward() call, autograd starts populating a new graph. This is exactly what allows you to use control flow statements in your model; you can change the shape, size and operations at every iteration if needed.\n",
        "\n",
        "In addition to that, saved intermediate values of the graph are freed when you call `.backward()` or `autograd.grad()`. Specify `retain_graph=True` if you need to backward through the graph a second time or if you need to access saved tensors after calling `backward()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVKFH0zk0z8j"
      },
      "source": [
        "### Excluding elements from the DAG\n",
        "\n",
        "`torch.autograd` tracks operations on all tensors which have their `requires_grad` flag set to `True`. For tensors that donâ€™t require gradients, setting this attribute to `False` excludes it from the gradient computation DAG.\n",
        "\n",
        "The output tensor of an operation will require gradients even if only a single input tensor has `requires_grad=True`\n",
        "\n",
        "You also have the option of using `with torch.no_grad()`, as everything under its scope will automatically disable gradient computation (even if `requires_grad=True` for some variables).\n",
        "\n",
        "But why would we want avoid tracking gradients?\n",
        "\n",
        "<details>\n",
        "  <ul>\n",
        "    <li>\"freeze\" part of a model, for example for finetuing just a classification layer;</li>\n",
        "    <li>reduce autograd's computations (although this is a lot more uncommon)</li>\n",
        "  </ul>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7ksexUF1IG9",
        "outputId": "e67e6fdb-c855-4c5c-b016-060d3a041f96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Does `a` require gradients?: False\n",
            "Does `b` require gradients?: True\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(5, 5)\n",
        "y = torch.rand(5, 5)\n",
        "z = torch.rand((5, 5), requires_grad=True)\n",
        "\n",
        "a = x + y\n",
        "print(f\"Does `a` require gradients?: {a.requires_grad}\")\n",
        "b = x + z\n",
        "print(f\"Does `b` require gradients?: {b.requires_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO5tKkwn2PdL"
      },
      "source": [
        "## Your first neural network\n",
        "\n",
        "<div>\n",
        "<img src=\"https://i.kym-cdn.com/entries/icons/original/000/039/408/cover10.jpg\" width=\"800\" height=\"400\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "### Creating a NN from scratch\n",
        "\n",
        "In this part of the notebook, we'll create a small neural network, similar to the one in this image:\n",
        "\n",
        "<div>\n",
        "<img src=\"https://pytorch.org/tutorials/_images/mnist.png\" width=\"800\" height=\"200\"/>\n",
        "</div>\n",
        "\n",
        "It is a simple feed-forward network. It takes the input, feeds it through several layers one after the other, and then finally gives the output.\n",
        "To create it, we'll leverage the `torch.nn`package."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dj8Rzk87BNF"
      },
      "source": [
        "### Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh5ZJAs-5Odu",
        "outputId": "41fe592d-2593-4aa2-a074-f23ce68a7cfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=1600, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Define network\n",
        "\n",
        "# let's create our toy network\n",
        "# as with every base torch model\n",
        "# it will be an extension of the torch.nn.Module class\n",
        "# see doc here: https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
        "\n",
        "# we'll have to define an __init__ function and the forward function as well\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 3 input image channel, 32 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 120)  # 5*5 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Convolution layer C1: 3 input image channel, 32 output channels,\n",
        "        # 5x5 square convolution, it uses RELU activation function, and\n",
        "        # outputs a Tensor with size (N, 32, 28, 28), where N is the size of the batch\n",
        "        c1 = F.relu(self.conv1(input))\n",
        "        # Subsampling layer S2: 2x2 grid, purely functional,\n",
        "        # this layer does not have any parameter, and outputs a (N, 32, 14, 14) Tensor\n",
        "        s2 = F.max_pool2d(c1, (2, 2))\n",
        "        # Convolution layer C3: 32 input channels, 64 output channels,\n",
        "        # 5x5 square convolution, it uses RELU activation function, and\n",
        "        # outputs a (N, 64, 10, 10) Tensor\n",
        "        c3 = F.relu(self.conv2(s2))\n",
        "        # Subsampling layer S4: 2x2 grid, purely functional,\n",
        "        # this layer does not have any parameter, and outputs a (N, 64, 5, 5) Tensor\n",
        "        s4 = F.max_pool2d(c3, 2)\n",
        "        # Flatten operation: purely functional, outputs a (N, 400) Tensor\n",
        "        s4 = torch.flatten(s4, 1)\n",
        "        # Fully connected layer F5: (N, 400) Tensor input,\n",
        "        # and outputs a (N, 120) Tensor, it uses RELU activation function\n",
        "        f5 = F.relu(self.fc1(s4))\n",
        "        # Fully connected layer F6: (N, 120) Tensor input,\n",
        "        # and outputs a (N, 84) Tensor, it uses RELU activation function\n",
        "        f6 = F.relu(self.fc2(f5))\n",
        "        # Gaussian layer OUTPUT: (N, 84) Tensor input, and\n",
        "        # outputs a (N, 10) Tensor\n",
        "        output = self.fc3(f6)\n",
        "        return output\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_GVvQSZ54Hn",
        "outputId": "d683a446-266a-4f69-e0c7-8632967a3d96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.weight torch.Size([32, 3, 5, 5]) \n",
            "\n",
            "conv1.bias torch.Size([32]) \n",
            "\n",
            "conv2.weight torch.Size([64, 32, 5, 5]) \n",
            "\n",
            "conv2.bias torch.Size([64]) \n",
            "\n",
            "fc1.weight torch.Size([120, 1600]) \n",
            "\n",
            "fc1.bias torch.Size([120]) \n",
            "\n",
            "fc2.weight torch.Size([84, 120]) \n",
            "\n",
            "fc2.bias torch.Size([84]) \n",
            "\n",
            "fc3.weight torch.Size([10, 84]) \n",
            "\n",
            "fc3.bias torch.Size([10]) \n",
            "\n",
            "Total number of trainable parameters: 256830 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# let's count how many trainable parameters we have\n",
        "\n",
        "count = 0\n",
        "for n, p in net.named_parameters():\n",
        "  print(n, p.shape, \"\\n\")\n",
        "  count += p.numel() if p.requires_grad else 0\n",
        "\n",
        "print(f\"Total number of trainable parameters: {count} \\n\")\n",
        "\n",
        "# to return the learnable parameters, we can use .parameters()\n",
        "# we'll see later how this comes in handy\n",
        "params = list(net.parameters())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75NO-ONf7KOC",
        "outputId": "197b152e-a874-481e-b778-e783f31c8699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0579,  0.0078, -0.0111,  0.0232, -0.0404,  0.0441,  0.0268,  0.0171,\n",
            "         -0.0346,  0.1015]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# finally, let's see our network in action!\n",
        "\n",
        "input = torch.rand(1, 3, 32, 32)\n",
        "out = net(input)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM-hyZU07Dze"
      },
      "source": [
        "### Loss function and optimizer\n",
        "\n",
        "Once we have our model, we'll have to define an appropriate **loss function** to train the network.\n",
        "\n",
        "We'll also have to define an **optimizer**, to tune the network's parameters w.r.t. our loss function, and feed the network `parameters()` to the it.\n",
        "\n",
        "We can pick both from torch's vast library:\n",
        "- loss functions at https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "- optimizers at https://pytorch.org/docs/stable/optim.html\n",
        "\n",
        "Since we are dealing with a classification problem, we'll choose:\n",
        "<details>\n",
        "  <ul>\n",
        "    <li> crossentropy as the loss function</li>\n",
        "    <li> adam as the optimizer</li>\n",
        "  </ul>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmH7glOO6ER7",
        "outputId": "0d631107-2dec-4270-8317-ae697a8715c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss function is CrossEntropyLoss() \n",
            " Optimizer is Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=net.parameters(), lr=0.001) #many optimizers out there, but remember: start easy!\n",
        "\n",
        "print(f\"Loss function is {loss_fn} \\n Optimizer is {optimizer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC-16YJUUeKF"
      },
      "source": [
        "### Gathering the data\n",
        "\n",
        "The dataset that we'll use to train our model is **CIFAR10**. It's a very popular dataset, comprising 10 classes of 3x32x32 images.\n",
        "\n",
        "While it's possible to download and create the dataset class from scratch, we can speed things up using the `torchvison` package. It includes most of the more popular datasets.\n",
        "\n",
        "In case you need to create and visualize a dataset from scratch, you can refer to this tutorial: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html.\n",
        "\n",
        "We'll now load the dataset, and then apply the transforms from `torchvision.transforms` to normalize and convert the images into tensors. Note that `torchvision` datasets will save data as `pillow` images by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wm7tEOOToSn",
        "outputId": "f7e47a01-4205-4f6e-8903-97d10f2ca953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "transforms = T.Compose([\n",
        "    T.RandomApply([\n",
        "        T.RandomGrayscale(p=0.25)\n",
        "    ]),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "]) #use Compose to concatenate multiple transforms\n",
        "\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transforms)\n",
        "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transforms)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "uf2G85rwUedb",
        "outputId": "620f4e10-e27c-4793-be87-30afcda21624"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "horse  cat    cat    car    bird   ship   plane  frog   \n"
          ]
        }
      ],
      "source": [
        "# to make loading data easier, we'll create a dataloader using\n",
        "# torch.utils.data.Dataloader\n",
        "\n",
        "batch_size = 512\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# let's visualize our data\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[:8]))\n",
        "# print labels\n",
        "print(''.join(f'{classes[labels[j]]:5s}  ' for j in range(8)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO8arDX3Rz1T"
      },
      "source": [
        "### Training loop\n",
        "\n",
        "Now that we have a model, an optimizer and some data that we can use to train it, let's define a training loop.\n",
        "\n",
        "A basic training loop is composed as follows: for each epoch, we'll iterate on each mini-batch and perform:\n",
        "- a forward pass on the data\n",
        "- the loss computation\n",
        "- backpropagation\n",
        "- **optional**: validation\n",
        "\n",
        "Before proceeding, we have to move everything to the GPU. Doing so will significantly speed up training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l40QpC-DWqSN",
        "outputId": "2e061de8-e47a-4502-b3c3-615dd8eac427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Current epoch is 0 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:31<00:00,  3.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running loss for epoch 0 is 0.8293757949556623\n",
            "Current epoch is 1 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:30<00:00,  3.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running loss for epoch 1 is 0.8316246508335581\n",
            "Current epoch is 2 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:38<00:00,  2.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running loss for epoch 2 is 0.8275134958782975\n",
            "Current epoch is 3 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:30<00:00,  3.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running loss for epoch 3 is 0.827918429155739\n",
            "Current epoch is 4 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:34<00:00,  2.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running loss for epoch 4 is 0.8274822904139149\n",
            "Current epoch is 5 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:36<00:00,  2.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running loss for epoch 5 is 0.8279711081057178\n",
            "Current epoch is 6 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:37<00:00,  2.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running loss for epoch 6 is 0.8291060079117211\n",
            "Current epoch is 7 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:36<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running loss for epoch 7 is 0.8286910391583735\n",
            "Current epoch is 8 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:36<00:00,  2.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running loss for epoch 8 is 0.830183387410884\n",
            "Current epoch is 9 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:33<00:00,  2.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running loss for epoch 9 is 0.829774050688257\n",
            "Finished Training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# move model to GPU\n",
        "net.to(device)\n",
        "net.train() #switch to train mode\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "  print(f\"Current epoch is {epoch} \\n\")\n",
        "  running_loss = 0.0\n",
        "  count = 0\n",
        "  for data in tqdm(trainloader, position=0, leave=True):\n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data\n",
        "\n",
        "    inputs = inputs.to(device) #move to GPU\n",
        "    labels = labels.to(device) #move to GPU\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = net(inputs)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    count+=1\n",
        "\n",
        "  print(f\"Running loss for epoch {epoch} is {running_loss / count}\")\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVPyA7MhbMiX",
        "outputId": "738b0128-4c33-41d0-fbee-da968d85f270"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=1600, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# let's save the model we just trained\n",
        "# and load it back again\n",
        "# this is just to show how to save and reload a model\n",
        "\n",
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)\n",
        "\n",
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH, weights_only=True))\n",
        "net.eval() #switch to eval mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf0sxjDbbe-d"
      },
      "source": [
        "### Testing the model\n",
        "\n",
        "We can finally test the model we just trained on the test dataset. We'll inspect performance on the whole test set and also on each class, to identify the ones where the network has struggled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7DqPeGTbnRH",
        "outputId": "65e89382-81a8-4df3-aa28-f2296ec9a0f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 66 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest probability is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2n4NbjAcDtc",
        "outputId": "034ef318-d7db-415a-d6c5-1f299b3d80f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for class: plane is 72.6 %\n",
            "Accuracy for class: car   is 84.9 %\n",
            "Accuracy for class: bird  is 46.3 %\n",
            "Accuracy for class: cat   is 42.0 %\n",
            "Accuracy for class: deer  is 59.0 %\n",
            "Accuracy for class: dog   is 67.5 %\n",
            "Accuracy for class: frog  is 78.8 %\n",
            "Accuracy for class: horse is 77.6 %\n",
            "Accuracy for class: ship  is 65.8 %\n",
            "Accuracy for class: truck is 73.5 %\n"
          ]
        }
      ],
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEv9ghIjeQQ-"
      },
      "source": [
        "## Congratulations!\n",
        "\n",
        "You just trained your very first basic network! In the next lab, we'll go through some more advanced topics, inlcuding loggin, automatic training/validation/testing, using SOTA models and the very basics of model tuning.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=12bo7doNOi1MQKy6G0u13b7lBVKVfL8w1\" width=\"500\" height=\"450\">\n",
        "</div>\n",
        "\n",
        "<small> (Yes, generative models still struggle with text) </small>\n",
        "\n",
        "<small> If you need anything else, feel free to shot me an email at:\n",
        "gioia@diag.uniroma1.it with the prefix [AML]. </small>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "KuomydktArWz",
        "xptkTurCgX3y"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
