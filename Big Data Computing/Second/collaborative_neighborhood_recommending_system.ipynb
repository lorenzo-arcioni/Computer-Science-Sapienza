{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering for Movie Recommendations\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Collaborative filtering is a popular approach in recommendation systems that leverages user-item interactions to predict user preferences. There are two main types of collaborative filtering:\n",
    "\n",
    "- **User-Based Collaborative Filtering**: Recommends items based on the preferences of users who are similar to the target user.\n",
    "- **Item-Based Collaborative Filtering**: Suggests items that are similar to those the user has already rated positively.\n",
    "\n",
    "In this notebook, we will explore both approaches for movie recommendations.\n",
    "\n",
    "## Dataset Description\n",
    "We use two datasets for this analysis:\n",
    "1. **Movies Dataset**:\n",
    "   - `Movie_ID`: Unique identifier for each movie.\n",
    "   - `Name`: Title of the movie.\n",
    "   - `Year`: Release year of the movie.\n",
    "\n",
    "2. **Ratings Dataset**:\n",
    "   - `User_ID`: Unique identifier for each user.\n",
    "   - `Movie_ID`: Identifier for the movie rated.\n",
    "   - `Rating`: Numeric rating given by the user (e.g., on a scale of 1-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load the dataset\n",
    "ratings = pd.read_csv(\"./data/Netflix_Dataset_Rating.csv\")  # Columns: User_ID, Rating, Movie_ID\n",
    "movies  = pd.read_csv(\"./data/Netflix_Dataset_Movie.csv\")    # Columns: Movie_ID, Year, Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formal Definition\n",
    "\n",
    "- $U = \\{u_1, u_2, \\dots, u_n\\}$ is the set of users.\n",
    "- $U_i = \\{u \\in U \\mid r_{u,i} \\neq 0\\}$ is the set of users who have rated item $i$\n",
    "- $I = \\{i_1, i_2, \\dots, i_m\\}$ is the set of items.\n",
    "- $I_u = \\{i \\in I \\mid r_{u,i} \\neq 0\\}$ is the set of items rated by user $u$\n",
    "- $R = \\{0, 1, \\dots, 5\\} \\lor R = [0, 1]$ is the set of ratings.\n",
    "- $r_{u,i}$ is the rating given by user $u$ for item $i$ (equal to 0 if not rated)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Based Collaborative Filtering\n",
    "\n",
    "### 1. Data Preprocessing\n",
    "- **User-Item Matrix Creation**: Convert the ratings dataset into a user-item matrix, where rows represent users and columns represent movies. Missing ratings are filled with zeros. Each rating is represented by a number from 1 to 5.\n",
    "  $$ M[u, i] = r_{u,i} \\in R$$\n",
    "  Where:\n",
    "  - $u \\in U$ is the set of users.\n",
    "  - $i \\in I$ is the set of movies.\n",
    "  - $r_{u,i}$ is the rating given by user $u$ for movie $i$.\n",
    "\n",
    "- **Sparse Matrix Conversion**: The dense matrix is converted to a sparse format for memory optimization:\n",
    "  $$M_{\\{\\text{sparse}\\}} = \\text{csr\\_matrix}(M)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a user-item matrix\n",
    "user_item_matrix = ratings.pivot(index='User_ID', columns='Movie_ID', values='Rating')\n",
    "\n",
    "# Fill missing values with 0 (can use NaN for some algorithms)\n",
    "user_item_matrix.fillna(0, inplace=True) # It is not the case for this dataset\n",
    "\n",
    "# Convert the DataFrame to a sparse matrix\n",
    "sparse_user_item = csr_matrix(user_item_matrix.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Collaborative Filtering Model\n",
    "We use the `scikit-learn` library to implement a KNN-based model:\n",
    "\n",
    "1. **Similarity Metric**: Cosine similarity is used to identify users with similar rating patterns. The formula for cosine similarity between two users $u$ and $v$ is:\n",
    "   $$\n",
    "   \\text{sim}(u, v) = \\frac{\\vec r_u \\cdot \\vec r_v}{\\|\\vec r_u\\| \\cdot \\|\\vec r_v\\|}\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\vec r_u$ and $\\vec r_v$ are column vectors of ratings for users $u$ and $v$ respectively (the $u$-th and $v$-th rows of the user-item matrix).\n",
    "   - $\\cdot$ represents the dot product.\n",
    "\n",
    "2. **Nearest Neighbors**: The model identifies the top $k$ nearest neighbors for each user, based on the similarity scores:\n",
    "   $$\\large\n",
    "   \\mathcal{N}_u^k = \\argmax_{U' \\subseteq U \\setminus \\{u\\} \\land |U'| = k} \\sum_{v \\in U'} \\text{sim}(u, v)\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\mathcal N_u^k$ is the set of the top $k$ nearest neighbors for user $u$.\n",
    "   - $U'$ is a subset of users excluding $u$.\n",
    "   - $k = 10$ (default value in this implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine', n_neighbors=10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Build the collaborative filtering model\n",
    "model_knn_user = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)\n",
    "model_knn_user.fit(sparse_user_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Recommendation Function (User-Based)\n",
    "\n",
    "In the user-based collaborative filtering approach, the recommendation function operates as follows:\n",
    "\n",
    "1. **Get all relevant items**: The set of items rated by the top $k$ nearest neighbors for user $u$:\n",
    "$$\n",
    "I^k = \\{i \\in I \\mid \\exists v \\in \\mathcal N_u^k : r_{v,i} \\neq 0\\}\n",
    "$$\n",
    "Where:\n",
    "- $\\mathcal N_u^k$ is the set of the top $k$ nearest neighbors for user $u$.\n",
    "- $I^k$ is the set of items rated by the top $k$ nearest neighbors for user $u$.\n",
    "- $k = 10$ (default value in this implementation).\n",
    "\n",
    "1. **Prediction Formula**: For a given user $u$ and an item $i$ not yet rated by $u$, the predicted rating is calculated as:\n",
    "   $$\\large\n",
    "   \\hat{r}_{u,i} = \\frac{\\sum_{v \\in \\mathcal N_u^k \\land i \\in I^k} \\text{sim}(u, v) \\cdot r_{v,i}}{\\sum_{v \\in \\mathcal N_u^k \\land i \\in I^k} \\text{sim}(u, v)}\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\hat{r}_{u,i}$ is the predicted rating for user $u$ on item $i$.\n",
    "   - $r_{v,i}$ is the rating of neighbor $v \\in \\mathcal N_u^k$ for item $i$.\n",
    "   - $\\text{sim}(u, v)$ is the similarity between users $u$ and $v$.\n",
    "\n",
    "This combination of steps allows the model to efficiently generate user-based collaborative filtering recommendations using nearest neighbors. This approach works well in cases where users with similar preferences exist in the dataset. For example, if two users have rated several movies similarly, the model assumes they will likely share preferences for other movies as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define a recommendation function\n",
    "def recommend_movies_user_based(user_id, num_recommendations=5):\n",
    "    \"\"\"Recommend movies using user-based collaborative filtering.\"\"\"\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        raise ValueError(\"User ID not found in the dataset\")\n",
    "\n",
    "    # Get the user vector\n",
    "    user_idx = user_item_matrix.index.get_loc(user_id)\n",
    "    user_vector = sparse_user_item[user_idx]\n",
    "\n",
    "    # Find nearest neighbors\n",
    "    distances, indices = model_knn_user.kneighbors(user_vector, n_neighbors=num_recommendations + 1)\n",
    "\n",
    "    # Filter out the user itself (distance = 0)\n",
    "    neighbors = indices.flatten()[1:]\n",
    "    similarity_scores = 1 - distances.flatten()[1:]  # Convert distances to similarity scores\n",
    "\n",
    "    # Get movies rated by similar users and calculate the weighted average rating\n",
    "    similar_users_ratings = user_item_matrix.iloc[neighbors]\n",
    "    weighted_ratings = (similar_users_ratings.T * similarity_scores).T  # Apply weights\n",
    "    mean_ratings = weighted_ratings.sum(axis=0) / similarity_scores.sum()\n",
    "\n",
    "    # Sort by rating and get the top recommendations\n",
    "    recommended_movies = mean_ratings.sort_values(ascending=False).head(num_recommendations)\n",
    "\n",
    "    # Map movie IDs to names\n",
    "    recommended_movies = recommended_movies.reset_index()\n",
    "    recommended_movies.columns = ['Movie_ID', 'Estimated_Rating']\n",
    "    recommendations = recommended_movies.merge(movies, on='Movie_ID')[['Name', 'Year', 'Estimated_Rating']]\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Testing\n",
    "The function is tested with a sample user to generate personalized recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 movie recommendations for User 1331154:\n",
      "                                                Name  Year  Estimated_Rating\n",
      "0      Lord of the Rings: The Fellowship of the Ring  2001          4.604151\n",
      "1                                    The Sixth Sense  1999          4.600873\n",
      "2                                         Braveheart  1995          4.600873\n",
      "3                                   The Last Samurai  2003          4.598734\n",
      "4  Pirates of the Caribbean: The Curse of the Bla...  2003          4.595456\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Test the recommendation function\n",
    "user_id_to_test = 1331154  # Change as needed\n",
    "num_recommendations = 5\n",
    "\n",
    "try:\n",
    "    user_based_recommendations = recommend_movies_user_based(user_id_to_test, num_recommendations=num_recommendations)\n",
    "    print(f\"Top {num_recommendations} movie recommendations for User {user_id_to_test}:\")\n",
    "    print(user_based_recommendations)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-Based Collaborative Filtering\n",
    "\n",
    "### 1. Data Preprocessing\n",
    "- **Item-User Matrix Creation**: Transpose the user-item matrix $M$ to create a new matrix $M' = M^T$, where rows represent movies and columns represent users. Missing ratings are filled with zeros.\n",
    "  $$ M'[i, u] = M[u, i] = r_{u,i} \\in R$$\n",
    "- **Sparse Matrix Conversion**: The dense matrix is converted to a sparse format to optimize memory usage.\n",
    "  $$M'_{\\{\\text{sparse}\\}} = \\text{csr\\_matrix}(M')$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Transpose the user-item matrix\n",
    "item_user_matrix = user_item_matrix.T\n",
    "\n",
    "# Convert the DataFrame to a sparse matrix\n",
    "sparse_item_user = csr_matrix(item_user_matrix.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Collaborative Filtering Model (Item-Based)\n",
    "We use the `scikit-learn` library to implement a KNN-based model:\n",
    "\n",
    "1. **Similarity Metric**: Cosine similarity is used to identify movies with similar rating patterns. The formula for cosine similarity between two movies $i$ and $j$ is:\n",
    "   $$\n",
    "   \\text{sim}(i, j) = \\frac{\\vec r_i \\cdot \\vec r_j}{\\|\\vec r_i\\| \\cdot \\|\\vec r_j\\|}\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\vec r_i$ and $\\vec r_j$ are column vectors of user ratings for movies $i$ and $j$ respectively (the $i$-th and $j$-th rows of the item-user matrix $M'$).\n",
    "   - $\\cdot$ represents the dot product.\n",
    "\n",
    "2. **Nearest Neighbors**: The model identifies the top $k$ nearest neighbors for each movie based on similarity scores:\n",
    "   $$\\large\n",
    "   \\mathcal{N}_i^k = \\argmax_{I'_u \\subseteq I_u \\setminus \\{i\\} \\land |I'_u| = k} \\sum_{j \\in I'_u} \\text{sim}(i, j)\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\mathcal N_i^k$ is the set of the top $k$ nearest neighbors (in the user $u$ rated movies set) for movie $i$.\n",
    "   - $I'_u$ is a subset of items rated by user $u$ that excludes movie $i$, obviously.\n",
    "   - $k = 10$ (default value in this implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build the item-based collaborative filtering model\n",
    "model_knn_item = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)\n",
    "\n",
    "# Calculate the sparse matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Recommendation Function (Item-Based)\n",
    "\n",
    "In the item-based collaborative filtering approach, the recommendation function works as follows:\n",
    "\n",
    "Predict movie ratings for the target user by aggregating ratings from similar movies. For a given user $u$ and an item $i$ not yet rated by $u$, the predicted rating is calculated as:\n",
    "   $$\\large\n",
    "   \\hat{r}_{u,i} = \\frac{\\sum_{j \\in \\mathcal N_i^k} \\text{sim}(i, j) \\cdot r_{u,j}}{\\sum_{j \\in \\mathcal N_i^k} \\text{sim}(i, j)}\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\hat{r}_{u,i}$ is the predicted rating for user $u$ on item $i$.\n",
    "   - $r_{u,j}$ is the rating of user $u$ for a similar item $j \\in \\mathcal N_i^k$.\n",
    "   - $\\text{sim}(i, j)$ is the similarity between items $i$ and $j$.\n",
    "   - $\\mathcal N_i^k$ is the set of the top $k$ most similar items to $i$.\n",
    "\n",
    "This method leverages the user's own preferences and the similarity relationships between movies, providing relevant and personalized suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Recommendation Function (Item-Based)\n",
    "from tqdm import tqdm\n",
    "\n",
    "def recommend_movies_item_based(user_id, num_recommendations=5):\n",
    "    \"\"\"Recommend movies using item-based collaborative filtering for a given user.\"\"\"\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        raise ValueError(\"User ID not found in the dataset\")\n",
    "\n",
    "    # Get the user's ratings\n",
    "    user_ratings = item_user_matrix.loc[:, user_id]\n",
    "    rated_movies = user_ratings[user_ratings > 0].index  # Movies the user has rated\n",
    "\n",
    "    if len(rated_movies) == 0:\n",
    "        raise ValueError(\"User has not rated any movies\")\n",
    "\n",
    "    # Initialize a dictionary to store weighted scores\n",
    "    movie_scores = {}\n",
    "\n",
    "    # Fit the model with the sparse item-user matrix limited to the movies rated by the user\n",
    "    sparse_item_user = item_user_matrix.values\n",
    "    sparse_item_user_u = item_user_matrix.loc[rated_movies].to_numpy()\n",
    "\n",
    "    # Fit the model with the sparse item-user matrix limited to the movies rated by the user\n",
    "    model_knn_item.fit(sparse_item_user_u)\n",
    "\n",
    "    # Iterate over all movies not rated by the user\n",
    "    for movie_id in tqdm(item_user_matrix.index.difference(rated_movies), desc=\"Processing Movies\", unit=\"movie\"):\n",
    "\n",
    "        # Get the vector for the movie\n",
    "        movie_vector = item_user_matrix.loc[movie_id, :] # Get the corresponding row in the item-user matrix\n",
    "\n",
    "        # Find nearest neighbors for the movie\n",
    "        distances, indices = model_knn_item.kneighbors(movie_vector.to_numpy().reshape(1, -1), n_neighbors=10)\n",
    "\n",
    "        # Calculate weighted average rating for the movie\n",
    "        similarity_scores = 1 - distances.flatten()  # Convert distances to similarity scores\n",
    "\n",
    "        # Get the indexes of the similar movies\n",
    "        similar_movies = [rated_movies[index] for index in indices.flatten()]\n",
    "\n",
    "        # Calculate the weighted average score for the movie using similarity scores\n",
    "        movie_scores[movie_id] = np.dot(similarity_scores, item_user_matrix.loc[similar_movies, user_id].to_numpy())\n",
    "\n",
    "    # Sort movies by aggregated score\n",
    "    recommended_movies = sorted(movie_scores.items(), key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "\n",
    "    # Normalize the scores\n",
    "    recommended_movies = [(movie_id, score / max(movie_scores.values()) * 5) for movie_id, score in recommended_movies]\n",
    "\n",
    "    # Map movie IDs to names\n",
    "    recommended_movies_df = pd.DataFrame(recommended_movies, columns=['Movie_ID', 'Estimated_Rating'])\n",
    "    recommendations = recommended_movies_df.merge(movies, on='Movie_ID')[['Name', 'Year', 'Estimated_Rating']]\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version with sparse matrix (more efficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def recommend_movies_item_based(user_id, num_recommendations=5):\n",
    "    \"\"\"Recommend movies using item-based collaborative filtering for a given user.\"\"\"\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        raise ValueError(\"User ID not found in the dataset\")\n",
    "\n",
    "    # Get the user's ratings\n",
    "    user_ratings = item_user_matrix.loc[:, user_id].to_numpy()\n",
    "    rated_movies = np.where(user_ratings > 0)[0]  # Indices of movies the user has rated\n",
    "\n",
    "    if len(rated_movies) == 0:\n",
    "        raise ValueError(\"User has not rated any movies\")\n",
    "\n",
    "    # Initialize a dictionary to store weighted scores\n",
    "    movie_scores = {}\n",
    "\n",
    "    # Convert item-user matrix to sparse format\n",
    "    sparse_item_user = csr_matrix(item_user_matrix.values)\n",
    "\n",
    "    # Fit the model with the sparse item-user matrix limited to the rated movies\n",
    "    sparse_item_user_u = sparse_item_user[rated_movies, :]\n",
    "    model_knn_item.fit(sparse_item_user_u)\n",
    "\n",
    "    # Iterate over all movies not rated by the user\n",
    "    for movie_id in tqdm(item_user_matrix.index.difference(item_user_matrix.index[rated_movies]), \n",
    "                         desc=\"Processing Movies\", unit=\"movie\"):\n",
    "        # Get the vector for the movie\n",
    "        movie_idx = item_user_matrix.index.get_loc(movie_id)\n",
    "        movie_vector = sparse_item_user[movie_idx, :]\n",
    "\n",
    "        # Find nearest neighbors for the movie\n",
    "        distances, indices = model_knn_item.kneighbors(movie_vector, n_neighbors=10)\n",
    "\n",
    "        # Calculate similarity scores\n",
    "        similarity_scores = 1 - distances.flatten()\n",
    "\n",
    "        # Get the indexes of the similar movies\n",
    "        similar_movies = rated_movies[indices.flatten()]\n",
    "\n",
    "        # Calculate the weighted average score for the movie using similarity scores\n",
    "        user_ratings_for_similar = user_ratings[similar_movies]\n",
    "        movie_scores[movie_id] = np.dot(similarity_scores, user_ratings_for_similar)\n",
    "\n",
    "    # Sort movies by aggregated score\n",
    "    recommended_movies = sorted(movie_scores.items(), key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "\n",
    "    # Normalize the scores\n",
    "    max_score = max(movie_scores.values()) if movie_scores else 1  # Avoid division by zero\n",
    "    recommended_movies = [(movie_id, score / max_score * 5) for movie_id, score in recommended_movies]\n",
    "\n",
    "    # Map movie IDs to names\n",
    "    recommended_movies_df = pd.DataFrame(recommended_movies, columns=['Movie_ID', 'Estimated_Rating'])\n",
    "    recommendations = recommended_movies_df.merge(movies, on='Movie_ID')[['Name', 'Year', 'Estimated_Rating']]\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Testing\n",
    "The function is tested with a sample user to generate personalized recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Movies: 100%|██████████| 1331/1331 [00:12<00:00, 108.98movie/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 movie recommendations for User 774868 (Item-Based):\n",
      "                                                Name  Year  Estimated_Rating\n",
      "0  Pirates of the Caribbean: The Curse of the Bla...  2003          5.000000\n",
      "1      Lord of the Rings: The Fellowship of the Ring  2001          4.943047\n",
      "2                                    The Sixth Sense  1999          4.885478\n",
      "3                                    American Beauty  1999          4.842662\n",
      "4                          Finding Nemo (Widescreen)  2003          4.788035\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Test the recommendation function\n",
    "user_id_to_test = 774868  # Change as needed\n",
    "num_recommendations = 5\n",
    "\n",
    "try:\n",
    "    item_based_recommendations = recommend_movies_item_based(user_id_to_test, num_recommendations=num_recommendations)\n",
    "    print(f\"Top {num_recommendations} movie recommendations for User {user_id_to_test} (Item-Based):\")\n",
    "    print(item_based_recommendations)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation of the Model\n",
    "\n",
    "To assess the effectiveness of the collaborative filtering approach, we perform a train-test split on the ratings data. The evaluation process includes:\n",
    "\n",
    "1. **Train-Test Split**:  \n",
    "   - 80% of the data is used for training the model.\n",
    "   - 20% of the data is reserved for testing.\n",
    "\n",
    "2. **Predictions and Metrics**:  \n",
    "   - For each user in the test set, the model predicts ratings for movies based on the nearest neighbors identified in the training data.\n",
    "   - **Mean Absolute Error (MAE)** is calculated as the primary metric to evaluate prediction accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 1000/1000 [05:36<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1.9254252623959465\n",
      "Root Mean Squared Error (RMSE): 2.298046346463847\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluation (Optional)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(recommendation_function, name='Model'):\n",
    "    \"\"\"Evaluate a recommendation function using MAE and RMSE.\"\"\"\n",
    "    # Split the ratings data\n",
    "    train_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create train and test user-item matrices\n",
    "    train_matrix = train_data.pivot(index='User_ID', columns='Movie_ID', values='Rating').fillna(0)\n",
    "    test_matrix = test_data.pivot(index='User_ID', columns='Movie_ID', values='Rating').fillna(0)\n",
    "\n",
    "    predictions = []\n",
    "    true_ratings = []\n",
    "\n",
    "    for user_id in tqdm(test_matrix.index, desc=\"Evaluating \" + name + \" Model\"):\n",
    "        try:\n",
    "            recommendations = recommendation_function(user_id, num_recommendations=10)\n",
    "            recommended_movie_ids = recommendations['Movie_ID']\n",
    "            user_test_ratings = test_matrix.loc[user_id]\n",
    "\n",
    "            for movie_id in recommended_movie_ids:\n",
    "                if movie_id in user_test_ratings.index and user_test_ratings[movie_id] > 0:\n",
    "                    predictions.append(recommendations.loc[recommendations['Movie_ID'] == movie_id, 'Estimated_Rating'].values[0])\n",
    "                    true_ratings.append(user_test_ratings[movie_id])\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    mae = mean_absolute_error(true_ratings, predictions)\n",
    "    rmse = mean_squared_error(true_ratings, predictions, squared=False)\n",
    "\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Example Evaluation\n",
    "evaluate_model(recommend_movies_user_based, name='User-Based')\n",
    "evaluate_model(recommend_movies_item_based, name='Item-Based')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This notebook demonstrated the implementation of a collaborative filtering approach for recommending movies. Key takeaways include:\n",
    "\n",
    "- The model effectively utilizes user similarity to make recommendations, as shown by the ability to generate relevant suggestions for a sample user.\n",
    "- The **MAE metric** provides a reliable evaluation of the model's predictive accuracy.\n",
    "- While collaborative filtering is powerful, it faces challenges such as:\n",
    "  - **Cold Start Problem**: Difficulty in recommending movies for new users or items.\n",
    "  - **Data Sparsity**: Limited interactions in the dataset can affect similarity computations.\n",
    "\n",
    "### Future Improvements\n",
    "\n",
    "To address the limitations, potential enhancements include:\n",
    "\n",
    "- Implementing hybrid recommendation systems that combine collaborative and content-based filtering.\n",
    "- Exploring matrix factorization techniques (e.g., Singular Value Decomposition).\n",
    "- Integrating deep learning-based recommendation methods.\n",
    "\n",
    "This collaborative filtering approach forms a solid foundation for building scalable and effective recommendation systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
