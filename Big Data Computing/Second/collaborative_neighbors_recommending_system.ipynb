{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Neighborhood-Based Filtering for Movie Recommendations (Incomplete)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Collaborative neighborhood-based filtering is a popular approach in recommendation systems that leverages user-item interactions to predict user preferences based on the preferences of users who are similar to the target user and the items that the target user has already rated. There are two main types of collaborative filtering:\n",
    "\n",
    "- **User-Based Collaborative Filtering**: Recommends items based on the preferences of users who are similar to the target user.\n",
    "- **Item-Based Collaborative Filtering**: Suggests items that are similar to those the user has already rated positively.\n",
    "\n",
    "In this notebook, we will explore both approaches for movie recommendations.\n",
    "\n",
    "## Dataset Description\n",
    "We use two datasets for this analysis:\n",
    "1. **Movies Dataset**:\n",
    "   - `Movie_ID`: Unique identifier for each movie.\n",
    "   - `Name`: Title of the movie.\n",
    "   - `Year`: Release year of the movie.\n",
    "\n",
    "2. **Ratings Dataset**:\n",
    "   - `User_ID`: Unique identifier for each user.\n",
    "   - `Movie_ID`: Identifier for the movie rated.\n",
    "   - `Rating`: Numeric rating given by the user (e.g., on a scale of 1-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load the dataset\n",
    "ratings = pd.read_csv(\"./data/Netflix_Dataset_Rating.csv\")  # Columns: User_ID, Rating, Movie_ID\n",
    "movies  = pd.read_csv(\"./data/Netflix_Dataset_Movie.csv\")    # Columns: Movie_ID, Year, Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formal Definition\n",
    "\n",
    "- $U = \\{u_1, u_2, \\dots, u_n\\}$ is the set of users.\n",
    "- $U_i = \\{u \\in U \\mid r_{u,i} \\neq 0\\}$ is the set of users who have rated item $i$\n",
    "- $I = \\{i_1, i_2, \\dots, i_m\\}$ is the set of items.\n",
    "- $I_u = \\{i \\in I \\mid r_{u,i} \\neq 0\\}$ is the set of items rated by user $u$\n",
    "- $R = \\{0, 1, \\dots, 5\\} \\lor R = [0, 1]$ is the set of ratings.\n",
    "- $r_{u,i}$ is the rating given by user $u$ for item $i$ (equal to 0 if not rated)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Based Collaborative Filtering\n",
    "\n",
    "### 1. Data Preprocessing\n",
    "- **User-Item Matrix Creation**: Convert the ratings dataset into a user-item matrix, where rows represent users and columns represent movies. Missing ratings are filled with zeros. Each rating is represented by a number from 1 to 5.\n",
    "  $$ M[u, i] = r_{u,i} \\in R$$\n",
    "  Where:\n",
    "  - $u \\in U$\n",
    "  - $i \\in I$.\n",
    "\n",
    "- **Sparse Matrix Conversion**: The dense matrix is converted to a sparse format for memory optimization:\n",
    "  $$M_{\\{\\text{sparse}\\}} = \\text{sparse}(M)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a user-item matrix\n",
    "user_item_matrix = ratings.pivot(index='User_ID', columns='Movie_ID', values='Rating')\n",
    "\n",
    "# Fill missing values with 0 (can use NaN for some algorithms)\n",
    "user_item_matrix.fillna(0, inplace=True) # It is not the case for this dataset\n",
    "\n",
    "# Convert the DataFrame to a sparse matrix\n",
    "sparse_user_item = csr_matrix(user_item_matrix.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Collaborative Filtering Model\n",
    "We use the `scikit-learn` library to implement a KNN-based model:\n",
    "\n",
    "1. **Similarity Metric**: Cosine similarity is used to identify users with similar rating patterns. The formula for cosine similarity between two users $u$ and $v$ is:\n",
    "   $$\n",
    "   \\text{sim}(u, v) = \\frac{\\vec r_u \\cdot \\vec r_v}{\\|\\vec r_u\\| \\cdot \\|\\vec r_v\\|}\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\vec r_u$ and $\\vec r_v$ are column vectors of ratings for users $u$ and $v$ respectively (the $u$-th and $v$-th rows of the user-item matrix).\n",
    "   - $\\cdot$ represents the dot product.\n",
    "\n",
    "2. **Nearest Neighbors**: The model identifies the top $k$ nearest neighbors for each user, based on the similarity scores:\n",
    "   $$\\large\n",
    "   \\mathcal{N}_u^k = \\argmax_{U' \\subseteq U \\setminus \\{u\\} \\land |U'| = k} \\sum_{v \\in U'} \\text{sim}(u, v)\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\mathcal N_u^k$ is the set of the top $k$ nearest neighbors for user $u$.\n",
    "   - $U'$ is a subset of users excluding $u$.\n",
    "   - $k = 10$ (default value in this implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build the collaborative filtering model\n",
    "model_knn_user = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Recommendation Function (User-Based)\n",
    "\n",
    "In the user-based collaborative filtering approach, the recommendation function operates as follows:\n",
    "\n",
    "1. **Get all relevant items**: The set of items rated by the top $k$ nearest neighbors for user $u$:\n",
    "   $$\\large\n",
    "   I^k = \\{i \\in I \\setminus I_u \\mid \\exists v \\in \\mathcal N_u^k : r_{v,i} \\neq 0\\}\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\mathcal N_u^k$ is the set of the top $k$ nearest neighbors for user $u$.\n",
    "   - $I^k$ is the set of items rated by the top $k$ nearest neighbors for user $u$ and not already rated by $u$.\n",
    "   - $k = 10$ (default value in this implementation).\n",
    "\n",
    "2. **Prediction Formula**: For a given user $u$, the set of predicted ratings for items $i \\in I^k$ is calculated as:\n",
    "   $$\\large\n",
    "   I^k_u = \\{\\hat{r}_{u,i} \\mid i \\in I^k\\} \\quad \\text{where} \\quad\n",
    "   \\hat{r}_{u,i} = \\frac{\\sum_{v \\in \\mathcal N_u^k} \\text{sim}(u, v) \\cdot r_{v,i}}{\\sum_{v \\in \\mathcal N_u^k} \\text{sim}(u, v)}\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\hat{r}_{u,i}$ is the predicted rating for user $u$ on item $i$.\n",
    "   - $r_{v,i}$ is the rating of neighbor $v \\in \\mathcal N_u^k$ for item $i$.\n",
    "   - $\\text{sim}(u, v)$ is the similarity between users $u$ and $v$.\n",
    "\n",
    "This combination of steps allows the model to efficiently generate user-based collaborative filtering recommendations using nearest neighbors. This approach works well in cases where users with similar preferences exist in the dataset. For example, if two users have rated several movies similarly, the model assumes they will likely share preferences for other movies as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define a rating and a recommendation function\n",
    "def recommend_movies_user_based(user_id, train_matrix, user_index, movie_index, movies, num_recommendations=None, k=10):\n",
    "    \"\"\"\n",
    "    Recommend movies using user-based collaborative filtering.\n",
    "\n",
    "    Parameters:\n",
    "        user_id (int): ID of the user for whom to generate recommendations.\n",
    "        train_matrix (csr_matrix): Sparse user-item matrix (rows = users, columns = movies).\n",
    "        user_index (dict): Maps user IDs to row indices in the train_matrix.\n",
    "        movie_index (dict): Maps column indices in the train_matrix to movie IDs.\n",
    "        movies (pd.DataFrame): DataFrame with movie metadata (columns: Movie_ID, Year, Name).\n",
    "        num_recommendations (int, optional): Number of recommendations to return. Defaults to None (all).\n",
    "        k (int, optional): Number of nearest neighbors to consider. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with recommended movies (columns: ['Movie_ID', 'Name', 'Year', 'Estimated_Rating']).\n",
    "    \"\"\"\n",
    "    if user_id not in user_index:\n",
    "        raise ValueError(f\"User ID {user_id} not found in the dataset\")\n",
    "\n",
    "    # Identify user index and retrieve their vector\n",
    "    user_idx = user_index[user_id]\n",
    "    user_vector = train_matrix[user_idx]\n",
    "\n",
    "    # Fit the KNN model and find neighbors\n",
    "    model_knn_user.fit(train_matrix)\n",
    "    distances, indices = model_knn_user.kneighbors(user_vector, n_neighbors=k + 1)\n",
    "\n",
    "    # Process neighbors (exclude the user itself)\n",
    "    neighbors, similarity_scores = indices.flatten()[1:], 1 - distances.flatten()[1:]\n",
    "\n",
    "    # Compute weighted ratings and normalize\n",
    "    similar_users_ratings = train_matrix[neighbors].toarray()\n",
    "    weighted_ratings = similar_users_ratings.T @ similarity_scores\n",
    "    normalization = similarity_scores.sum()\n",
    "    mean_ratings = weighted_ratings / normalization\n",
    "\n",
    "    # Filter out already rated movies\n",
    "    mean_ratings[user_vector.indices] = 0\n",
    "\n",
    "    # Rank movies by estimated ratings\n",
    "    top_indices = np.argsort(mean_ratings)[::-1]\n",
    "    if num_recommendations:\n",
    "        top_indices = top_indices[:num_recommendations]\n",
    "\n",
    "    # Map indices back to movie IDs and retrieve metadata\n",
    "    recommendations = pd.DataFrame({\n",
    "        'Movie_ID': [movie_index[idx] for idx in top_indices],\n",
    "        'Estimated_Rating': mean_ratings[top_indices]\n",
    "    })\n",
    "    recommendations = recommendations.merge(movies, on='Movie_ID')[['Movie_ID', 'Name', 'Year', 'Estimated_Rating']]\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Testing (User-Based)\n",
    "The function is tested with a sample user to generate personalized recommendations (User-Based)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 movie recommendations for User 305344:\n",
      "             Name  Year  Estimated_Rating  Movie_ID\n",
      "0  Doctor Zhivago  1965          4.211178      3153\n",
      "1         Hackers  1995          3.834992      3680\n",
      "2             Ray  2004          3.648459       886\n",
      "3      The Rookie  1990          3.424174      2251\n",
      "4        Sideways  2004          3.339992      3282\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Test the recommendation function\n",
    "user_id_to_test = 305344  # User ID for which to generate recommendations\n",
    "num_recommendations = 5\n",
    "\n",
    "# Create dictionaries to map user IDs and movie IDs to matrix indices\n",
    "user_index = {user_id: idx for idx, user_id in enumerate(user_item_matrix.index)}\n",
    "movie_index = {idx: movie_id for idx, movie_id in enumerate(user_item_matrix.columns)}\n",
    "\n",
    "try:\n",
    "    # Generate recommendations for the specified user\n",
    "    user_based_recommendations = recommend_movies_user_based(\n",
    "        user_id=user_id_to_test,\n",
    "        train_matrix=sparse_user_item,\n",
    "        user_index=user_index,\n",
    "        movie_index=movie_index,\n",
    "        movies=movies,\n",
    "        num_recommendations=num_recommendations,\n",
    "        k=10\n",
    "    )\n",
    "    \n",
    "    # Display recommendations\n",
    "    print(f\"Top {num_recommendations} movie recommendations for User {user_id_to_test}:\")\n",
    "    print(user_based_recommendations[['Name', 'Year', 'Estimated_Rating', 'Movie_ID']])\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-Based Collaborative Filtering\n",
    "\n",
    "### 1. Data Preprocessing\n",
    "- **Item-User Matrix Creation**: Transpose the user-item matrix $M$ to create a new matrix $M' = M^T$, where rows represent movies and columns represent users. Missing ratings are filled with zeros.\n",
    "  $$ M'[i, u] = M[u, i] = r_{u,i} \\in R$$\n",
    "- **Sparse Matrix Conversion**: The dense matrix is converted to a sparse format to optimize memory usage.\n",
    "  $$M'_{\\{\\text{sparse}\\}} = \\text{csr\\_matrix}(M')$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Transpose the user-item matrix\n",
    "item_user_matrix = user_item_matrix.T\n",
    "\n",
    "# Convert the DataFrame to a sparse matrix\n",
    "sparse_item_user = csr_matrix(item_user_matrix.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Collaborative Filtering Model (Item-Based)\n",
    "We use the `scikit-learn` library to implement a KNN-based model:\n",
    "\n",
    "1. **Similarity Metric**: Cosine similarity is used to identify movies with similar rating patterns. The formula for cosine similarity between two movies $i$ and $j$ is:\n",
    "   $$\n",
    "   \\text{sim}(i, j) = \\frac{\\vec r_i \\cdot \\vec r_j}{\\|\\vec r_i\\| \\cdot \\|\\vec r_j\\|}\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\vec r_i$ and $\\vec r_j$ are column vectors of user ratings for movies $i$ and $j$ respectively (the $i$-th and $j$-th rows of the item-user matrix $M'$).\n",
    "   - $\\cdot$ represents the dot product.\n",
    "\n",
    "2. **Nearest Neighbors**: The model identifies the top $k$ nearest neighbors for each movie $i \\in I \\setminus I_u$ based on similarity scores:\n",
    "   $$\\large\n",
    "   \\mathcal{N}_i^k = \\argmax_{I'_u \\subseteq I_u \\setminus \\{i\\} \\land |I'_u| = k} \\sum_{j \\in I'_u} \\text{sim}(i, j)\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\mathcal N_i^k$ is the set of the top $k$ nearest movies (in the user $u$ rated movies set) for movie $i$.\n",
    "   - $I'_u$ is a subset, of size $k$, of items rated by user $u$ that excludes movie $i$, obviously.\n",
    "   - $k = 10$ (default value in this implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build the item-based collaborative filtering model\n",
    "model_knn_item = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)\n",
    "\n",
    "# Create the sparse matrix for the item-based model\n",
    "sparse_item_user = csr_matrix(item_user_matrix.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Recommendation Function (Item-Based)\n",
    "\n",
    "In the item-based collaborative filtering approach, the recommendation function works as follows:\n",
    "\n",
    "Predict movie ratings for the target user $u$ by aggregating ratings from similar movies (not already rated by $u$) to the already rated ones. For a given user $u$ and a set of items not yet rated by $u$, the predicted rating is calculated as:\n",
    "   $$\\large\n",
    "   I^k_u = \\{\\hat{r}_{u,i} \\mid i \\in I \\setminus I_u \\setminus \\{i\\}\\} \\quad \\text{where} \\quad\n",
    "   \\hat{r}_{u,i} = \\frac{\\sum_{j \\in \\mathcal N_i^k} \\text{sim}(i, j) \\cdot r_{u,j}}{\\sum_{j \\in \\mathcal N_i^k} \\text{sim}(i, j)}\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\hat{r}_{u,i}$ is the predicted rating for user $u$ on item $i$.\n",
    "   - $r_{u,j}$ is the rating of user $u$ for a similar item $j \\in \\mathcal N_i^k$.\n",
    "   - $\\text{sim}(i, j)$ is the similarity between items $i$ and $j$.\n",
    "   - $\\mathcal N_i^k$ is the set of the top $k$ most similar items to $i$.\n",
    "   - $I^k_u$ is the set of predicted ratings for user $u$ on items not yet rated by $u$.\n",
    "\n",
    "Thus, for each movie not rated by the target user, the model calculates a weighted average of similar movies' ratings based on their similarity scores. The predicted ratings are then sorted and the top are returned.\n",
    "\n",
    "For accuracy reasons, the predicted rating will be sorted by $\\sum_{j \\in \\mathcal N_i^k} \\text{sim}(i, j) \\cdot r_{u,j}$ and not by $\\hat{r}_{u,i}$. This smply because when we divide by $\\sum_{j \\in \\mathcal N_i^k} \\text{sim}(i, j)$ we are not considering the similarity scores anymore, and this is not an optimal approach since we want that movies that are closer to already rated ones have an higher weight in the rating estimation. \n",
    "\n",
    "This method leverages the user's own preferences and the similarity relationships between movies, providing relevant and personalized suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Recommendation Function (Item-Based)\n",
    "from tqdm import tqdm\n",
    "\n",
    "def recommend_movies_item_based(user_id, train_matrix, num_recommendations=5, k=10):\n",
    "    \"\"\"Recommend movies using item-based collaborative filtering for a given user.\"\"\"\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        raise ValueError(\"User ID not found in the dataset\")\n",
    "\n",
    "    # Get the user's ratings\n",
    "    user_ratings = item_user_matrix.loc[:, user_id].to_numpy()\n",
    "    rated_movies = np.where(user_ratings > 0)[0]  # Indices of movies the user has rated\n",
    "\n",
    "    if len(rated_movies) == 0:\n",
    "        raise ValueError(\"User has not rated any movies\")\n",
    "\n",
    "    # Initialize a dictionary to store weighted scores\n",
    "    movie_scores = {}\n",
    "\n",
    "    # Fit the model with the sparse item-user matrix limited to the rated movies\n",
    "    sparse_item_user_u = train_matrix[rated_movies, :]\n",
    "    model_knn_item.fit(sparse_item_user_u)\n",
    "\n",
    "    # Get unseen movies\n",
    "    not_rated_movies = item_user_matrix.index.difference(item_user_matrix.index[rated_movies])\n",
    "\n",
    "    # Iterate over all movies not rated by the user\n",
    "    for movie_id in tqdm(not_rated_movies, \n",
    "                         desc=\"Processing Movies\", unit=\"movie\"):\n",
    "        # Get the vector for the movie\n",
    "        movie_idx = item_user_matrix.index.get_loc(movie_id)\n",
    "        movie_vector = train_matrix[movie_idx, :]\n",
    "\n",
    "        # Find nearest neighbors for the movie\n",
    "        distances, indices = model_knn_item.kneighbors(movie_vector, n_neighbors=k)\n",
    "\n",
    "        # Calculate similarity scores\n",
    "        similarity_scores = 1 - distances.flatten()\n",
    "\n",
    "        # Get the indexes of the similar movies\n",
    "        similar_movies = rated_movies[indices.flatten()]\n",
    "\n",
    "        # Calculate the weighted average score for the movie using similarity scores\n",
    "        user_ratings_for_similar = user_ratings[similar_movies]\n",
    "        movie_scores[movie_id]   = [\n",
    "            np.dot(similarity_scores, user_ratings_for_similar), # Weighted sum\n",
    "            similarity_scores.sum() # Sum of similarity scores\n",
    "        ]\n",
    "\n",
    "    # Sort movies by aggregated score\n",
    "    recommended_movies = sorted(movie_scores.items(), key=lambda x: x[1][0], reverse=True)[:num_recommendations]\n",
    "\n",
    "    # Normalize the scores\n",
    "    recommended_movies = [(movie_id, score[0] / score[1]) for movie_id, score in recommended_movies]\n",
    "\n",
    "    # Map movie IDs to names\n",
    "    recommended_movies_df = pd.DataFrame(sorted(recommended_movies, key=lambda x: x[1], reverse=True), columns=['Movie_ID', 'Estimated_Rating'])\n",
    "    recommendations = recommended_movies_df.merge(movies, on='Movie_ID')[['Movie_ID', 'Name', 'Year', 'Estimated_Rating']]\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def recommend_movies_item_based(user_id, train_matrix, item_index, user_index, movies, num_recommendations=5, k=10):\n",
    "    \"\"\"\n",
    "    Recommend movies using item-based collaborative filtering for a given user.\n",
    "    This version ensures the same results as the original, but with optimized performance.\n",
    "    \"\"\"\n",
    "    # Verifica che l'utente esista nel dataset\n",
    "    if user_id not in user_index:\n",
    "        raise ValueError(\"User ID not found in the dataset\")\n",
    "\n",
    "    # Ottieni l'indice interno dell'utente\n",
    "    user_idx = user_index[user_id]\n",
    "\n",
    "    # Recupera le valutazioni dell'utente come array\n",
    "    user_ratings = train_matrix[:, user_idx].toarray().flatten()\n",
    "    rated_movie_indices = np.where(user_ratings > 0)[0]  # Indici dei film valutati dall'utente\n",
    "\n",
    "    # Controlla se l'utente ha valutato almeno un film\n",
    "    if len(rated_movie_indices) == 0:\n",
    "        raise ValueError(\"User has not rated any movies\")\n",
    "\n",
    "    # Inizializza un dizionario per salvare i punteggi ponderati\n",
    "    movie_scores = {}\n",
    "\n",
    "    # KNN per ottenere i film più simili\n",
    "    model_knn_item = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "    \n",
    "    # Allenare il modello con la matrice item-user (limitato ai film già valutati)\n",
    "    sparse_item_user_u = train_matrix[rated_movie_indices, :]\n",
    "    model_knn_item.fit(sparse_item_user_u)\n",
    "    \n",
    "    # Trova i film non ancora valutati dall'utente\n",
    "    not_rated_movie_indices = np.setdiff1d(np.arange(train_matrix.shape[0]), rated_movie_indices)\n",
    "\n",
    "    # Itera sui film non valutati dall'utente\n",
    "    for movie_idx in tqdm(not_rated_movie_indices, desc=\"Processing Movies\", unit=\"movie\"):\n",
    "        # Ottieni il vettore per il film non valutato\n",
    "        movie_vector = train_matrix[movie_idx, :]\n",
    "\n",
    "        # Trova i vicini più simili al film non valutato\n",
    "        distances, indices = model_knn_item.kneighbors(movie_vector, n_neighbors=k)\n",
    "\n",
    "        # Calcola i punteggi di similarità\n",
    "        similarity_scores = 1 - distances.flatten()  # La similarità è (1 - distanza coseno)\n",
    "\n",
    "        # Ottieni gli indici dei film simili che l'utente ha valutato\n",
    "        similar_movies = rated_movie_indices[indices.flatten()]\n",
    "\n",
    "        # Calcola il punteggio medio ponderato per il film\n",
    "        user_ratings_for_similar = user_ratings[similar_movies]\n",
    "        weighted_score = np.dot(similarity_scores, user_ratings_for_similar)\n",
    "        sum_similarity_scores = similarity_scores.sum()\n",
    "\n",
    "        if sum_similarity_scores > 0:\n",
    "            movie_scores[movie_idx] = [weighted_score, sum_similarity_scores]\n",
    "\n",
    "    # Ordina i film per punteggio e seleziona i migliori\n",
    "    recommended_movie_indices = sorted(movie_scores.items(), key=lambda x: x[1][0], reverse=True)[:num_recommendations]\n",
    "\n",
    "    # Converte gli indici in ID dei film\n",
    "    recommended_movies = [(item_index[movie_idx], score[0] / score[1]) for movie_idx, score in recommended_movie_indices]\n",
    "\n",
    "    # Crea il DataFrame delle raccomandazioni\n",
    "    recommended_movies_df = pd.DataFrame(sorted(recommended_movies, key=lambda x: x[1], reverse=True), columns=['Movie_ID', 'Estimated_Rating'])\n",
    "    recommendations = recommended_movies_df.merge(movies, on='Movie_ID')[['Movie_ID', 'Name', 'Year', 'Estimated_Rating']]\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Testing\n",
    "The function is tested with a sample user to generate personalized recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Movies: 100%|██████████| 1331/1331 [00:09<00:00, 145.36movie/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 movie recommendations for User 774868 (Item-Based):\n",
      "                                                Name  Year  Estimated_Rating  \\\n",
      "0                          Finding Nemo (Widescreen)  2003          4.817077   \n",
      "1  Pirates of the Caribbean: The Curse of the Bla...  2003          4.816355   \n",
      "2      Lord of the Rings: The Fellowship of the Ring  2001          4.809336   \n",
      "3                                    The Sixth Sense  1999          4.808670   \n",
      "4                                    American Beauty  1999          4.761287   \n",
      "\n",
      "   Movie_ID  \n",
      "0      3962  \n",
      "1      1905  \n",
      "2      2452  \n",
      "3      4306  \n",
      "4       571  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Test the recommendation function\n",
    "user_id_to_test = 774868#1331154  # Change as needed\n",
    "num_recommendations = 5\n",
    "\n",
    "try:\n",
    "    item_based_recommendations = recommend_movies_item_based(user_id_to_test, sparse_item_user, num_recommendations=num_recommendations, k=10)\n",
    "    print(f\"Top {num_recommendations} movie recommendations for User {user_id_to_test} (Item-Based):\")\n",
    "    print(item_based_recommendations[['Name', 'Year', 'Estimated_Rating', 'Movie_ID']])\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Movies: 100%|██████████| 1331/1331 [00:09<00:00, 146.46movie/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 movie recommendations for User 774868 (Item-Based):\n",
      "                                                Name  Year  Estimated_Rating  \\\n",
      "0                          Finding Nemo (Widescreen)  2003          4.817077   \n",
      "1  Pirates of the Caribbean: The Curse of the Bla...  2003          4.816355   \n",
      "2      Lord of the Rings: The Fellowship of the Ring  2001          4.809336   \n",
      "3                                    The Sixth Sense  1999          4.808670   \n",
      "4                                    American Beauty  1999          4.761287   \n",
      "\n",
      "   Movie_ID  \n",
      "0      3962  \n",
      "1      1905  \n",
      "2      2452  \n",
      "3      4306  \n",
      "4       571  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Test the recommendation function (Item-Based)\n",
    "user_id_to_test = 774868  # Cambia l'ID utente se necessario\n",
    "num_recommendations = 5\n",
    "\n",
    "try:\n",
    "    # Genera raccomandazioni usando il metodo Item-Based\n",
    "    item_based_recommendations = recommend_movies_item_based(\n",
    "        user_id=user_id_to_test,\n",
    "        train_matrix=sparse_item_user,\n",
    "        item_index=movie_index,\n",
    "        user_index=user_index,\n",
    "        movies=movies,\n",
    "        num_recommendations=num_recommendations,\n",
    "        k=10\n",
    "    )\n",
    "\n",
    "    # Stampa le raccomandazioni\n",
    "    print(f\"Top {num_recommendations} movie recommendations for User {user_id_to_test} (Item-Based):\")\n",
    "    print(item_based_recommendations[['Name', 'Year', 'Estimated_Rating', 'Movie_ID']])\n",
    "\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation of the Model\n",
    "\n",
    "To assess the effectiveness of the collaborative filtering approach, we perform a train-test split on the ratings data. The evaluation process includes:\n",
    "\n",
    "1. **Train-Test Split**:  \n",
    "   - 80% of the data is used for training the model.\n",
    "   - 20% of the data is reserved for testing.\n",
    "\n",
    "2. **Predictions and Metrics**:  \n",
    "   - For each user in the test set, the model predicts ratings for movies based on the nearest neighbors identified in the training data.\n",
    "   - **Mean Absolute Error (MAE)** is calculated as the primary metric to evaluate prediction accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_ID\n",
      "305344     1344\n",
      "387418     1339\n",
      "2439493    1324\n",
      "2118461    1305\n",
      "1664010    1257\n",
      "716173     1169\n",
      "1314869    1132\n",
      "2056022    1072\n",
      "1852040    1053\n",
      "2606799    1039\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calcola il numero di valutazioni per ogni utente\n",
    "user_ratings_count = user_item_matrix.apply(lambda row: (row > 0).sum(), axis=1)\n",
    "\n",
    "# Ordina gli utenti per numero di valutazioni, in ordine decrescente\n",
    "top_users = user_ratings_count.sort_values(ascending=False)\n",
    "\n",
    "# Mostra i primi 10 utenti con più valutazioni\n",
    "print(top_users.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision @ K: 0.011904761904761904\n",
      "Recall @ K: 0.09259259259259259\n",
      "Accuracy @ K: 0.010660980810234541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def evaluate_user_based_recommendation(user_id, train_matrix, user_index, movie_index, movies, num_recommendations=5, k=10):\n",
    "    \"\"\"\n",
    "    Valuta il modello di raccomandazione con metriche di precisione, recall e accuracy @ K.\n",
    "    \"\"\"\n",
    "    # Verifica che l'utente esista nel dataset\n",
    "    if user_id not in user_index:\n",
    "        raise ValueError(\"User ID not found in the dataset\")\n",
    "    \n",
    "    # Ottieni l'indice interno dell'utente\n",
    "    user_idx = user_index[user_id]\n",
    "    user_ratings = train_matrix[user_idx].toarray().flatten()  # Recupera le valutazioni dell'utente come array\n",
    "    rated_movie_indices = np.where(user_ratings > 0)[0]  # Indici dei film valutati dall'utente\n",
    "\n",
    "    # Considera come \"rilevanti\" i film con una valutazione maggiore di 3\n",
    "    relevant_movie_indices = rated_movie_indices[user_ratings[rated_movie_indices] > 3]\n",
    "\n",
    "    # Nascondi le valutazioni dei film rilevanti nella matrice di test\n",
    "    test_matrix = train_matrix.copy()\n",
    "    test_matrix[user_idx, relevant_movie_indices] = 0\n",
    "\n",
    "    # Genera raccomandazioni per l'utente\n",
    "    recommendations = recommend_movies_user_based(user_id, test_matrix, user_index, movie_index, movies, num_recommendations, k)\n",
    "\n",
    "    # Ottieni gli ID dei film raccomandati\n",
    "    recommended_movie_ids = recommendations['Movie_ID'].tolist()\n",
    "\n",
    "    # Filtro per gestire eventuali ID non trovati in movie_index\n",
    "    recommended_movie_indices = [\n",
    "        movie_index[movie_id] for movie_id in recommended_movie_ids if movie_id in movie_index\n",
    "    ]\n",
    "\n",
    "    # Calcola precision, recall e accuracy @ K\n",
    "    true_positives = len(set(recommended_movie_indices) & set(relevant_movie_indices))  # Film raccomandati e rilevanti\n",
    "    precision_at_k = true_positives / len(recommended_movie_indices) if len(recommended_movie_indices) > 0 else 0\n",
    "    recall_at_k = true_positives / len(relevant_movie_indices) if len(relevant_movie_indices) > 0 else 0\n",
    "    accuracy_at_k = true_positives / len(set(recommended_movie_indices) | set(relevant_movie_indices)) if len(set(recommended_movie_indices) | set(relevant_movie_indices)) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"precision_at_k\": precision_at_k,\n",
    "        \"recall_at_k\": recall_at_k,\n",
    "        \"accuracy_at_k\": accuracy_at_k,\n",
    "    }\n",
    "\n",
    "# Test della funzione di valutazione\n",
    "user_id = 387418  # ID di un utente esistente\n",
    "metrics = evaluate_user_based_recommendation(\n",
    "    user_id=user_id,\n",
    "    train_matrix=sparse_user_item,\n",
    "    user_index=user_index,\n",
    "    movie_index=movie_index,\n",
    "    movies=movies,\n",
    "    num_recommendations=1000\n",
    ")\n",
    "\n",
    "print(f\"Precision @ K: {metrics['precision_at_k']}\")\n",
    "print(f\"Recall @ K: {metrics['recall_at_k']}\")\n",
    "print(f\"Accuracy @ K: {metrics['accuracy_at_k']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Movies: 100%|██████████| 174/174 [01:18<00:00,  2.22movie/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision @ K: 0.09090909090909091\n",
      "Recall @ K: 0.024539877300613498\n",
      "Accuracy @ K: 0.019704433497536946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_item_based_recommendation(user_id, train_matrix, user_index, item_index, movies, num_recommendations=5, k=10):\n",
    "    \"\"\"\n",
    "    Valuta il modello di raccomandazione basato sugli item con metriche di precisione, recall e accuracy @ K.\n",
    "    \"\"\"\n",
    "    # Verifica che l'utente esista nel dataset\n",
    "    if user_id not in user_index:\n",
    "        raise ValueError(\"User ID not found in the dataset\")\n",
    "    \n",
    "    # Ottieni l'indice interno dell'utente\n",
    "    user_idx = user_index[user_id]\n",
    "    user_ratings = train_matrix[:, user_idx].toarray().flatten()  # Recupera le valutazioni dell'utente come array\n",
    "    rated_movie_indices = np.where(user_ratings > 0)[0]  # Indici dei film valutati dall'utente\n",
    "\n",
    "    # Considera come \"rilevanti\" i film con una valutazione maggiore di 3\n",
    "    relevant_movie_indices = rated_movie_indices[user_ratings[rated_movie_indices] > 3]\n",
    "\n",
    "    # Nascondi le valutazioni dei film rilevanti nella matrice di test\n",
    "    test_matrix = train_matrix.copy()\n",
    "    test_matrix[relevant_movie_indices, user_idx] = 0\n",
    "\n",
    "    # Genera raccomandazioni per l'utente\n",
    "    recommendations = recommend_movies_item_based(user_id, test_matrix, item_index, user_index, movies, num_recommendations, k)\n",
    "\n",
    "    # Ottieni gli ID dei film raccomandati\n",
    "    recommended_movie_ids = recommendations['Movie_ID'].tolist()\n",
    "\n",
    "    # Filtro per gestire eventuali ID non trovati in item_index\n",
    "    recommended_movie_indices = [\n",
    "        item_index[movie_id] for movie_id in recommended_movie_ids if movie_id in item_index\n",
    "    ]\n",
    "\n",
    "    # Calcola precision, recall e accuracy @ K\n",
    "    true_positives = len(set(recommended_movie_indices) & set(relevant_movie_indices))  # Film raccomandati e rilevanti\n",
    "    precision_at_k = true_positives / len(recommended_movie_indices) if len(recommended_movie_indices) > 0 else 0\n",
    "    recall_at_k = true_positives / len(relevant_movie_indices) if len(relevant_movie_indices) > 0 else 0\n",
    "    accuracy_at_k = true_positives / len(set(recommended_movie_indices) | set(relevant_movie_indices)) if len(set(recommended_movie_indices) | set(relevant_movie_indices)) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"precision_at_k\": precision_at_k,\n",
    "        \"recall_at_k\": recall_at_k,\n",
    "        \"accuracy_at_k\": accuracy_at_k,\n",
    "    }\n",
    "\n",
    "# Test della funzione di valutazione\n",
    "user_id = 387418  # ID di un utente esistente\n",
    "metrics = evaluate_item_based_recommendation(\n",
    "    user_id=user_id,\n",
    "    train_matrix=sparse_item_user,\n",
    "    user_index=user_index,\n",
    "    item_index=movie_index,\n",
    "    movies=movies,\n",
    "    num_recommendations=1000\n",
    ")\n",
    "\n",
    "print(f\"Precision @ K: {metrics['precision_at_k']}\")\n",
    "print(f\"Recall @ K: {metrics['recall_at_k']}\")\n",
    "print(f\"Accuracy @ K: {metrics['accuracy_at_k']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This notebook demonstrated the implementation of a collaborative filtering approach for recommending movies. Key takeaways include:\n",
    "\n",
    "- The model effectively utilizes user similarity to make recommendations, as shown by the ability to generate relevant suggestions for a sample user.\n",
    "- The **MAE metric** provides a reliable evaluation of the model's predictive accuracy.\n",
    "- While collaborative filtering is powerful, it faces challenges such as:\n",
    "  - **Cold Start Problem**: Difficulty in recommending movies for new users or items.\n",
    "  - **Data Sparsity**: Limited interactions in the dataset can affect similarity computations.\n",
    "\n",
    "### Future Improvements\n",
    "\n",
    "To address the limitations, potential enhancements include:\n",
    "\n",
    "- Implementing hybrid recommendation systems that combine collaborative and content-based filtering.\n",
    "- Exploring matrix factorization techniques (e.g., Singular Value Decomposition).\n",
    "- Integrating deep learning-based recommendation methods.\n",
    "\n",
    "This collaborative filtering approach forms a solid foundation for building scalable and effective recommendation systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
