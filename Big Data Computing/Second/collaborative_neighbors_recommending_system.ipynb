{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Neighborhood-Based Filtering for Movie Recommendations\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Collaborative neighborhood-based filtering is a popular approach in recommendation systems that leverages user-item interactions to predict user preferences based on the preferences of users who are similar to the target user and the items that the target user has already rated. There are two main types of collaborative filtering:\n",
    "\n",
    "- **User-Based Collaborative Filtering**: Recommends items based on the preferences of users who are similar to the target user.\n",
    "- **Item-Based Collaborative Filtering**: Suggests items that are similar to those the user has already rated positively.\n",
    "\n",
    "In this notebook, we will explore both approaches for movie recommendations.\n",
    "\n",
    "## Dataset Description\n",
    "We use two datasets for this analysis:\n",
    "1. **Movies Dataset**:\n",
    "   - `Movie_ID`: Unique identifier for each movie.\n",
    "   - `Name`: Title of the movie.\n",
    "   - `Year`: Release year of the movie.\n",
    "\n",
    "2. **Ratings Dataset**:\n",
    "   - `User_ID`: Unique identifier for each user.\n",
    "   - `Movie_ID`: Identifier for the movie rated.\n",
    "   - `Rating`: Numeric rating given by the user (e.g., on a scale of 1-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load the dataset\n",
    "ratings = pd.read_csv(\"./data/Netflix_Dataset_Rating.csv\")  # Columns: User_ID, Rating, Movie_ID\n",
    "movies  = pd.read_csv(\"./data/Netflix_Dataset_Movie.csv\")    # Columns: Movie_ID, Year, Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formal Definition\n",
    "\n",
    "- $U = \\{u_1, u_2, \\dots, u_n\\}$ is the set of users.\n",
    "- $U_i = \\{u \\in U \\mid r_{u,i} \\neq 0\\}$ is the set of users who have rated item $i$\n",
    "- $I = \\{i_1, i_2, \\dots, i_m\\}$ is the set of items.\n",
    "- $I_u = \\{i \\in I \\mid r_{u,i} \\neq 0\\}$ is the set of items rated by user $u$\n",
    "- $R = \\{0, 1, \\dots, 5\\} \\lor R = [0, 1]$ is the set of ratings.\n",
    "- $r_{u,i}$ is the rating given by user $u$ for item $i$ (equal to 0 if not rated)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Based Collaborative Filtering\n",
    "\n",
    "### 1. Data Preprocessing\n",
    "- **User-Item Matrix Creation**: Convert the ratings dataset into a user-item matrix, where rows represent users and columns represent movies. Missing ratings are filled with zeros. Each rating is represented by a number from 1 to 5.\n",
    "  $$ M[u, i] = r_{u,i} \\in R$$\n",
    "  Where:\n",
    "  - $u \\in U$\n",
    "  - $i \\in I$.\n",
    "\n",
    "- **Sparse Matrix Conversion**: The dense matrix is converted to a sparse format for memory optimization:\n",
    "  $$M_{\\{\\text{sparse}\\}} = \\text{sparse}(M)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a user-item matrix\n",
    "user_item_matrix = ratings.pivot(index='User_ID', columns='Movie_ID', values='Rating')\n",
    "\n",
    "# Fill missing values with 0 (can use NaN for some algorithms)\n",
    "user_item_matrix.fillna(0, inplace=True) # It is not the case for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Collaborative Filtering Model\n",
    "We use the `scikit-learn` library to implement a KNN-based model:\n",
    "\n",
    "1. **Similarity Metric**: Cosine similarity is used to identify users with similar rating patterns. The formula for cosine similarity between two users $u$ and $v$ is:\n",
    "   $$\n",
    "   \\text{sim}(u, v) = \\frac{\\vec r_u \\cdot \\vec r_v}{\\|\\vec r_u\\| \\cdot \\|\\vec r_v\\|}\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\vec r_u$ and $\\vec r_v$ are column vectors of ratings for users $u$ and $v$ respectively (the $u$-th and $v$-th rows of the user-item matrix).\n",
    "   - $\\cdot$ represents the dot product.\n",
    "\n",
    "2. **Nearest Neighbors**: The model identifies the top $k$ nearest neighbors for each user, based on the similarity scores:\n",
    "   $$\\large\n",
    "   \\mathcal{N}_u^k = \\argmax_{U' \\subseteq U \\setminus \\{u\\} \\land |U'| = k} \\sum_{v \\in U'} \\text{sim}(u, v)\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\mathcal N_u^k$ is the set of the top $k$ nearest neighbors for user $u$.\n",
    "   - $U'$ is a subset of users excluding $u$.\n",
    "   - $k = 10$ (default value in this implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build the collaborative filtering model\n",
    "model_knn_user = NearestNeighbors(metric='cosine', algorithm='brute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Recommendation Function (User-Based)\n",
    "\n",
    "In the user-based collaborative filtering approach, the recommendation function operates as follows:\n",
    "\n",
    "1. **Get all relevant items**: The set of items rated by the top $k$ nearest neighbors for user $u$:\n",
    "   $$\\large\n",
    "   I^k = \\{i \\in I \\setminus I_u \\mid \\exists v \\in \\mathcal N_u^k : r_{v,i} \\neq 0\\}\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\mathcal N_u^k$ is the set of the top $k$ nearest neighbors for user $u$.\n",
    "   - $I^k$ is the set of items rated by the top $k$ nearest neighbors for user $u$ and not already rated by $u$.\n",
    "   - $k = 10$ (default value in this implementation).\n",
    "\n",
    "2. **Prediction Formula**: For a given user $u$, the set of predicted ratings for items $i \\in I^k$ is calculated as:\n",
    "   $$\\large\n",
    "   I^k_u = \\{\\hat{r}_{u,i} \\mid i \\in I^k\\} \\quad \\text{where} \\quad\n",
    "   \\hat{r}_{u,i} = \\frac{\\sum_{v \\in \\mathcal N_u^k} \\text{sim}(u, v) \\cdot r_{v,i}}{\\sum_{v \\in \\mathcal N_u^k} \\text{sim}(u, v)}\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\hat{r}_{u,i}$ is the predicted rating for user $u$ on item $i$.\n",
    "   - $r_{v,i}$ is the rating of neighbor $v \\in \\mathcal N_u^k$ for item $i$.\n",
    "   - $\\text{sim}(u, v)$ is the similarity between users $u$ and $v$.\n",
    "\n",
    "This combination of steps allows the model to efficiently generate user-based collaborative filtering recommendations using nearest neighbors. This approach works well in cases where users with similar preferences exist in the dataset. For example, if two users have rated several movies similarly, the model assumes they will likely share preferences for other movies as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define a rating and a recommendation function\n",
    "def recommend_movies_user_based(user_id, train_matrix, user_index, item_index, num_recommendations=None, k=10):\n",
    "    \"\"\"\n",
    "    Recommend movies using user-based collaborative filtering.\n",
    "\n",
    "    Parameters:\n",
    "        user_id (int): ID of the user for whom to generate recommendations.\n",
    "        train_matrix (csr_matrix): Sparse user-item matrix (rows = users, columns = movies).\n",
    "        user_index (dict): Maps user IDs to row indices in the train_matrix.\n",
    "        item_index (dict): Maps column indices in the train_matrix to movie IDs.\n",
    "        movies (pd.DataFrame): DataFrame with movie metadata (columns: Movie_ID, Year, Name).\n",
    "        num_recommendations (int, optional): Number of recommendations to return. Defaults to None (all).\n",
    "        k (int, optional): Number of nearest neighbors to consider. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with recommended movies (columns: ['Movie_ID', 'Name', 'Year', 'Estimated_Rating']).\n",
    "    \"\"\"\n",
    "    if user_id not in user_index:\n",
    "        raise ValueError(f\"User ID {user_id} not found in the dataset\")\n",
    "    \n",
    "    # Transform into a sparse matrix\n",
    "    train_matrix = csr_matrix(train_matrix.values)\n",
    "\n",
    "    # Identify user index and retrieve their vector\n",
    "    user_idx = user_index[user_id]\n",
    "    user_vector = train_matrix[user_idx]\n",
    "\n",
    "    # Fit the KNN model and find neighbors\n",
    "    model_knn_user.fit(train_matrix)\n",
    "    distances, indices = model_knn_user.kneighbors(user_vector, n_neighbors=k + 1)\n",
    "\n",
    "    # Process neighbors (exclude the user itself)\n",
    "    neighbors, similarity_scores = indices.flatten()[1:], 1 - distances.flatten()[1:]\n",
    "\n",
    "    # Compute weighted ratings and normalize\n",
    "    similar_users_ratings = train_matrix[neighbors].toarray()\n",
    "    weighted_ratings = similar_users_ratings.T @ similarity_scores\n",
    "    normalization = similarity_scores.sum()\n",
    "    mean_ratings = weighted_ratings / normalization\n",
    "\n",
    "    # Filter out already rated movies\n",
    "    mean_ratings[user_vector.indices] = 0\n",
    "\n",
    "    # Rank movies by estimated ratings\n",
    "    top_indices = np.argsort(mean_ratings)[::-1]\n",
    "    if num_recommendations:\n",
    "        top_indices = top_indices[:num_recommendations]\n",
    "\n",
    "    # Map indices back to movie IDs and retrieve metadata\n",
    "    recommendations = pd.DataFrame({\n",
    "        'Movie_ID': [item_index[idx] for idx in top_indices],\n",
    "        'Estimated_Rating': mean_ratings[top_indices]\n",
    "    })\n",
    "    recommendations = recommendations.merge(movies, on='Movie_ID')[['Movie_ID', 'Name', 'Year', 'Estimated_Rating']]\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Testing (User-Based)\n",
    "The function is tested with a sample user to generate personalized recommendations (User-Based)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 movie recommendations for User 305344:\n",
      "             Name  Year  Estimated_Rating  Movie_ID\n",
      "0  Doctor Zhivago  1965          4.211178      3153\n",
      "1         Hackers  1995          3.834992      3680\n",
      "2             Ray  2004          3.648459       886\n",
      "3      The Rookie  1990          3.424174      2251\n",
      "4        Sideways  2004          3.339992      3282\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Test the recommendation function\n",
    "user_id_to_test = 305344  # User ID for which to generate recommendations\n",
    "num_recommendations = 5\n",
    "\n",
    "# Create dictionaries to map user IDs and movie IDs to matrix indices\n",
    "user_index = {user_id: idx for idx, user_id in enumerate(user_item_matrix.index)}\n",
    "movie_index = {idx: movie_id for idx, movie_id in enumerate(user_item_matrix.columns)}\n",
    "\n",
    "try:\n",
    "    # Generate recommendations for the specified user\n",
    "    user_based_recommendations = recommend_movies_user_based(\n",
    "        user_id=user_id_to_test,\n",
    "        train_matrix=user_item_matrix,\n",
    "        user_index=user_index,\n",
    "        item_index=movie_index,\n",
    "        num_recommendations=num_recommendations,\n",
    "        k=10\n",
    "    )\n",
    "    \n",
    "    # Display recommendations\n",
    "    print(f\"Top {num_recommendations} movie recommendations for User {user_id_to_test}:\")\n",
    "    print(user_based_recommendations[['Name', 'Year', 'Estimated_Rating', 'Movie_ID']])\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-Based Collaborative Filtering\n",
    "\n",
    "### 1. Data Preprocessing\n",
    "- **Item-User Matrix Creation**: Transpose the user-item matrix $M$ to create a new matrix $M' = M^T$, where rows represent movies and columns represent users. Missing ratings are filled with zeros.\n",
    "  $$ M'[i, u] = M[u, i] = r_{u,i} \\in R$$\n",
    "- **Sparse Matrix Conversion**: The dense matrix is converted to a sparse format to optimize memory usage.\n",
    "  $$M'_{\\{\\text{sparse}\\}} = \\text{csr\\_matrix}(M')$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Transpose the user-item matrix\n",
    "item_user_matrix = user_item_matrix.T\n",
    "\n",
    "# Convert the DataFrame to a sparse matrix\n",
    "sparse_item_user = csr_matrix(item_user_matrix.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Collaborative Filtering Model (Item-Based)\n",
    "We use the `scikit-learn` library to implement a KNN-based model:\n",
    "\n",
    "1. **Similarity Metric**: Cosine similarity is used to identify movies with similar rating patterns. The formula for cosine similarity between two movies $i$ and $j$ is:\n",
    "   $$\n",
    "   \\text{sim}(i, j) = \\frac{\\vec r_i \\cdot \\vec r_j}{\\|\\vec r_i\\| \\cdot \\|\\vec r_j\\|}\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\vec r_i$ and $\\vec r_j$ are column vectors of user ratings for movies $i$ and $j$ respectively (the $i$-th and $j$-th rows of the item-user matrix $M'$).\n",
    "   - $\\cdot$ represents the dot product.\n",
    "\n",
    "2. **Nearest Neighbors**: The model identifies the top $k$ nearest neighbors for each movie $i \\in I \\setminus I_u$ based on similarity scores:\n",
    "   $$\\large\n",
    "   \\mathcal{N}_i^k = \\argmax_{I'_u \\subseteq I_u \\setminus \\{i\\} \\land |I'_u| = k} \\sum_{j \\in I'_u} \\text{sim}(i, j)\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\mathcal N_i^k$ is the set of the top $k$ nearest movies (in the user $u$ rated movies set) for movie $i$.\n",
    "   - $I'_u$ is a subset, of size $k$, of items rated by user $u$ that excludes movie $i$, obviously.\n",
    "   - $k = 10$ (default value in this implementation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Recommendation Function (Item-Based)\n",
    "\n",
    "In the item-based collaborative filtering approach, the recommendation function works as follows:\n",
    "\n",
    "Predict movie ratings for the target user $u$ by aggregating ratings from similar movies (not already rated by $u$) to the already rated ones. For a given user $u$ and a set of items not yet rated by $u$, the predicted rating is calculated as:\n",
    "   $$\\large\n",
    "   I^k_u = \\{\\hat{r}_{u,i} \\mid i \\in I \\setminus I_u \\setminus \\{i\\}\\} \\quad \\text{where} \\quad\n",
    "   \\hat{r}_{u,i} = \\frac{\\sum_{j \\in \\mathcal N_i^k} \\text{sim}(i, j) \\cdot r_{u,j}}{\\sum_{j \\in \\mathcal N_i^k} \\text{sim}(i, j)}\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\hat{r}_{u,i}$ is the predicted rating for user $u$ on item $i$.\n",
    "   - $r_{u,j}$ is the rating of user $u$ for a similar item $j \\in \\mathcal N_i^k$.\n",
    "   - $\\text{sim}(i, j)$ is the similarity between items $i$ and $j$.\n",
    "   - $\\mathcal N_i^k$ is the set of the top $k$ most similar items to $i$.\n",
    "   - $I^k_u$ is the set of predicted ratings for user $u$ on items not yet rated by $u$.\n",
    "\n",
    "Thus, for each movie not rated by the target user, the model calculates a weighted average of similar movies' ratings based on their similarity scores. The predicted ratings are then sorted and the top are returned.\n",
    "\n",
    "For accuracy reasons, the predicted rating will be sorted by $\\sum_{j \\in \\mathcal N_i^k} \\text{sim}(i, j) \\cdot r_{u,j}$ and not by $\\hat{r}_{u,i}$. This smply because when we divide by $\\sum_{j \\in \\mathcal N_i^k} \\text{sim}(i, j)$ we are not considering the similarity scores anymore, and this is not an optimal approach since we want that movies that are closer to already rated ones have an higher weight in the rating estimation. \n",
    "\n",
    "This method leverages the user's own preferences and the similarity relationships between movies, providing relevant and personalized suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Recommendation Function (Item-Based)\n",
    "from tqdm import tqdm\n",
    "\n",
    "def recommend_movies_item_based(user_id, train_matrix, item_index, user_index, num_recommendations=None, k=10):\n",
    "    \"\"\"\n",
    "    Recommend movies using item-based collaborative filtering for a given user.\n",
    "    This is an optimized version that maintains the same functionality as the original.\n",
    "    \n",
    "    Args:\n",
    "        user_id (int): The ID of the user for whom to make recommendations.\n",
    "        train_matrix (csr_matrix): The sparse matrix of item-user ratings.\n",
    "        item_index (dict): A mapping of item IDs to their index in the matrix.\n",
    "        user_index (dict): A mapping of user IDs to their index in the matrix.\n",
    "        num_recommendations (int): The number of movies to recommend. Default is 5.\n",
    "        k (int): The number of neighbors to consider in KNN. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame of recommended movies with their estimated ratings.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the user ID is not found in the dataset or if the user has not rated any movies.\n",
    "    \"\"\"\n",
    "\n",
    "    # Transform into s sparse matrix\n",
    "    train_matrix = csr_matrix(train_matrix.T.values)\n",
    "    \n",
    "    # Check if the user exists in the dataset\n",
    "    if user_id not in user_index:\n",
    "        raise ValueError(\"User ID not found in the dataset\")\n",
    "\n",
    "    # Get the internal index of the user\n",
    "    user_idx = user_index[user_id]\n",
    "    # Get the user's ratings as a flattened numpy array\n",
    "    user_ratings = train_matrix[:, user_idx].toarray().flatten()\n",
    "    # Get the indices of movies that the user has rated\n",
    "    rated_movie_indices = np.where(user_ratings > 0)[0]\n",
    "\n",
    "    # Check if the user has rated any movies\n",
    "    if len(rated_movie_indices) == 0:\n",
    "        raise ValueError(\"User has not rated any movies\")\n",
    "\n",
    "    # Initialize the KNN model\n",
    "    model_knn_item = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "\n",
    "    # Train the model using only the rated items\n",
    "    sparse_item_user_u = train_matrix[rated_movie_indices, :]\n",
    "    model_knn_item.fit(sparse_item_user_u)\n",
    "\n",
    "    # Find movies that the user has not rated\n",
    "    not_rated_movie_indices = np.where(user_ratings == 0)[0]\n",
    "\n",
    "    movie_scores = {} # Initialize the movie score dictionary\n",
    "\n",
    "    # Iterate over movies that the user has not rated\n",
    "    for movie_idx in tqdm(not_rated_movie_indices, desc=\"Processing Movies\", unit=\"movie\"):\n",
    "        \n",
    "        # Get the feature vector for the current movie\n",
    "        movie_vector = train_matrix[movie_idx, :]\n",
    "        # Find the k-nearest neighbors to the movie\n",
    "        distances, indices = model_knn_item.kneighbors(movie_vector, n_neighbors=k)\n",
    "        # Calculate the similarity scores (1 - cosine distance)\n",
    "        similarity_scores = 1 - distances.flatten()\n",
    "        # Get the indices of similar movies that the user has rated\n",
    "        similar_movies = rated_movie_indices[indices.flatten()]\n",
    "        # Get the ratings of similar movies from the user\n",
    "        user_ratings_for_similar = user_ratings[similar_movies]\n",
    "        \n",
    "        # Calculate the weighted score by multiplying similarity scores with user ratings\n",
    "        weighted_score = np.dot(similarity_scores, user_ratings_for_similar)\n",
    "        # Sum of the similarity scores\n",
    "        sum_similarity_scores = np.sum(similarity_scores)\n",
    "\n",
    "        # If sum of the similarity score is > 0, add the weighted score and sum to the dictionary\n",
    "        if sum_similarity_scores > 0:\n",
    "            movie_scores[movie_idx] = [weighted_score, sum_similarity_scores]\n",
    "\n",
    "    # Sort the movies based on their weighted score, and take the top num_recommendations\n",
    "    recommended_movie_indices = sorted(movie_scores.items(), key=lambda x: x[1][0], reverse=True)\n",
    "\n",
    "    # Get the top movies (if num_recommendations is specified)\n",
    "    if num_recommendations:\n",
    "        recommended_movie_indices = recommended_movie_indices[:num_recommendations]\n",
    "\n",
    "    # Convert the movie indices to movie IDs and calculate the estimated ratings\n",
    "    recommended_movies = [(item_index[movie_idx], score[0] / score[1]) for movie_idx, score in recommended_movie_indices]\n",
    "    \n",
    "    # Create a pandas DataFrame from the recommended movies\n",
    "    recommended_movies_df = pd.DataFrame(sorted(recommended_movies, key=lambda x: x[1], reverse=True), columns=['Movie_ID', 'Estimated_Rating'])\n",
    "    # Merge the recommended movie DataFrame with the movie DataFrame to get movie details\n",
    "    recommendations = recommended_movies_df.merge(movies, on='Movie_ID')[['Movie_ID', 'Name', 'Year', 'Estimated_Rating']]\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Testing\n",
    "The function is tested with a sample user to generate personalized recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Movies: 100%|██████████| 1331/1331 [00:09<00:00, 146.19movie/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 movie recommendations for User 774868 (Item-Based):\n",
      "                                                Name  Year  Estimated_Rating  \\\n",
      "0                          Finding Nemo (Widescreen)  2003          4.817077   \n",
      "1  Pirates of the Caribbean: The Curse of the Bla...  2003          4.816355   \n",
      "2      Lord of the Rings: The Fellowship of the Ring  2001          4.809336   \n",
      "3                                    The Sixth Sense  1999          4.808670   \n",
      "4                                    American Beauty  1999          4.761287   \n",
      "\n",
      "   Movie_ID  \n",
      "0      3962  \n",
      "1      1905  \n",
      "2      2452  \n",
      "3      4306  \n",
      "4       571  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Test the recommendation function (Item-Based)\n",
    "user_id_to_test = 774868  # Cambia l'ID utente se necessario\n",
    "num_recommendations = 5\n",
    "\n",
    "# Genera raccomandazioni usando il metodo Item-Based\n",
    "item_based_recommendations = recommend_movies_item_based(\n",
    "    user_id=user_id_to_test,\n",
    "    train_matrix=user_item_matrix,\n",
    "    item_index=movie_index,\n",
    "    user_index=user_index,\n",
    "    num_recommendations=num_recommendations,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "# Stampa le raccomandazioni\n",
    "print(f\"Top {num_recommendations} movie recommendations for User {user_id_to_test} (Item-Based):\")\n",
    "print(item_based_recommendations[['Name', 'Year', 'Estimated_Rating', 'Movie_ID']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation of the Model\n",
    "\n",
    "To assess the effectiveness of the collaborative filtering approach, we perform a train-test split on the ratings data. The evaluation process includes:\n",
    "\n",
    "1. **Train-Test Split**:  \n",
    "   - 80% of the data is used for training the model.\n",
    "   - 20% of the data is reserved for testing.\n",
    "\n",
    "2. **Predictions and Metrics**:  \n",
    "   - For each user in the test set, the model predicts ratings for movies based on the nearest neighbors identified in the training data.\n",
    "   - **Mean Absolute Error (MAE)** is calculated as the primary metric to evaluate prediction accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Processed |██████████████████████████████████████████████████| 100.0% Complete\n",
      "MAE (User-Based): 1.8283969653997267\n",
      "RMSE (User-Based): 0.7185450272327487\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def print_progress_bar(iteration, total, prefix='', suffix='', decimals=1, length=50, fill='█'):\n",
    "    \"\"\"\n",
    "    Print a manual progress bar in the terminal.\n",
    "    \"\"\"\n",
    "    percent = f\"{100 * (iteration / float(total)):.{decimals}f}\"\n",
    "    filled_length = int(length * iteration // total)\n",
    "    bar = fill * filled_length + '-' * (length - filled_length)\n",
    "    sys.stdout.write(f'\\r{prefix} |{bar}| {percent}% {suffix}')\n",
    "    sys.stdout.flush()\n",
    "    if iteration == total:\n",
    "        print()  # Print a new line on completion\n",
    "\n",
    "\n",
    "def evaluate_recommendation_system(recommendation_function, train_matrix, test_size=0.2, k=10, users_to_test=10):\n",
    "    \"\"\"\n",
    "    Evaluate a recommendation system using the Mean Absolute Error (MAE) metric.\n",
    "    Includes a manual progress bar for tracking progress.\n",
    "\n",
    "    Parameters:\n",
    "        recommendation_function (function): The recommendation function to evaluate.\n",
    "        train_matrix (pd.DataFrame): The user-item matrix.\n",
    "        user_index (dict): Mapping of user IDs to matrix indices.\n",
    "        movie_index (dict): Mapping of movie IDs to matrix indices.\n",
    "        test_size (float): The proportion of data to use for testing. Defaults to 0.2.\n",
    "        k (int): The number of recommendations to generate. Defaults to 10.\n",
    "        users_to_test (int): Number of users to test. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        float: The Mean Absolute Error (MAE) of the recommendation system.\n",
    "    \"\"\"\n",
    "    def get_indexes_of_active_users(train_matrix):\n",
    "        # Count non-zero ratings for each user\n",
    "        user_counts = (train_matrix != 0).sum(axis=1)\n",
    "        return user_counts[(user_counts >= 50)].index\n",
    "\n",
    "    def get_random_user_indexes(users_to_test, train_matrix):\n",
    "        # Randomly sample active users\n",
    "        return np.random.choice(get_indexes_of_active_users(train_matrix), size=users_to_test, replace=False)\n",
    "\n",
    "    def get_random_rated_movies(user, train_matrix):\n",
    "        # Randomly sample rated movies for a given user\n",
    "        rated_movies = train_matrix.loc[user][train_matrix.loc[user] > 0].index\n",
    "        selected_rated_movies = np.random.choice(rated_movies, size=int(len(rated_movies) * test_size), replace=False)\n",
    "        return {movie: train_matrix.loc[user, movie] for movie in selected_rated_movies}\n",
    "\n",
    "    mae  = 0\n",
    "    rmse = 0\n",
    "\n",
    "    # Randomly select users and their rated movies\n",
    "    random_user_item = {\n",
    "        user_id: get_random_rated_movies(user_id, train_matrix) for user_id in get_random_user_indexes(users_to_test, train_matrix)\n",
    "    }\n",
    "\n",
    "    # Remove empty movie lists\n",
    "    random_user_item = {key: value for key, value in random_user_item.items() if value}\n",
    "\n",
    "    total_users = len(random_user_item)\n",
    "    user_count = 0\n",
    "\n",
    "    recomendations_list = []\n",
    "    random_rated_movies_list = []\n",
    "\n",
    "    # Iterate over users\n",
    "    for user_id, random_rated_movies in random_user_item.items():\n",
    "        user_count += 1\n",
    "\n",
    "        # Print the progress for users\n",
    "        print_progress_bar(user_count, total_users, prefix=\"Users Processed\", suffix=\"Complete\")\n",
    "\n",
    "        if not random_rated_movies:\n",
    "            continue\n",
    "\n",
    "        # Temporarily set ratings for selected movies to 0\n",
    "        for movie_id in random_rated_movies.keys():\n",
    "            user_idx = user_index[user_id]\n",
    "            movie_idx = user_item_matrix.columns.get_loc(movie_id)\n",
    "            train_matrix.iloc[user_idx, movie_idx] = 0\n",
    "\n",
    "        # Generate recommendations for the user\n",
    "        recommendations = recommendation_function(\n",
    "            user_id=user_id,\n",
    "            train_matrix=train_matrix,\n",
    "            user_index=user_index,\n",
    "            item_index=movie_index,\n",
    "            k=k\n",
    "        )\n",
    "\n",
    "        # Restore the original train matrix\n",
    "        for movie_id, rating in random_rated_movies.items():\n",
    "            user_idx = user_index[user_id]\n",
    "            movie_idx = user_item_matrix.columns.get_loc(movie_id)\n",
    "            train_matrix.iloc[user_idx, movie_idx] = rating\n",
    "        \n",
    "        # Calculate the Mean Absolute Error (MAE)\n",
    "        mae_tmp  = 0\n",
    "        rmse_tmp = 0\n",
    "\n",
    "        for movie_id, rating in random_rated_movies.items():\n",
    "            # Get the estimated rating for the movie\n",
    "            estimated_rating = recommendations.loc[recommendations['Movie_ID'] == movie_id, 'Estimated_Rating'].values[0]\n",
    "            # Update the MAE_tmp\n",
    "            mae_tmp  += np.abs(rating - estimated_rating)\n",
    "            rmse_tmp += (rating - estimated_rating)**2\n",
    "\n",
    "            #print(movie_id, rating, estimated_rating)\n",
    "\n",
    "        # Normalize the MAE_tmp by the number of rated movies\n",
    "        mae_tmp /= len(random_rated_movies)\n",
    "        mae += mae_tmp\n",
    "\n",
    "        rmse_tmp = rmse_tmp**0.5 / len(random_rated_movies)\n",
    "        rmse += rmse_tmp\n",
    "\n",
    "        #random_rated_movies_list.append(random_rated_movies)\n",
    "        #recomendations_list.append(recommendations)\n",
    "\n",
    "    # Return the average MAE\n",
    "    return mae / users_to_test, rmse / users_to_test #, recomendations_list, random_rated_movies_list\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "error_user_based = evaluate_recommendation_system(\n",
    "    recommend_movies_user_based,\n",
    "    train_matrix=user_item_matrix,\n",
    "    test_size=0.1,\n",
    "    k=10,\n",
    "    users_to_test=10\n",
    ")\n",
    "\n",
    "print(f\"MAE (User-Based): {error_user_based[0]}\")\n",
    "print(f\"RMSE (User-Based): {error_user_based[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Processed |█████████████████████████-------------------------| 50.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Movies: 100%|██████████| 1302/1302 [00:33<00:00, 39.44movie/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Processed |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Movies: 100%|██████████| 1202/1202 [03:24<00:00,  5.87movie/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Item-Based): 0.698911456974068\n",
      "RMSE (Item-Based): 0.17488502101362058\n"
     ]
    }
   ],
   "source": [
    "error_item_based = evaluate_recommendation_system(\n",
    "    recommend_movies_item_based,\n",
    "    train_matrix=user_item_matrix,\n",
    "    test_size=0.2,\n",
    "    k=10,\n",
    "    users_to_test=2\n",
    ")\n",
    "\n",
    "print(f\"MAE (Item-Based): {error_item_based[0]}\")\n",
    "print(f\"RMSE (Item-Based): {error_item_based[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Processed |██████████████████████████████████████████████████| 100.0% Complete\n",
      "User-Based Recommendation Metrics:\n",
      "Precision@K: 0.0910\n",
      "Recall@K: 0.7570\n",
      "F1-Score@K: 0.1522\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def print_progress_bar(iteration, total, prefix='', suffix='', decimals=1, length=50, fill='█'):\n",
    "    \"\"\"\n",
    "    Print a manual progress bar in the terminal.\n",
    "    \"\"\"\n",
    "    percent = f\"{100 * (iteration / float(total)):.{decimals}f}\"\n",
    "    filled_length = int(length * iteration // total)\n",
    "    bar = fill * filled_length + '-' * (length - filled_length)\n",
    "    sys.stdout.write(f'\\r{prefix} |{bar}| {percent}% {suffix}')\n",
    "    sys.stdout.flush()\n",
    "    if iteration == total:\n",
    "        print()  # Print a new line on completion\n",
    "\n",
    "def evaluate_recommendation_metrics(recommendation_function, train_matrix, k=10, at_k=10, test_size=0.2, users_to_test=10):\n",
    "    \"\"\"\n",
    "    Evaluate a recommendation system using Precision@K, Recall@K, and F1-Score@K.\n",
    "\n",
    "    Parameters:\n",
    "        recommendation_function (function): The recommendation function to evaluate.\n",
    "        train_matrix (pd.DataFrame): The user-item matrix.\n",
    "        k (int): Number of neighbors for the recommendation algorithm.\n",
    "        at_k (int): Number of recommendations to consider for metrics.\n",
    "        test_size (float): Proportion of rated items to hold out for testing.\n",
    "        users_to_test (int): Number of users to test.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the average Precision@K, Recall@K, and F1-Score@K.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_indexes_of_active_users(train_matrix):\n",
    "        user_counts = (train_matrix != 0).sum(axis=1)\n",
    "        return user_counts[(user_counts >= 50)].index\n",
    "\n",
    "    def get_random_user_indexes(users_to_test, train_matrix):\n",
    "        return np.random.choice(get_indexes_of_active_users(train_matrix), size=users_to_test, replace=False)\n",
    "\n",
    "    def get_random_rated_movies(user, train_matrix):\n",
    "        \"\"\"\n",
    "        Select the highest-rated movies for a given user as the test set.\n",
    "        \"\"\"\n",
    "        rated_movies = train_matrix.loc[user][train_matrix.loc[user] > 0]\n",
    "        rated_movies_sorted = rated_movies.sort_values(ascending=False)  # Sort by rating (descending)\n",
    "        num_test_movies = max(1, int(len(rated_movies) * test_size))  # Ensure at least 1 test movie\n",
    "        selected_rated_movies = np.random.choice(rated_movies_sorted.index[:num_test_movies], size=num_test_movies, replace=False)\n",
    "        return {movie: train_matrix.loc[user, movie] for movie in selected_rated_movies}\n",
    "\n",
    "    precision_sum = 0\n",
    "    recall_sum = 0\n",
    "    f1_sum = 0\n",
    "\n",
    "    # Randomly select users and their rated movies\n",
    "    random_user_item = {\n",
    "        user_id: get_random_rated_movies(user_id, train_matrix) for user_id in get_random_user_indexes(users_to_test, train_matrix)\n",
    "    }\n",
    "\n",
    "    # Remove empty movie lists\n",
    "    random_user_item = {key: value for key, value in random_user_item.items() if value}\n",
    "\n",
    "    total_users = len(random_user_item)\n",
    "    user_count = 0\n",
    "\n",
    "    for user_id, random_rated_movies in random_user_item.items():\n",
    "        user_count += 1\n",
    "\n",
    "        # Print the progress for users\n",
    "        print_progress_bar(user_count, total_users, prefix=\"Users Processed\", suffix=\"Complete\")\n",
    "\n",
    "        if not random_rated_movies:\n",
    "            continue\n",
    "\n",
    "        # Temporarily set ratings for selected movies to 0\n",
    "        for movie_id in random_rated_movies.keys():\n",
    "            user_idx = user_index[user_id]\n",
    "            movie_idx = user_item_matrix.columns.get_loc(movie_id)\n",
    "            train_matrix.iloc[user_idx, movie_idx] = 0\n",
    "\n",
    "        # Generate recommendations for the user\n",
    "        recommendations = recommendation_function(\n",
    "            user_id=user_id,\n",
    "            train_matrix=train_matrix,\n",
    "            user_index=user_index,\n",
    "            item_index=movie_index,\n",
    "            k=k\n",
    "        )\n",
    "\n",
    "        # Restore the original train matrix\n",
    "        for movie_id, rating in random_rated_movies.items():\n",
    "            user_idx = user_index[user_id]\n",
    "            movie_idx = user_item_matrix.columns.get_loc(movie_id)\n",
    "            train_matrix.iloc[user_idx, movie_idx] = rating\n",
    "\n",
    "        at_k = min(at_k, len(recommendations))\n",
    "\n",
    "        # Calculate Precision@K, Recall@K, and F1-score@K\n",
    "        recommended_movies = set(recommendations['Movie_ID'][:at_k])\n",
    "        relevant_movies = set(random_rated_movies.keys())\n",
    "\n",
    "        # True Positives\n",
    "        true_positives = len(recommended_movies & relevant_movies)\n",
    "        # Precision@K\n",
    "        precision = true_positives / at_k if at_k > 0 else 0\n",
    "        # Recall@K\n",
    "        recall = true_positives / len(relevant_movies) if len(relevant_movies) > 0 else 0\n",
    "        # F1-Score@K\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        precision_sum += precision\n",
    "        recall_sum += recall\n",
    "        f1_sum += f1\n",
    "\n",
    "    # Calculate average metrics\n",
    "    average_precision = precision_sum / total_users\n",
    "    average_recall = recall_sum / total_users\n",
    "    average_f1 = f1_sum / total_users\n",
    "\n",
    "    return {\n",
    "        'Precision@K': average_precision,\n",
    "        'Recall@K': average_recall,\n",
    "        'F1-Score@K': average_f1\n",
    "    }\n",
    "\n",
    "# Valutazione dei sistemi di raccomandazione\n",
    "np.random.seed(42)\n",
    "\n",
    "metrics_user_based = evaluate_recommendation_metrics(\n",
    "    recommend_movies_user_based,\n",
    "    train_matrix=user_item_matrix,\n",
    "    k=10,  # Numero di vicini per il KNN\n",
    "    at_k=100,  # Numero di raccomandazioni da considerare per Precision@K\n",
    "    test_size=0.1,\n",
    "    users_to_test=10\n",
    ")\n",
    "\n",
    "print(f\"User-Based Recommendation Metrics:\")\n",
    "print(f\"Precision@K: {metrics_user_based['Precision@K']:.4f}\")\n",
    "print(f\"Recall@K: {metrics_user_based['Recall@K']:.4f}\")\n",
    "print(f\"F1-Score@K: {metrics_user_based['F1-Score@K']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Processed |█████████████████████████-------------------------| 50.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Movies: 100%|██████████| 1250/1250 [03:18<00:00,  6.30movie/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Processed |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Movies: 100%|██████████| 1265/1265 [03:05<00:00,  6.83movie/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item-Based Recommendation Metrics:\n",
      "Precision@K: 0.0350\n",
      "Recall@K: 0.3788\n",
      "F1-Score@K: 0.0641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_item_based = evaluate_recommendation_metrics(\n",
    "    recommend_movies_item_based,\n",
    "    train_matrix=user_item_matrix,\n",
    "    k=10,  # Numero di vicini per il KNN\n",
    "    at_k=100,  # Numero di raccomandazioni da considerare per Precision@K\n",
    "    test_size=0.1,\n",
    "    users_to_test=2\n",
    ")\n",
    "\n",
    "print(f\"Item-Based Recommendation Metrics:\")\n",
    "print(f\"Precision@K: {metrics_item_based['Precision@K']:.4f}\")\n",
    "print(f\"Recall@K: {metrics_item_based['Recall@K']:.4f}\")\n",
    "print(f\"F1-Score@K: {metrics_item_based['F1-Score@K']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This notebook demonstrated the implementation of a collaborative filtering approach for recommending movies. Key takeaways include:\n",
    "\n",
    "- The model effectively utilizes user similarity to make recommendations, as shown by the ability to generate relevant suggestions for a sample user.\n",
    "- The **MAE metric** and **RMSE** provide a reliable evaluation of the model's predictive accuracy.\n",
    "- While collaborative filtering is powerful, it faces challenges such as:\n",
    "  - **Cold Start Problem**: Difficulty in recommending movies for new users or items.\n",
    "  - **Data Sparsity**: Limited interactions in the dataset can affect similarity computations.\n",
    "\n",
    "### Future Improvements\n",
    "\n",
    "To address the limitations, potential enhancements include:\n",
    "\n",
    "- Implementing hybrid recommendation systems that combine collaborative and content-based filtering.\n",
    "- Exploring matrix factorization techniques (e.g., Singular Value Decomposition).\n",
    "- Integrating deep learning-based recommendation methods.\n",
    "\n",
    "This collaborative filtering approach forms a solid foundation for building scalable and effective recommendation systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
