{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ultralytics library\n",
    "!pip install ultralytics\n",
    "!pip install -U ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings in the notebook to maintain clean output cells\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import cv2\n",
    "import yaml\n",
    "from PIL import Image\n",
    "from collections import deque\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the visual appearance of Seaborn plots\n",
    "sns.set(rc={'axes.facecolor': '#ffe4de'}, style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained YOLOv8 nano segmentation model\n",
    "model = YOLO('yolov8n-seg.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset_path\n",
    "dataset_path = '/kaggle/input/pothole-image-segmentation-dataset/Pothole_Segmentation_YOLOv8'\n",
    "\n",
    "# Set the path to the YAML file\n",
    "yaml_file_path = os.path.join(dataset_path, 'data.yaml')\n",
    "\n",
    "# Load and print the contents of the YAML file\n",
    "with open(yaml_file_path, 'r') as file:\n",
    "    yaml_content = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    print(yaml.dump(yaml_content, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths for training and validation image sets\n",
    "train_images_path = os.path.join(dataset_path, 'train', 'images')\n",
    "valid_images_path = os.path.join(dataset_path, 'valid', 'images')\n",
    "\n",
    "# Initialize counters for the number of images\n",
    "num_train_images = 0\n",
    "num_valid_images = 0\n",
    "\n",
    "# Initialize sets to hold the unique sizes of images\n",
    "train_image_sizes = set()\n",
    "valid_image_sizes = set()\n",
    "\n",
    "# Check train images sizes and count\n",
    "for filename in os.listdir(train_images_path):\n",
    "    if filename.endswith('.jpg'):  \n",
    "        num_train_images += 1\n",
    "        image_path = os.path.join(train_images_path, filename)\n",
    "        with Image.open(image_path) as img:\n",
    "            train_image_sizes.add(img.size)\n",
    "\n",
    "# Check validation images sizes and count\n",
    "for filename in os.listdir(valid_images_path):\n",
    "    if filename.endswith('.jpg'): \n",
    "        num_valid_images += 1\n",
    "        image_path = os.path.join(valid_images_path, filename)\n",
    "        with Image.open(image_path) as img:\n",
    "            valid_image_sizes.add(img.size)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of training images: {num_train_images}\")\n",
    "print(f\"Number of validation images: {num_valid_images}\")\n",
    "\n",
    "# Check if all images in training set have the same size\n",
    "if len(train_image_sizes) == 1:\n",
    "    print(f\"All training images have the same size: {train_image_sizes.pop()}\")\n",
    "else:\n",
    "    print(\"Training images have varying sizes.\")\n",
    "\n",
    "# Check if all images in validation set have the same size\n",
    "if len(valid_image_sizes) == 1:\n",
    "    print(f\"All validation images have the same size: {valid_image_sizes.pop()}\")\n",
    "else:\n",
    "    print(\"Validation images have varying sizes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for the random number generator\n",
    "random.seed(0)\n",
    "\n",
    "# Create a list of image files\n",
    "image_files = [f for f in os.listdir(train_images_path) if f.endswith('.jpg')]\n",
    "\n",
    "# Randomly select 15 images\n",
    "random_images = random.sample(image_files, 15)\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(19, 12))\n",
    "\n",
    "# Loop through each image and display it in a 3x5 grid\n",
    "for i, image_file in enumerate(random_images):\n",
    "    image_path = os.path.join(train_images_path, image_file)\n",
    "    image = Image.open(image_path)\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Add a suptitle\n",
    "plt.suptitle('Random Selection of Dataset Images', fontsize=24)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Deleting unnecessary variable to free up memory\n",
    "del image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on our custom dataset\n",
    "results = model.train(\n",
    "    data=yaml_file_path,     # Path to the dataset configuration file\n",
    "    epochs=150,              # Number of epochs to train for\n",
    "    imgsz=640,               # Size of input images as integer\n",
    "    patience=15,             # Epochs to wait for no observable improvement for early stopping of training\n",
    "    batch=16,                # Number of images per batch\n",
    "    optimizer='auto',        # Optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]\n",
    "    lr0=0.0001,              # Initial learning rate \n",
    "    lrf=0.01,                # Final learning rate (lr0 * lrf)\n",
    "    dropout=0.25,            # Use dropout regularization\n",
    "    device=0,                # Device to run on, i.e. cuda device=0 \n",
    "    seed=42                  # Random seed for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the directory\n",
    "post_training_files_path = '/kaggle/working/runs/segment/train'\n",
    "\n",
    "# List the files in the directory\n",
    "!ls {post_training_files_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the full file path by joining the directory path with the filename\n",
    "results_file_path = os.path.join(post_training_files_path, 'results.png')\n",
    "\n",
    "# Read the image using cv2\n",
    "image = cv2.imread(results_file_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  \n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.figure(figsize=(20, 8), dpi=200)\n",
    "plt.imshow(image)\n",
    "plt.title('Training and Validation Loss Trends', fontsize=24)\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot learning curves for loss values\n",
    "def plot_learning_curve(df, train_loss_col, val_loss_col, title, ylim_range=[0,2]):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    sns.lineplot(data=df, x='epoch', y=train_loss_col, label='Train Loss', color='blue', linestyle='-', linewidth=2)\n",
    "    sns.lineplot(data=df, x='epoch', y=val_loss_col, label='Validation Loss', color='#ed2f00', linestyle='--', linewidth=2)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(ylim_range)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the full file path for 'results.csv' using the directory path and file name\n",
    "results_csv_path = os.path.join(post_training_files_path, 'results.csv')\n",
    "\n",
    "# Load the CSV file from the constructed path into a pandas DataFrame\n",
    "df = pd.read_csv(results_csv_path)\n",
    "\n",
    "# Remove any leading whitespace from the column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Plot the learning curves for each loss\n",
    "plot_learning_curve(df, 'train/box_loss', 'val/box_loss', 'Bounding Box Loss Learning Curve')\n",
    "plot_learning_curve(df, 'train/cls_loss', 'val/cls_loss', 'Classification Loss Learning Curve')\n",
    "plot_learning_curve(df, 'train/dfl_loss', 'val/dfl_loss', 'Distribution Focal Loss Learning Curve')\n",
    "plot_learning_curve(df, 'train/seg_loss', 'val/seg_loss', 'Segmentation Loss Learning Curve', ylim_range=[0,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filenames for 'Box' and 'Mask' metrics along with their titles\n",
    "box_files_titles = {\n",
    "    'BoxP_curve.png': 'Bounding Box Precision-Confidence Curve',\n",
    "    'BoxR_curve.png': 'Bounding Box Recall-Confidence Curve',\n",
    "    'BoxF1_curve.png': 'Bounding Box F1-Confidence Curve'\n",
    "}\n",
    "mask_files_titles = {\n",
    "    'MaskP_curve.png': 'Mask Precision-Confidence Curve',\n",
    "    'MaskR_curve.png': 'Mask Recall-Confidence Curve',\n",
    "    'MaskF1_curve.png': 'Mask F1-Confidence Curve'\n",
    "}\n",
    "\n",
    "# Create a 3x2 subplot\n",
    "fig, axs = plt.subplots(3, 2, figsize=(20, 20))\n",
    "\n",
    "# Function to read and convert image for plotting\n",
    "def read_and_convert_image(file_path):\n",
    "    # Read the image using cv2\n",
    "    image = cv2.imread(file_path)\n",
    "    # Convert from BGR to RGB\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Plot 'Box' images in the first column with meaningful titles\n",
    "for i, (filename, title) in enumerate(box_files_titles.items()):\n",
    "    img_path = os.path.join(post_training_files_path, filename)\n",
    "    img = read_and_convert_image(img_path)\n",
    "    axs[i, 0].imshow(img)\n",
    "    axs[i, 0].set_title(title, fontsize=20)\n",
    "    axs[i, 0].axis('off') \n",
    "\n",
    "# Plot 'Mask' images in the second column with meaningful titles\n",
    "for i, (filename, title) in enumerate(mask_files_titles.items()):\n",
    "    img_path = os.path.join(post_training_files_path, filename)\n",
    "    img = read_and_convert_image(img_path)\n",
    "    axs[i, 1].imshow(img)\n",
    "    axs[i, 1].set_title(title, fontsize=20)\n",
    "    axs[i, 1].axis('off')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filenames for 'Box' and 'Mask' metrics along with their titles\n",
    "pr_files_titles = {\n",
    "    'BoxPR_curve.png': 'Bounding Box Precision-Recall Curve',\n",
    "    'MaskPR_curve.png': 'Mask Precision-Recall Curve'\n",
    "}\n",
    "\n",
    "# Create a 1x2 subplot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Plot 'Box' and 'Mask' images in the subplot with meaningful titles\n",
    "for i, (filename, title) in enumerate(pr_files_titles.items()):\n",
    "    img_path = os.path.join(post_training_files_path, filename)\n",
    "    img = read_and_convert_image(img_path)\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].set_title(title, fontsize=20)\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the path to the confusion matrix images\n",
    "confusion_matrix_path = os.path.join(post_training_files_path, 'confusion_matrix.png')\n",
    "confusion_matrix_normalized_path = os.path.join(post_training_files_path, 'confusion_matrix_normalized.png')\n",
    "\n",
    "# Create a 1x2 subplot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 10), dpi=200)\n",
    "\n",
    "# Read and convert both images\n",
    "cm_img = read_and_convert_image(confusion_matrix_path)\n",
    "cm_norm_img = read_and_convert_image(confusion_matrix_normalized_path)\n",
    "\n",
    "# Display the images\n",
    "axs[0].imshow(cm_img)\n",
    "axs[0].set_title('Confusion Matrix', fontsize=24)\n",
    "axs[0].axis('off') \n",
    "\n",
    "axs[1].imshow(cm_norm_img)\n",
    "axs[1].set_title('Normalized Confusion Matrix', fontsize=24)\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the path to the best model weights file using os.path.join\n",
    "best_model_path = os.path.join(post_training_files_path, 'weights/best.pt')\n",
    "\n",
    "# Load the best model weights into the YOLO model\n",
    "best_model = YOLO(best_model_path)\n",
    "\n",
    "# Validate the best model using the validation set with default parameters\n",
    "metrics = best_model.val(split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary to a pandas DataFrame and use the keys as the index\n",
    "metrics_df = pd.DataFrame.from_dict(metrics.results_dict, orient='index', columns=['Metric Value'])\n",
    "\n",
    "# Display the DataFrame\n",
    "metrics_df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the validation images\n",
    "valid_images_path = os.path.join(dataset_path, 'valid', 'images')\n",
    "\n",
    "# List all jpg images in the directory\n",
    "image_files = [file for file in os.listdir(valid_images_path) if file.endswith('.jpg')]\n",
    "\n",
    "# Select 9 images at equal intervals\n",
    "num_images = len(image_files)\n",
    "selected_images = [image_files[i] for i in range(0, num_images, num_images // 9)]\n",
    "\n",
    "# Initialize the subplot\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 21))\n",
    "fig.suptitle('Validation Set Inferences', fontsize=24)\n",
    "\n",
    "# Perform inference on each selected image and display it\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    image_path = os.path.join(valid_images_path, selected_images[i])\n",
    "    results = best_model.predict(source=image_path, imgsz=640)\n",
    "    annotated_image = results[0].plot()\n",
    "    annotated_image_rgb = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
    "    ax.imshow(annotated_image_rgb)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the sample video in the dataset\n",
    "dataset_video_path = '/kaggle/input/pothole-image-segmentation-dataset/Pothole_Segmentation_YOLOv8/sample_video.mp4'\n",
    "\n",
    "# Define the destination path in the working directory\n",
    "video_path = '/kaggle/working/sample_video.mp4'\n",
    "\n",
    "# Copy the video file from its original location in the dataset to the current working directory in Kaggle\n",
    "shutil.copyfile(dataset_video_path, video_path)\n",
    "\n",
    "# Initiate vehicle detection on the sample video using the best performing model and save the output\n",
    "best_model.predict(source=video_path, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the .avi video generated by the YOLOv8 prediction to .mp4 format for compatibility with notebook display\n",
    "!ffmpeg -y -loglevel panic -i /kaggle/working/runs/segment/predict/sample_video.avi processed_sample_video.mp4\n",
    "\n",
    "# Embed and display the processed sample video within the notebook\n",
    "Video(\"processed_sample_video.mp4\", embed=True, width=960)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
