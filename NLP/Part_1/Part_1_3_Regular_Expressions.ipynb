{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdhvdUzmtkzI"
   },
   "source": [
    "<img src='https://www.di.uniroma1.it/sites/all/themes/sapienza_bootstrap/logo.png' width=\"200\"/> \n",
    "\n",
    "# Part 1.3 - Regular Expressions\n",
    "A regular expression (shortened as regex or `RegEx`), sometimes referred to as a rational expression, is a sequence of characters that specifies a match pattern in text. Usually, such patterns are used by string-searching algorithms for \"**find**\" or \"**find & replace**\" operations on strings, or for input validation. Regular expression techniques are developed in theoretical computer science and formal language theory.\n",
    " \n",
    "### **Objectives:**\n",
    "\n",
    "By the end of this notebook, Parham will have learned what `Regular Expressions` are and their use cases in `NLP`. He will acquire the basic concepts and syntax, such as **Quantifiers**, **Anchors**, **Groups**, etc. Subsequently, he will dive into more practical problems, such as **Matching and Extracting data**, and **Substitution and Splitting**. Last but not least, Parham will grasp some advanced techniques in the aforementioned scope, including **Named Groups**, **Non-Capturing Groups**, and **Conditional Statements**. Finally, he will challenge himself with a set of small tasks in this context.\n",
    "\n",
    "### **References**: \n",
    "- [https://docs.python.org/3/library/re.html](https://docs.python.org/3/library/re.html)\n",
    "- [https://www.geeksforgeeks.org/regular-expression-python-examples/](https://www.geeksforgeeks.org/regular-expression-python-examples/)\n",
    "### **Tutors**:\n",
    "- Professor Stefano Farali\n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7e/Gmail_icon_%282020%29.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **Email**: Stefano.faralli@uniroma1.it\n",
    "    - <img src=\"https://www.iconsdb.com/icons/preview/red/linkedin-6-xxl.png\" alt=\"Logo\" width=\"20\" height=\"20\"> **LinkedIn**: [LinkedIn](https://www.linkedin.com/in/stefano-faralli-b1183920/) \n",
    "- Professor Iacopo Masi\n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7e/Gmail_icon_%282020%29.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **Email**: masi@di.uniroma1.it  \n",
    "    - <img src=\"https://www.iconsdb.com/icons/preview/red/linkedin-6-xxl.png\" alt=\"Logo\" width=\"20\" height=\"20\"> **LinkedIn**: [LinkedIn](https://www.linkedin.com/in/iacopomasi/)  \n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ae/Github-desktop-logo-symbol.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **GitHub**: [GitHub](https://github.com/iacopomasi)  \n",
    "\n",
    "### **Contributors**:\n",
    "- Parham Membari\n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7e/Gmail_icon_%282020%29.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **Email**: p.membari96@gmail.com\n",
    "    - <img src=\"https://www.iconsdb.com/icons/preview/red/linkedin-6-xxl.png\" alt=\"Logo\" width=\"20\" height=\"20\"> **LinkedIn**: [LinkedIn](https://www.linkedin.com/in/p-mem/)\n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ae/Github-desktop-logo-symbol.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **GitHub**:  [GitHub](https://github.com/parham075)\n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ec/Medium_logo_Monogram.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **Medium**: [Medium](https://medium.com/@p.membari96)\n",
    "\n",
    "**Tabel of Content:**\n",
    "\n",
    "1. Import Libraries\n",
    "2. Introduction to Regular Expressions\n",
    "3. Basic Concepts and Syntax\n",
    "4. Practical Applications\n",
    "5. Exercises and Challenges\n",
    "6. Closing Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUmX7sO71Hra"
   },
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-vf7lt-Z1w9F"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import re\n",
    "from loguru import logger\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Configure logging\n",
    "nltk.data.path.append(os.getcwd() + \"datasets/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MnBh_WJ17a9"
   },
   "source": [
    "## 2. Introduction to Regular Expressions\n",
    "\n",
    "In this part of the notebook, Parham will gain basic knowledge about `RegEx`, and some of his questions will be answered. These answers will help him understand the core concepts of `RegEx` and prepare him to dive into practical tasks with more confidence.\n",
    "\n",
    "### 1. What are Regular Expressions? \n",
    "Regular expressions (shortened as `regex` or `regexp`) are sequences of characters that define a search pattern. Some operations such as searching, matching, and manipulating text based on specific condition can be achieved by leveraging these patterns. `RegEx` are integral to string-processing algorithms and are used extensively for tasks such as:\n",
    "\n",
    "- **Finding and Replacing:** Searching for specific patterns within text and replacing them with new strings.\n",
    "- **Input Validation:** Ensuring that input strings meet specific formats (e.g., email addresses, phone numbers).\n",
    "- **Text Parsing and Extraction:** Extracting specific data from larger text structures, such as dates, URLs, or particular text segments.\n",
    "\n",
    "Regular expressions are supported by various programming languages and tools, making them a versatile and powerful tool in text processing and data analysis.\n",
    "\n",
    "### 2. How are `RegEx` useful in NLP?\n",
    "\n",
    "Regular expressions are extremely useful in Natural Language Processing (NLP) for several reasons:\n",
    "\n",
    "- **Text Cleaning and Preprocessing:** Regular expressions help in removing irrelevant and redundant characters, normalizing text, and preparing data for further analysis.\n",
    "- **Tokenization:** Splitting text into tokens (words, sentences) based on patterns is a crucial step in many NLP tasks.\n",
    "- **Pattern Matching:** Identifying specific patterns in text, such as dates, phone numbers, email addresses, etc.\n",
    "- **Information Extraction:** Extracting structured information from unstructured text data.\n",
    "- **Data Validation:** Ensuring that input data conforms to expected formats, such as validating email addresses and phone numbers.\n",
    "\n",
    "### 3. How `RegEx` works in the core?\n",
    "\n",
    "To address this question the user will expand his knowledge about the `Regex Engine`. A RegEx engine is the software component that interprets and executes regular expressions. It processes the pattern specified by the `RegEx` and performs the matching operation against the target text. Understanding how the regex engine works can help in writing efficient and effective regular expressions. \n",
    "\n",
    "There are primarily two types of regex engines:\n",
    "\n",
    "- **DFA (Deterministic Finite Automaton) Engine:**\n",
    "  - **Characteristics:** \n",
    "    - Processes the input text in a single pass.\n",
    "    - Always finds the longest possible match.\n",
    "    - No backtracking is involved.\n",
    "  - **Advantages:**\n",
    "    - Fast and efficient, especially for simple patterns.\n",
    "  - **Disadvantages:**\n",
    "    - Limited in terms of features and flexibility.\n",
    "  - **Examples:** Lexical analyzers in compilers often use DFA engines.\n",
    "\n",
    "- **NFA (Non-deterministic Finite Automaton) Engine:**\n",
    "  - **Characteristics:**\n",
    "    - Can backtrack to find matches.\n",
    "    - Supports more complex patterns, including those with nested and recursive structures.\n",
    "  - **Advantages:**\n",
    "    - More flexible and powerful, supporting advanced regex features.\n",
    "  - **Disadvantages:**\n",
    "    - Can be slower due to backtracking, especially with complex patterns.\n",
    "  - **Examples:** Most modern regex implementations, such as those in Perl, Python, and JavaScript, use NFA engines.\n",
    "\n",
    "When you use a regular expression to search through text, the regex engine follows these general steps:\n",
    "\n",
    "- **Compile the Pattern:**\n",
    "  - The regex pattern is parsed and compiled into an internal representation that the engine can work with.\n",
    "\n",
    "- **Search the Text:**\n",
    "  - The engine begins scanning the target text from the start (or from the specified position).\n",
    "  - It tries to match the pattern against the text character by character.\n",
    "\n",
    "- **Backtracking (NFA Engines):**\n",
    "  - If a partial match fails, the engine backtracks to try alternative paths in the pattern. This allows it to handle more complex matching scenarios.\n",
    "\n",
    "- **Return the Result:**\n",
    "  - Once a match is found, the engine returns the match object.\n",
    "  - If no match is found, the engine returns a result indicating no match.\n",
    "\n",
    "**Explain with an example:**\n",
    "\n",
    "  Suppose the user is looking for a specific pattern in a text, namely `/coding/`, in the following sentence:\n",
    "\n",
    "  `coding is a cool hobby.`\n",
    "\n",
    "  Steps Followed by the Regex Engine:\n",
    "\n",
    "  0. **Encoding the Pattern:** The pattern `/coding/` is encoded into tokens that can be interpreted by the regex engine.\n",
    "    \n",
    "  1. **Searching for the Pattern:** The engine begins to search for the specific pattern in the text. In this example, the first character `c` is the first matched candidate, followed by `o` as the second, and so on, until the entire pattern is matched. \n",
    "  \n",
    "  - > The `/g` at the end of the pattern stands for a **global** match, indicating that the engine should find all matches in the text. Without the global flag, the regex engine would return only the first match.\n",
    "\n",
    "  2. **Backtracking:** If a partial match is found but not completed, the engine backtracks. For example, when matching `coding` in `cool`, the engine matches `c` and `o`, but `o` does not match the third character `d` in `coding`. Therefore, the engine backtracks to the beginning of `cool` and continues searching.\n",
    "\n",
    "  3. **Returning Match Objects:** Once all global matches are found, the engine returns the match object(s).\n",
    "\n",
    "  **Step-by-Step Matching**\n",
    "\n",
    "  - The engine starts at the beginning of the text: `coding is a cool hobby.`\n",
    "  - It matches `c`, `o`, `d`, `i`, `n`, `g` with the corresponding characters in `coding` and completes the pattern match.\n",
    "  - The global flag `/g` ensures the engine continues searching through the text, but since there are no other instances of `coding`, the search ends.\n",
    "\n",
    "  **Diagram Illustration**\n",
    "\n",
    "  1. Initial Matching:\n",
    "\n",
    "  ```\n",
    "  coding is a cool hobby.\n",
    "  ^\n",
    "  c\n",
    "  ```\n",
    "\n",
    "  2. Continuing Match:\n",
    "\n",
    "  ```\n",
    "  coding is a cool hobby.\n",
    "  ^^^^^^\n",
    "  coding\n",
    "  ```\n",
    "\n",
    "  3. Backtracking (if needed):\n",
    "\n",
    "  ```\n",
    "  coding is a cool hobby.\n",
    "                ^\n",
    "                d (does not match next part of \"coding\")\n",
    "  ```\n",
    "\n",
    "  4. Completion:\n",
    "  - Once all matches are found, the engine returns the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Concepts and Syntax\n",
    "\n",
    "In this section, Parham will learn about fundamental concepts and syntax used in `RegEx` including:\n",
    "- Literals and Meta-characters\n",
    "- Character Classes and Sets\n",
    "- Quantifiers\n",
    "- Anchors\n",
    "- Groups and Ranges\n",
    "- Escape Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Literals and Meta-characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1) Literals\n",
    "The most basic regular expression consists of a single literal character, such as `a`. It matches the first occurrence of that character in the string. If the string is `Jack is a boy`, it matches the `a` after the `J`. The fact that this `a` is in the middle of the word does not matter to the regex engine. If it matters to you, you will need to tell that to the regex engine by using [word boundaries](https://www.regular-expressions.info/wordboundaries.html). We will get to that later.\n",
    "\n",
    ">The re module offers a set of functions that allows us to search a string for a match:\n",
    "> \n",
    ">| Function  | Description                                                   |\n",
    ">|-----------|---------------------------------------------------------------|\n",
    ">| findall   | Returns a list containing all matches                         |\n",
    ">| search    | Returns a Match object if there is a match anywhere in the string |\n",
    ">| split     | Returns a list where the string has been split at each match  |\n",
    ">| sub       | Replaces one or many matches with a string                    |\n",
    ">| find      | Returns the lowest index of the substring if found in the string |\n",
    ">| finditer  | Returns an iterator yielding Match objects for all matches    |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern: 'a' is found\n"
     ]
    }
   ],
   "source": [
    "# Define the text to search\n",
    "text = \"Jack is a boy\"\n",
    "\n",
    "# Define the pattern to search for\n",
    "pattern = r\"a\"\n",
    "\n",
    "# Use re.search to find the first match of the pattern in the text\n",
    "match = re.search(pattern, text)\n",
    "\n",
    "# Check if a match is found and print the matched text\n",
    "if match:\n",
    "    print(f\"Pattern: '{match[0]}' is found\")\n",
    "else:\n",
    "    print(\"No match found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 1:**\n",
    "  \n",
    "Given the following text, find all occurrences of the letter `a`, and count how many times it appears before the first occurrence of the word `apple`. Return both the matches and their positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "470"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"In a faraway land, \n",
    "        there was a magical forest where apple treees grew abundantly. \n",
    "        One sunny afternoon, \n",
    "        a young adventurer found herself wandering among the apple treees. \n",
    "        She marveled at the vibrant colors and sweet scents. \n",
    "        The apples seemed to be glowing in the sunlight, \n",
    "        and she picked a few to enjoy later. \n",
    "        As she continued her journey, \n",
    "        she found that the apples had a mysterious quality to them.\"\"\"\n",
    "pattern = r\"a\"\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 🧑🏿‍💻 Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched text: a, Location: 3\n",
      "Matched text: a, Location: 6\n",
      "Matched text: a, Location: 8\n",
      "Matched text: a, Location: 10\n",
      "Matched text: a, Location: 14\n",
      "Matched text: a, Location: 35\n",
      "Matched text: a, Location: 38\n",
      "Matched text: a, Location: 41\n",
      "Matched text: a, Location: 45\n",
      "Count of 'a' before the first occurrence of 'apple': 9\n"
     ]
    }
   ],
   "source": [
    "# @title 👀 Solution\n",
    "\n",
    "# Find the position of the first occurrence of the word 'apple'\n",
    "apple_position = text.find(\"apple\")\n",
    "\n",
    "# Use re.finditer to find all matches of the pattern in the text\n",
    "matches = re.finditer(pattern, text)\n",
    "\n",
    "# Initialize the count of 'a' before 'apple'\n",
    "count_before_apple = 0\n",
    "\n",
    "# Iterate over the matches and print their positions\n",
    "for match in matches:\n",
    "    position = match.start()\n",
    "    # Increment the count if the position is before 'apple'\n",
    "    if position < apple_position:\n",
    "        print(f\"Matched text: {match[0]}, Location: {position}\")\n",
    "        count_before_apple += 1\n",
    "\n",
    "print(f\"Count of 'a' before the first occurrence of 'apple': {count_before_apple}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**: \n",
    "\n",
    "Find all occurrences of the letter a, and count how many times it appears between the first and second occurrences of the word apple. Return both the matches and their positions, and the count of a characters between the two occurrences of apple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 🧑🏿‍💻 Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched text: a, Location: 79\n",
      "Matched text: a, Location: 84\n",
      "Matched text: a, Location: 110\n",
      "Matched text: a, Location: 130\n",
      "Matched text: a, Location: 138\n",
      "Matched text: a, Location: 164\n",
      "Matched text: a, Location: 173\n",
      "Count of 'a' between the first and second occurrences of 'apple': 7\n"
     ]
    }
   ],
   "source": [
    "# @title 👀 Solution\n",
    "# Find the positions of the first and second occurrences of the word 'apple'\n",
    "apple_positions = [m.start() for m in re.finditer(r\"apple\", text)]\n",
    "\n",
    "\n",
    "first_apple_position = apple_positions[0] + len(\"apple\")\n",
    "second_apple_position = apple_positions[1]\n",
    "\n",
    "# Use re.finditer to find all matches of the pattern in the text\n",
    "matches = re.finditer(pattern, text)\n",
    "\n",
    "# Initialize the count of 'a' between the two 'apple'\n",
    "count_between_apples = 0\n",
    "\n",
    "# Iterate over the matches and count 'a' between the two 'apple'\n",
    "for match in matches:\n",
    "    position = match.start()\n",
    "    if first_apple_position <= position < second_apple_position:\n",
    "        count_between_apples += 1\n",
    "        print(f\"Matched text: {match[0]}, Location: {position}\")\n",
    "\n",
    "print(\n",
    "    f\"Count of 'a' between the first and second occurrences of 'apple': {count_between_apples}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2) Meta-characters\n",
    "\n",
    "Meta-characters are special characters in regular expressions that have specific meanings and functions. They help define complex patterns and provide powerful matching capabilities. Here are some common meta-characters and their meanings:\n",
    "\n",
    "| Symbol                      | Description                                       | Pattern  | Text Examples               | Matches        |\n",
    "|-----------------------------|---------------------------------------------------|----------|-----------------------------|-----------------|\n",
    "| **Dot (`.`)**               | Matches any single character except a newline.   | `c.t`    | `cat`, `cot`, `cut`         | Matches all     |\n",
    "| **Caret (`^`)**             | Matches the start of a string.                   | `^The`   | `The cat`, `A cat`          | `The cat`       |\n",
    "| **Dollar (`$`)**            | Matches the end of a string.                     | `cat$`   | `The cat`, `The cat is here`| `The cat`       |\n",
    "| **Asterisk (`*`)**          | It specifies that the preceding element may occur zero or more times. | `ca*t`   | `ct`, `cat`, `caat`         | Matches all     |\n",
    "| **Plus (`+`)**              | Matches one or more of the preceding character.  | `ca+t`   | `cat`, `caat`, `ct`         | `cat`, `caat`   |\n",
    "| **Question Mark (`?`)**     | Matches zero or one of the preceding character.  | `ca?t`   | `cat`, `ct`                 | `cat`, `ct`     |\n",
    "| **Braces (`{n,m}`)**        | Matches between `n` and `m` occurrences of the preceding character. | `a{2,4}` | `aa`, `aaa`, `aaaa` | Matches all     |\n",
    "| **Square Brackets (`[]`)**  | Matches any one of the characters inside the brackets. | `[abc]` | `a`, `b`, `c`            | Matches all     |\n",
    "| **Pipe (`\\|`)**             | Acts as an OR operator.                         | `cat\\|dog` | `cat`, `dog`               | Matches either  |\n",
    "| **Parentheses (`()`)**      | Groups patterns and captures the matched text.  | `(ab)+`  | `ab`, `abab`               | Matches both    |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-12 12:44:24.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mExample for Dot (.)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot matches: ['and', 'and', 'and', 'and']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-12 12:44:24.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mExample for Caret (^)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caret match: I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-12 12:44:24.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m14\u001b[0m - \u001b[1mExample for Dollar ($)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dollar match: them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-12 12:44:24.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mExample for Asterisk (*)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asterisk matches: ['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'app', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'app', 'a', 'a', 'a', 'a', 'app', 'a', 'a', 'a', 'a', 'app', 'a', 'a', 'a']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-12 12:44:24.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mExample for Plus (+)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plus matches: ['s', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-12 12:44:24.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mExample for Question Mark (?)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Mark matches: ['the', 'tre', 'te', 'the', 'tre', 'the', 'the', 'te', 'the', 'te', 'the']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-12 12:44:24.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mExample for Braces (`{n,m}`)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: 'pp' found in positions 62:64\n",
      "Match: 'pp' found in positions 184:186\n",
      "Match: 'pp' found in positions 273:275\n",
      "Match: 'p' found in positions 334:335\n",
      "Match: 'pp' found in positions 431:433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-12 12:44:24.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1mExample for Square Brackets (`[]`)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'e', 'a', 'i', 'i', 'm', 'e']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-12 12:44:24.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mExample for Pipe (`|`)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'tree', 'tree']\n",
      "Yes, there is/are 3 match(es)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-12 12:44:24.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mExample for Parentheses (`()`)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: 'race in 2 hours and 30 minutes.'\n",
      "Group 1 (race): 'race'\n",
      "Group 2 (time): '2 hours'\n",
      "Group 3 (time): '30 minutes.'\n"
     ]
    }
   ],
   "source": [
    "# Dot (.)\n",
    "logger.info(\"Example for Dot (.)\")\n",
    "pattern = r\"a.d\"\n",
    "matches = re.findall(pattern, text)\n",
    "print(f\"Dot matches: {matches if matches else 'No match'}\")\n",
    "sys.stdout.flush()\n",
    "# Caret (^)\n",
    "logger.info(\"Example for Caret (^)\")\n",
    "pattern = r\"^I\"\n",
    "match = re.search(pattern, text)\n",
    "print(f\"Caret match: {match[0] if match else 'No match'}\")\n",
    "sys.stdout.flush()\n",
    "# Dollar ($)\n",
    "logger.info(\"Example for Dollar ($)\")\n",
    "pattern = r\"them\\.$\"\n",
    "match = re.search(pattern, text)\n",
    "print(f\"Dollar match: {match[0] if match else 'No match'}\")\n",
    "sys.stdout.flush()\n",
    "# Asterisk (*)\n",
    "logger.info(\"Example for Asterisk (*)\")\n",
    "pattern = r\"ap*\"\n",
    "matches = re.findall(pattern, text)\n",
    "print(f\"Asterisk matches: {matches}\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Plus (+)\n",
    "logger.info(\"Example for Plus (+)\")\n",
    "pattern = r\"s+\"\n",
    "matches = re.findall(pattern, text)\n",
    "print(f\"Plus matches: {matches}\")\n",
    "sys.stdout.flush()\n",
    "# Question Mark (?) make the previous character optional\n",
    "logger.info(\"Example for Question Mark (?)\")\n",
    "pattern = r\"t.?e\"  # find zero/one char between \"t\" and the \"e\"\n",
    "matches = re.findall(pattern, text)\n",
    "print(f\"Question Mark matches: {matches}\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "logger.info(\"Example for Braces (`{n,m}`)\")\n",
    "# Define the pattern to match sequences of 2 to 3 'l's\n",
    "pattern = r\"p{1,3}\"\n",
    "# Find all matches of the pattern\n",
    "matches = re.finditer(pattern, text)\n",
    "# Print the matches and the words containing them\n",
    "for match in matches:\n",
    "    # Find the start and end indices of the match\n",
    "    start_index = match.start()\n",
    "    end_index = match.end()\n",
    "    print(\n",
    "        f\"Match: '{text[start_index:end_index]}' found in positions {start_index}:{end_index}\"\n",
    "    )\n",
    "\n",
    "sys.stdout.flush()\n",
    "logger.info(\"Example for Square Brackets (`[]`)\")\n",
    "txt = \"The rain in Rome\"\n",
    "# Find all lower case characters alphabetically between \"a\" and \"m\":\n",
    "matches = re.findall(\"[a-m]\", txt)\n",
    "print(matches)\n",
    "sys.stdout.flush()\n",
    "\n",
    "logger.info(\"Example for Pipe (`|`)\")\n",
    "pattern = r\"tree|there\"\n",
    "matches = re.findall(pattern, text)\n",
    "if matches:\n",
    "    print(matches)\n",
    "    print(f\"Yes, there is/are {len(matches)} match(es)!\")\n",
    "else:\n",
    "    print(\"No match\")\n",
    "sys.stdout.flush()\n",
    "logger.info(\"Example for Parentheses (`()`)\")\n",
    "\n",
    "# Define the pattern to match the word \"race\" followed by \"in\" and a time (e.g., \"2 hours\")\n",
    "txt = \"The runner finished the race in 2 hours and 30 minutes.\"\n",
    "\n",
    "pattern = r\"(race) in (\\d+ hours) and (\\d+ minutes.)\"\n",
    "\n",
    "# Find all matches of the pattern\n",
    "matches = re.finditer(pattern, txt)\n",
    "\n",
    "# Print the matches and the groups\n",
    "for match in matches:\n",
    "    # Print the entire match\n",
    "    print(f\"Match: '{match.group(0)}'\")\n",
    "    # Print the captured groups\n",
    "    print(f\"Group 1 (race): '{match.group(1)}'\")\n",
    "    print(f\"Group 2 (time): '{match.group(2)}'\")\n",
    "    print(f\"Group 3 (time): '{match.group(3)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Write a Python script to extract and format phone number information from a given text using regular expressions. The result must be the extracted information including country names, country codes, and phone numbers.\n",
    "\n",
    "```\n",
    "txt = Dario called his mom in the Italy at +39-335-880-5661.\n",
    "Romina called her dad in the Iran at +98-912-052-0182.\n",
    "John called his friend in the USA at +1-202-555-0173.\n",
    "Mary contacted her colleague in the UK at +44-20-7946-0958.\n",
    "Ravi made a call to his family in India at +91-22-6789-1234.\n",
    "Anna dialed her cousin in Australia at +61-2-9876-5432.\n",
    "Carlos phoned his business partner in Brazil at +55-11-2345-6789.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BadqVnjB1HRc"
   },
   "outputs": [],
   "source": [
    "# @title 🧑🏿‍💻 Your code here\n",
    "txt = \"\"\"\n",
    "Dario called his mom in the Italy at +39-335-880-5661.\n",
    "Romina called her dad in the Iran at +98-912-052-0182.\n",
    "John called his friend in the USA at +1-202-555-0173.\n",
    "Mary contacted her colleague in the UK at +44-20-7946-0958.\n",
    "Ravi made a call to his family in India at +91-22-6789-1234.\n",
    "Anna dialed her cousin in Australia at +61-2-9876-5432.\n",
    "Carlos phoned his business partner in Brazil at +55-11-2345-6789.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Code</th>\n",
       "      <th>Phone Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italy</td>\n",
       "      <td>+39</td>\n",
       "      <td>3358805661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iran</td>\n",
       "      <td>+98</td>\n",
       "      <td>9120520182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USA</td>\n",
       "      <td>+1</td>\n",
       "      <td>2025550173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UK</td>\n",
       "      <td>+44</td>\n",
       "      <td>2079460958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India</td>\n",
       "      <td>+91</td>\n",
       "      <td>2267891234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Australia</td>\n",
       "      <td>+61</td>\n",
       "      <td>298765432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>+55</td>\n",
       "      <td>1123456789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country Code Phone Number\n",
       "0      Italy  +39   3358805661\n",
       "1       Iran  +98   9120520182\n",
       "2        USA   +1   2025550173\n",
       "3         UK  +44   2079460958\n",
       "4      India  +91   2267891234\n",
       "5  Australia  +61    298765432\n",
       "6     Brazil  +55   1123456789"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title 👀 Solution\n",
    "# Text with multiple phone numbers including country codes\n",
    "txt = \"\"\"\n",
    "Dario called his mom in the Italy at +39-335-880-5661.\n",
    "Romina called her dad in the Iran at +98-912-052-0182.\n",
    "John called his friend in the USA at +1-202-555-0173.\n",
    "Mary contacted her colleague in the UK at +44-20-7946-0958.\n",
    "Ravi made a call to his family in India at +91-22-6789-1234.\n",
    "Anna dialed her cousin in Australia at +61-2-9876-5432.\n",
    "Carlos phoned his business partner in Brazil at +55-11-2345-6789.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Regex pattern to extract the country, country code, and phone number\n",
    "pattern = (\n",
    "    r\"(?P<country>\\w+)\\s+at\\s+(?P<code>\\+\\d{1,3})-(?P<number>\\d{1,4}-\\d{1,4}-\\d{1,4})\"\n",
    ")\n",
    "\n",
    "\n",
    "# Find all matches in the text\n",
    "matches = re.finditer(pattern, txt)\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame(columns=[\"Country\", \"Code\", \"Phone Number\"])\n",
    "\n",
    "# List to store each row of data\n",
    "rows = []\n",
    "# Append each match as a dictionary to the list\n",
    "for idx, match in enumerate(matches):\n",
    "    df.loc[idx] = [\n",
    "        match.group(\"country\"),\n",
    "        match.group(\"code\"),\n",
    "        re.sub(r\"-\", \"\", match.group(\"number\")),\n",
    "    ]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Write a code to extract the date and time from the given text based on the conditional pattern.\n",
    "Format the results in a DataFrame with columns \"Date\" and \"Time\".\n",
    ">Hint: The regex conditional is an `IF…THEN…ELSE` construct. Its basic form is this:\n",
    ">`(?(A)X|Y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 🧑🏿‍💻 Your code here\n",
    "txt = \"\"\"\n",
    "Meeting scheduled on 2023-12-15 at 10:00 AM in the conference room.\n",
    "Event is set for 01/12/2023 at 2:30 PM at the main hall.\n",
    "The report is due on 2023-11-30 at 3:00 PM in the office.\n",
    "Join us on 10/11/2024 for a webinar at 6:45 PM.\n",
    "Please confirm by 2024-05-20 at 9:00 AM in the boardroom.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-15</td>\n",
       "      <td>10:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/12/2023</td>\n",
       "      <td>2:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>3:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>9:00 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time\n",
       "0  2023-12-15  10:00 AM\n",
       "1  01/12/2023   2:30 PM\n",
       "2  2023-11-30   3:00 PM\n",
       "3  2024-05-20   9:00 AM"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title 👀 Solution\n",
    "txt = \"\"\"\n",
    "Meeting scheduled on 2023-12-15 at 10:00 AM in the conference room.\n",
    "Event is set for 01/12/2023 at 2:30 PM at the main hall.\n",
    "The report is due on 2023-11-30 at 3:00 PM in the office.\n",
    "Join us on 10/11/2024 for a webinar at 6:45 PM.\n",
    "Please confirm by 2024-05-20 at 9:00 AM in the boardroom.\n",
    "\"\"\"\n",
    "\n",
    "# Regex pattern to extract date and time with conditional logic\n",
    "\n",
    "pattern = r\"(?P<date>\\d{4}-\\d{2}-\\d{2}|\\d{2}/\\d{2}/\\d{4})\\s+at\\s+(?P<time>\\d{1,2}:\\d{2}\\s[AP]M)\"\n",
    "\n",
    "# Find all matches in the text\n",
    "matches = re.finditer(pattern, txt)\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame(columns=[\"Date\", \"Time\"])\n",
    "\n",
    "# Populate the DataFrame using loc\n",
    "for idx, match in enumerate(matches):\n",
    "    df.loc[idx] = [match.group(\"date\"), match.group(\"time\")]\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Practical Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When discussing the Practical Applications of Regular Expressions (Regex) in the context of Natural Language Processing (NLP), it's crucial to highlight how these tools are used to handle, manipulate, and analyze text data effectively. Here’s how each of the mentioned topics **Substitution and Splitting** can be applied in NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substitution and Splitting\n",
    "\n",
    "In this section, Parham will explore two fundamental `Regex` **Substitution** and **Splitting** techniques that are essential in many NLP tasks. These techniques play a critical role in processes like text normalization and tokenization, which are foundational steps in any NLP application. \n",
    "\n",
    "For example, text normalization often involves converting text into a standard format, such as splitting sentences into separate records, which is useful for tasks like **Sentence-Level Analysis**, **Data Augmentation**, and **Simplifying Models**. However, these techniques may not be suitable for applications like **Contextual Understanding**, **Paragraph-Level Classification**, or **Sequence Models**. Additionally, he will learn how to lowercase text, remove special characters, and replace contractions, ensuring that your data is clean and consistent for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lorenzo/Documenti/GitHub/Computer-Science-\n",
      "[nltk_data]     Sapienza/NLP/Part_1/datasets/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names, get_dataset_split_names, load_dataset, load_from_disk\n",
    "\n",
    "ds = load_dataset(\"GroNLP/ik-nlp-22_slp\", \"paragraphs\")[\"train\"].select_columns(\"text\")\n",
    "nltk.download('punkt_tab', download_dir=os.getcwd() + '/datasets/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the dialogue above is from eliza an early natural language processing system eliza that could carry on a limited conversation with a user by imitating the responses of a rogerian psychotherapist weizenbaum 1966',\n",
       " 'eliza is a surprisingly simple program that uses pattern matching to recognize phrases like i need x and translate them into suitable outputs like what would it mean to you if you got x',\n",
       " 'this simple technique succeeds in this domain because eliza doesnt actually need to know anything to mimic a rogerian psychotherapist',\n",
       " 'as weizenbaum notes this is one of the few dialogue genres where listeners can act as if they know nothing of the world',\n",
       " 'elizas mimicry of human conversation was remarkably successful many people who interacted with eliza came to believe that it really understood them and their problems many continued to believe in elizas abilities even after the programs operation was explained to them weizenbaum 1976 and even today such chatbots are a fun diversion']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessed(sample):\n",
    "    for text in sample[\"text\"]:\n",
    "        # Step 1: Sentence tokenization\n",
    "        sentences = sent_tokenize(text)\n",
    "        # Apply your other preprocessing steps to each sentence\n",
    "        processed_sentences = []\n",
    "        # proccess each sentence in each sample\n",
    "        for sentence in sentences:\n",
    "            # Remove special characters\n",
    "            normalized_text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", sentence)\n",
    "            # Lowercase the text\n",
    "            normalized_text = normalized_text.lower()\n",
    "            # Replace contractions\n",
    "            contractions = {\n",
    "                \"don't\": \"do not\",\n",
    "                \"can't\": \"cannot\",\n",
    "                \"i'm\": \"i am\",\n",
    "                \"it's\": \"it is\",\n",
    "                r\"won\\'t\": \"will not\",\n",
    "                r\"can\\'t\": \"cannot\",\n",
    "                r\"ain\\'t\": \"is not\",\n",
    "                r\"(\\w+)\\'ll\": \"\\g<1> will\",\n",
    "                r\"(\\w+)n\\'t\": \"\\g<1> not\",\n",
    "                r\"(\\w+)\\'ve\": \"\\g<1> have\",\n",
    "                r\"(\\w+)\\'s\": \"\\g<1> is\",\n",
    "                r\"(\\w+)\\'re\": \"\\g<1> are\",\n",
    "                r\"(\\w+)\\'d\": \"\\g<1> would\",\n",
    "            }\n",
    "            for contraction, replacement in contractions.items():\n",
    "                normalized_text = re.sub(\n",
    "                    r\"\\b\" + contraction + r\"\\b\", replacement, normalized_text\n",
    "                )\n",
    "\n",
    "            processed_sentences.append(normalized_text)\n",
    "\n",
    "        # Return each processed sentence as a new record\n",
    "        return {\"text\": processed_sentences}\n",
    "\n",
    "\n",
    "# Apply the preprocessing function\n",
    "ds_preprocessed = ds.map(preprocessed, batched=True, batch_size=1)\n",
    "ds_preprocessed = ds_preprocessed.filter(\n",
    "    lambda x: len(x[\"text\"]) > 0\n",
    ")  # Remove any empty records\n",
    "ds_preprocessed[\"text\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Exercise: Regex-Based Named Entity Extraction\n",
    "\n",
    "### **Objective:**  \n",
    "In this exercise, you'll deepen your understanding of `Regex` by applying it to a named entity extraction task using a real-world dataset. You'll focus on identifying and extracting specific types of information, such as dates, usernames, and hashtags, from text data.\n",
    "\n",
    "### **Dataset:**  \n",
    "You will work with the [TweetEval](https://huggingface.co/datasets/cardiffnlp/tweet_eval) dataset, available through **Hugging Face**. This dataset contains a diverse collection of tweets labeled for various tasks.\n",
    "\n",
    "### **Steps:**\n",
    "\n",
    "1. **Load the Dataset:**  \n",
    "   - Load the `text` subset of the TweetEval dataset from Hugging Face.\n",
    "\n",
    "2. **Entity Extraction:**  \n",
    "   - Use regular expressions to extract the following entities from the tweets:\n",
    "     - **Dates:** Extract mentions of dates in formats like `DD/MM/YYYY` or `Month Day, Year` or `Day of the week, Year`.\n",
    "     - **URLs:** Extract any URLs from the tweets.\n",
    "     - **Usernames:** Extract any usernames mentioned in the tweets.\n",
    "     - **Hashtags:** Extract any hashtags mentioned in the tweets.\n",
    "\n",
    "3. **Data Enhancement:**  \n",
    "   - Store each of the extracted entities in a new field within the dataset.\n",
    "\n",
    "4. **Export the Results:**  \n",
    "   - Save the enhanced dataset in `JsonL` format.\n",
    "\n",
    "> **Note:** For more information on using the Hugging Face Dataset module, please refer to this [documentation](https://huggingface.co/docs/datasets/v1.1.1/processing.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaricamento dataset da Hugging Face...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978c821fa52b462ca2214d05db6eb3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/45615 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628f48c839ce4ebdb809c44417d66dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/12284 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642df765b3ce4f10ba5b81763109aa73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 45615\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 12284\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n",
      "{'text': '\"QT @user In the original draft of the 7th book, Remus Lupin survived the Battle of Hogwarts. #HappyBirthdayRemusLupin\"', 'label': 2}\n"
     ]
    }
   ],
   "source": [
    "# @title 🧑🏿‍💻 Your code here\n",
    "\n",
    "# Percorso dove salvare il dataset\n",
    "dataset_path = \"./datasets/tweet_eval_sentiment\"\n",
    "\n",
    "# Controlla se il dataset esiste già in locale\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"Caricamento dataset da disco...\")\n",
    "    dataset = load_from_disk(dataset_path)\n",
    "else:\n",
    "    print(\"Scaricamento dataset da Hugging Face...\")\n",
    "    dataset = load_dataset(\"cardiffnlp/tweet_eval\", \"sentiment\")\n",
    "    dataset.save_to_disk(dataset_path)  # Salva il dataset in locale per uso futuro\n",
    "\n",
    "# Verifica che il dataset sia stato caricato correttamente\n",
    "print(dataset)\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Closing Thoughts\n",
    "Through this Notebooks Parham performed the following activities:\n",
    "- Acquired knowlege of how `Regex` works.\n",
    "- Applied different `Regex` syntaxes on different texts\n",
    "- Introduced with a small real world usage of `Regex` in NLP tasks\n",
    "- Challenged him/her self with a real NLP task leveraging `Regex` and **Hugging Face Dataset** library.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "datas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
