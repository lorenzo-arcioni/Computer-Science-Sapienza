{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac32e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2834f42bb2344193a291364264dfc5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLAP_weights_2023.pth:   0%|          | 0.00/690M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2597b5adde4fb081a5934179aea228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb26ce5075af44639ed2cc36a3b53c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d178b2fba04952a207fac804fffa1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91e0e698aa64949a9ccdfa4b9f06fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd345733a1974b2ba283f52b69afc9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8980914e649a4add9478ea8557436e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from msclap import CLAP\n",
    "\n",
    "# Load model (Choose between versions '2022' or '2023')\n",
    "# The model weight will be downloaded automatically if `model_fp` is not specified\n",
    "clap_model = CLAP(version = '2023', use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8bbbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esc50_dataset import ESC50\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971e762",
   "metadata": {},
   "source": [
    "## Zero-shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c78bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ESC-50-master.zip:  2.45 MB/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:00, 13724.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "root_path = \"./ESC-50-master\" # Folder with ESC-50-master/\n",
    "dataset = ESC50(root=root_path, download=True) #If download=False code assumes base_folder='ESC-50-master' in esc50_dataset.py\n",
    "prompt = 'this is the sound of '\n",
    "y = [prompt + x for x in dataset.classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "284071ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing text embeddings\n",
    "text_embeddings = clap_model.get_text_embeddings(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f85281b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [08:45<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESC50 Accuracy 0.9385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Computing audio embeddings\n",
    "y_preds, y_labels = [], []\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    x, _, one_hot_target = dataset.__getitem__(i)\n",
    "    audio_embeddings = clap_model.get_audio_embeddings([x], resample=True)\n",
    "    similarity = clap_model.compute_similarity(audio_embeddings, text_embeddings)\n",
    "    y_pred = F.softmax(similarity.detach().cpu(), dim=1).numpy()\n",
    "    y_preds.append(y_pred)\n",
    "    y_labels.append(one_hot_target.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "y_labels, y_preds = np.concatenate(y_labels, axis=0), np.concatenate(y_preds, axis=0)\n",
    "acc = accuracy_score(np.argmax(y_labels, axis=1), np.argmax(y_preds, axis=1))\n",
    "print('ESC50 Accuracy {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20728ed4",
   "metadata": {},
   "source": [
    "## Zero-shot Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b10eceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes for zero-shot\n",
    "# Should be in lower case and can be more than one word\n",
    "classes = ['coughing','sneezing','drinking sipping', 'breathing', 'brushing teeth']\n",
    "ground_truth = ['coughing']\n",
    "# Add prompt\n",
    "prompt = 'this is a sound of '\n",
    "class_prompts = [prompt + x for x in classes]\n",
    "#Load audio files\n",
    "audio_files = [x for x in dataset.audio_paths[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83c9ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute text embeddings from natural text\n",
    "text_embeddings = clap_model.get_text_embeddings(class_prompts)\n",
    "\n",
    "# compute the audio embeddings from an audio file\n",
    "audio_embeddings = clap_model.get_audio_embeddings(audio_files, resample=True)\n",
    "\n",
    "# compute the similarity between audio_embeddings and text_embeddings\n",
    "similarity = clap_model.compute_similarity(audio_embeddings, text_embeddings)\n",
    "\n",
    "similarity = F.softmax(similarity, dim=1)\n",
    "values, indices = similarity[0].topk(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33c60cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: ['coughing']\n",
      "Top predictions:\n",
      "\n",
      "        sneezing: 95.66%\n",
      "        coughing: 2.85%\n",
      "  brushing teeth: 0.73%\n",
      "       breathing: 0.52%\n",
      "drinking sipping: 0.24%\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(\"Ground Truth: {}\".format(ground_truth))\n",
    "print(\"Top predictions:\\n\")\n",
    "for value, index in zip(values, indices):\n",
    "    print(f\"{classes[index]:>16s}: {100 * value.item():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08153df4",
   "metadata": {},
   "source": [
    "## Audio Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f003e1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating captions: 100%|████████████████████████| 5/5 [00:43<00:00,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file: ./ESC-50-master/ESC-50-master/audio/1-100032-A-0.wav\n",
      "Generated caption: A dog barks and then barks again. \n",
      "\n",
      "Audio file: ./ESC-50-master/ESC-50-master/audio/1-100038-A-14.wav\n",
      "Generated caption: A variety of birds are chirping and chirping in the background. \n",
      "\n",
      "Audio file: ./ESC-50-master/ESC-50-master/audio/1-100210-A-36.wav\n",
      "Generated caption: A machine is running and then it starts to run again. \n",
      "\n",
      "Audio file: ./ESC-50-master/ESC-50-master/audio/1-100210-B-36.wav\n",
      "Generated caption: A machine is running and then starts to whirr. \n",
      "\n",
      "Audio file: ./ESC-50-master/ESC-50-master/audio/1-101296-A-19.wav\n",
      "Generated caption: A thunderstorm is making its way through the forest. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load and initialize CLAP\n",
    "clap_model = CLAP(version='clapcap', use_cuda=False)\n",
    "\n",
    "# Load audio files\n",
    "audio_files = [x for x in dataset.audio_paths[:5]]\n",
    "\n",
    "# Generate captions with progress bar\n",
    "captions = []\n",
    "for path in tqdm(audio_files, desc=\"Generating captions\", ncols=80):\n",
    "    caption = clap_model.generate_caption(\n",
    "        [path],\n",
    "        resample=True,\n",
    "        beam_size=5,\n",
    "        entry_length=67,\n",
    "        temperature=0.01\n",
    "    )[0]\n",
    "    captions.append(caption)\n",
    "\n",
    "# Print results\n",
    "for audio, caption in zip(audio_files, captions):\n",
    "    print(f\"Audio file: {audio}\\nGenerated caption: {caption}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
