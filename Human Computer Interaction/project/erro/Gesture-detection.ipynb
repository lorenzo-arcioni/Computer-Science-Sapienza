{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connessione con VLC\n",
    "\n",
    "Per utilizzare il programma come player, segui questi passaggi:\n",
    "\n",
    "1. **Scaricare VLC**  \n",
    "   - Scarica e installa VLC dal sito ufficiale.\n",
    "\n",
    "2. **Aprire VLC**  \n",
    "   - Avvia l'applicazione VLC sul tuo dispositivo.\n",
    "\n",
    "3. **Accedere alle impostazioni avanzate**  \n",
    "   - Vai su:  \n",
    "   `Strumenti > Preferenze`  \n",
    "   - Clicca su `Tutto` (in basso a sinistra).\n",
    "\n",
    "4. **Abilita l'interfaccia web**  \n",
    "   - Nella lista a sinistra, seleziona `Interfacce principali`.  \n",
    "   - Sulla destra, spunta la voce `Web`.\n",
    "\n",
    "5. **Configura Lua e la password**  \n",
    "   - Espandi la sezione `> Interfacce principali` nella lista a sinistra.  \n",
    "   - Seleziona `Lua`.  \n",
    "   - In `HTTP Lua` (lato destro), inserisci la password: `123`\n",
    "\n",
    "6. **Salva e riavvia**  \n",
    "   - Clicca `Salva` in basso a destra.  \n",
    "   - Chiudi e riapri VLC.  \n",
    "   *Assicurati che VLC rimanga aperto in background.*\n",
    "\n",
    "7. **Accedi al player web**  \n",
    "   - Apri il browser e vai all'indirizzo:  [http://localhost:8080](http://localhost:8080)\n",
    "\n",
    "8. **Aggiungi contenuti**  \n",
    "   - Scarica file multimediali (es. canzoni e sound effects) sul tuo dispositivo.\n",
    "\n",
    "9. **Modifica i path**  \n",
    "   - Aggiorna il `path` nella sezione del codice contrassegnata con *VLC functions* che indica le canzoni da gestire\n",
    "   - Aggiorna il `path_start_sound` e `path_completed_sound` nella sezione del codice contrassegnata con *#Er codice* che indicano i sound effects al rilevamento di gesti\n",
    "\n",
    "10. **Modifica il nome delle delle canzoni nei file di codice**  \n",
    "   - Aggiorna il `enqueue_tracks` nella sezione del codice contrassegnata con *VLC functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pip install\n",
    "\n",
    "\n",
    "# !pip install requests\n",
    "# !pip install cv2\n",
    "# !pip install mediapipe\n",
    "# !pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from urllib.parse import quote\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import math\n",
    "from playsound import playsound\n",
    "import threading\n",
    "import os\n",
    "import pygame\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VLC\n",
    "\n",
    "\n",
    "Assicurati di aggiornare la variabile `path` con il tuo percorso di salvataggio delle canzoni.\n",
    "\n",
    "Personalizza i nomi delle canzoni nelle funzioni `enqueue_track` per aggiungere i tuoi brani preferiti alla playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VLC connection\n",
    "\n",
    "\n",
    "VLC_PASSWORD = '123'\n",
    "VLC_URL = \"http://localhost:8080/requests/status.xml\"\n",
    "\n",
    "def vlc_command(command):\n",
    "    response = requests.get(f\"{VLC_URL}?command={command}\", auth=HTTPBasicAuth('', VLC_PASSWORD))\n",
    "    if response.status_code == 200:\n",
    "        print(f\"[✓] Comando '{command}' eseguito\")\n",
    "    else:\n",
    "        print(f\"[✗] Errore: {response.status_code}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#VLC functons\n",
    "def enqueue_track(filepath_or_url):\n",
    "    # Se è un file locale, aggiungiamo file:///\n",
    "    if filepath_or_url.startswith(\"http\"):\n",
    "        input_url = filepath_or_url\n",
    "    else:\n",
    "        input_url = \"file:///\" + quote(filepath_or_url.replace(\"\\\\\", \"/\"))\n",
    "\n",
    "    full_url = f\"{VLC_URL}?command=in_enqueue&input={input_url}\"\n",
    "    response = requests.get(full_url, auth=HTTPBasicAuth('', VLC_PASSWORD))\n",
    "\n",
    "\n",
    "# Funzione per convertire un percorso in URI valido per VLC\n",
    "def get_vlc_uri(file_path):\n",
    "    # Sostituisci \\ con / e codifica caratteri speciali (spazi, parentesi, etc.)\n",
    "    uri_path = file_path.replace(\"\\\\\", \"/\")\n",
    "    return urllib.parse.quote(uri_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#cambia questa path con la tua\n",
    "path = r\"music\"\n",
    "\n",
    "# Aggiungi alcune canzoni all'interno della path precedente per iniziare\n",
    "enqueue_track(path + r\"\\Arctic Monkeys - Knee Socks.mp3\")\n",
    "enqueue_track(path + r\"\\Future-Mask Off (Marimba Ringtone).mp3\")\n",
    "\n",
    "# Funzioni per i comandi VLC\n",
    "def play_pause():\n",
    "    vlc_command(\"pl_pause\")\n",
    "\n",
    "def next():\n",
    "    vlc_command(\"pl_next\")\n",
    "\n",
    "def prev():\n",
    "    vlc_command(\"pl_previous\")\n",
    "\n",
    "def vol_up():\n",
    "    vlc_command(\"volume&val=+80\")\n",
    "\n",
    "def vol_dw():\n",
    "    vlc_command(\"volume&val=-80\")\n",
    "    \n",
    "# def stop():\n",
    "#     vlc_command(\"pl_stop\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gesture recognition functions\n",
    "\n",
    "\n",
    "\n",
    "def check_open_hand(hand_landmarks):\n",
    "    all_y = [lm.y for lm in hand_landmarks.landmark]\n",
    "    all_x = [lm.x for lm in hand_landmarks.landmark]\n",
    "    \n",
    "    # IDs delle articolazioni delle dita (MediaPipe landmarks)\n",
    "    finger_tips = [4, 8, 12, 16, 20]  # pollice, indice, medio, anulare, mignolo\n",
    "    finger_pips = [2, 6, 10, 14, 18]   # articolazioni corrispondenti\n",
    "\n",
    "    open_fingers = 0\n",
    "    \n",
    "    if hand_landmarks.landmark[0].y > min(all_y[1:]): #se il polso si trova più in basso rispetto a tutte le altre\n",
    "        for i in range(5):\n",
    "            tip = hand_landmarks.landmark[finger_tips[i]] #punta del dito corrente\n",
    "            pip = hand_landmarks.landmark[finger_pips[i]] #articolazione del dito corrente\n",
    "            \n",
    "            # Per il pollice controlliamo la coordinata x\n",
    "            if i == 0:  # pollice\n",
    "                if (hand_landmarks.landmark[0].x < tip.x and tip.x > pip.x and hand_landmarks.landmark[1].x > hand_landmarks.landmark[0].x ) or \\\n",
    "                    (hand_landmarks.landmark[0].x > tip.x and tip.x < pip.x and hand_landmarks.landmark[1].x < hand_landmarks.landmark[0].x ):\n",
    "                    open_fingers += 1\n",
    "            # Per le altre dita controlliamo la coordinata y\n",
    "            else:\n",
    "                if tip.y < pip.y and\\\n",
    "                    abs(hand_landmarks.landmark[4].x-hand_landmarks.landmark[20].x)>0.1 and\\\n",
    "                    abs(hand_landmarks.landmark[0].y-hand_landmarks.landmark[12].y)>0.3    :  # la punta è sopra l'articolazione (dito aperto)\n",
    "                    open_fingers += 1\n",
    "        \n",
    "        # Consideriamo la mano aperta se almeno 4 dita sono aperte (puoi cambiare a 5 per essere più preciso)\n",
    "        return open_fingers >= 5\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def check_thumbs_up(hand_landmarks):\n",
    "    all_y = [lm.y for lm in hand_landmarks.landmark]\n",
    "    all_x = [lm.x for lm in hand_landmarks.landmark]\n",
    "    \n",
    "    thumb_y = all_y[3:5]\n",
    "    \n",
    "    other_y = all_y[5:] #but not 0\n",
    "    \n",
    "    if max(thumb_y) < min(other_y) and abs(hand_landmarks.landmark[4].y-hand_landmarks.landmark[5].y)>0.1 :\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def check_thumbs_down(hand_landmarks):\n",
    "    all_y = [lm.y for lm in hand_landmarks.landmark]\n",
    "    all_x = [lm.x for lm in hand_landmarks.landmark]\n",
    "    \n",
    "    # new\n",
    "    thumb_y = all_y[3:5] #joints 3,4\n",
    "    other_y = all_y[5:] #all joints but 0,2,3,4\n",
    "        \n",
    "\n",
    "    if min(thumb_y) > max(other_y) and\\\n",
    "        abs(hand_landmarks.landmark[4].x - hand_landmarks.landmark[17].x) < 0.2 and\\\n",
    "        abs(hand_landmarks.landmark[4].x - hand_landmarks.landmark[9].x) < 0.2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def check_thumbs_rx(hand_landmarks):\n",
    "    all_y = [lm.y for lm in hand_landmarks.landmark]\n",
    "    all_x = [lm.x for lm in hand_landmarks.landmark]\n",
    "    \n",
    "    # new\n",
    "    thumb_x = all_x[2:5]\n",
    "    other_x = all_x[5:] #but not 0\n",
    "\n",
    "    indici_nocche=[5, 9, 13, 17]\n",
    "    nocche=[all_y[i] for i in indici_nocche]\n",
    "\n",
    "    indici_tips=[8, 12, 16, 20]\n",
    "    tips=[all_y[i] for i in indici_tips]\n",
    "\n",
    "\n",
    "    dita_chiuse = all(\n",
    "        all_y[tip] > all_y[nocca]\n",
    "        for tip, nocca in zip(indici_tips, indici_nocche)\n",
    "    )\n",
    "\n",
    "\n",
    "    if min(thumb_x) > max(other_x) and\\\n",
    "        abs(hand_landmarks.landmark[4].y - hand_landmarks.landmark[17].y) < 0.2 and\\\n",
    "        abs(hand_landmarks.landmark[4].y - hand_landmarks.landmark[9].y) < 0.2 and\\\n",
    "        min(tips)>max(nocche) and\\\n",
    "        dita_chiuse:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def check_thumbs_sx(hand_landmarks):\n",
    "    all_y = [lm.y for lm in hand_landmarks.landmark]\n",
    "    all_x = [lm.x for lm in hand_landmarks.landmark]\n",
    "    \n",
    "    # new\n",
    "    thumb_x = all_x[2:5]\n",
    "    other_x = all_x[5:] #but not 0\n",
    "\n",
    "    indici_nocche=[5, 9, 13, 17]\n",
    "    nocche=[all_y[i] for i in indici_nocche]\n",
    "\n",
    "    indici_tips=[8, 12, 16, 20]\n",
    "    tips=[all_y[i] for i in indici_tips]\n",
    "    \n",
    "    dita_chiuse = all(\n",
    "        all_y[tip] > all_y[nocca]\n",
    "        for tip, nocca in zip(indici_tips, indici_nocche)\n",
    "    )\n",
    "\n",
    "    if min(thumb_x) < max(other_x) and\\\n",
    "        abs(hand_landmarks.landmark[4].y - hand_landmarks.landmark[17].y) < 0.2 and\\\n",
    "        abs(hand_landmarks.landmark[4].y - hand_landmarks.landmark[9].y) < 0.2 and\\\n",
    "            dita_chiuse:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def fuuu(hand_landmarks):\n",
    "    all_y = [lm.y for lm in hand_landmarks.landmark]\n",
    "    all_x = [lm.x for lm in hand_landmarks.landmark]\n",
    "    \n",
    "    all=all_y[0:8]+all_y[13:]\n",
    "    \n",
    "    return hand_landmarks.landmark[11].y < min(all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test di verifica della detection di gesture\n",
    "- \"Scommenta\" la seguente cella di codice e eseguila assieme alle precedenti per controllare se le gesture vengono riconosciute correttamente\n",
    "- Ricorda che la cam si chiude premendo `q` o, in caso non funzionasse, `restartando` il kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test if gesture are effectively detected - no functions applied\n",
    "\n",
    "\n",
    "# now = time.time()\n",
    "\n",
    "# mp_hands = mp.solutions.hands\n",
    "# mp_draw = mp.solutions.drawing_utils\n",
    "# hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "\n",
    "# # Open webcam\n",
    "# cap = cv2.VideoCapture(0)  # Change to 1 if using an external webcam\n",
    "\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "    \n",
    "#     # Flip the frame horizontally for a mirror effect\n",
    "#     frame = cv2.flip(frame, 1)\n",
    "    \n",
    "#     # Convert to RGB\n",
    "#     rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     # Process the frame and get hand landmarks\n",
    "#     results = hands.process(rgb_frame)\n",
    "\n",
    "#     # Draw hand landmarks and print\n",
    "#     if results.multi_hand_landmarks:\n",
    "#         for hand_id, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "#             # print(f\"\\nHand {hand_id + 1} detected:\")\n",
    "            \n",
    "#             for i, lm in enumerate(hand_landmarks.landmark):\n",
    "#                 # print(f\"  Landmark {i}: (X: {lm.x:.4f}, Y: {lm.y:.4f}, Z: {lm.z:.4f})\")\n",
    "#                 # Draw the landmarks on the hand\n",
    "#                 mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                \n",
    "#             if check_open_hand(hand_landmarks):\n",
    "#                 # Visualizza sul frame\n",
    "#                 x, y = int(hand_landmarks.landmark[0].x * frame.shape[1]), int(hand_landmarks.landmark[0].y * frame.shape[0])\n",
    "#                 cv2.putText(frame, \"MANO APERTA\", (x, y-50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                \n",
    "                \n",
    "#             elif check_thumbs_up(hand_landmarks):\n",
    "#                 # Visualizza sul frame\n",
    "#                 x, y = int(hand_landmarks.landmark[0].x * frame.shape[1]), int(hand_landmarks.landmark[0].y * frame.shape[0])\n",
    "#                 cv2.putText(frame, \"POLLICE SU'\", (x, y-50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                    \n",
    "#             elif check_thumbs_down(hand_landmarks):\n",
    "#                 # Visualizza sul frame\n",
    "#                 x, y = int(hand_landmarks.landmark[0].x * frame.shape[1]), int(hand_landmarks.landmark[0].y * frame.shape[0])\n",
    "#                 cv2.putText(frame, \"POLLICE GIU'\", (x, y-50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                \n",
    "#             elif  check_thumbs_rx(hand_landmarks):\n",
    "#                 # Visualizza sul frame\n",
    "#                 x, y = int(hand_landmarks.landmark[0].x * frame.shape[1]), int(hand_landmarks.landmark[0].y * frame.shape[0])\n",
    "#                 cv2.putText(frame, \"POLLICE DX\", (x, y-50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                \n",
    "#             elif  check_thumbs_sx(hand_landmarks):\n",
    "#                 # Visualizza sul frame\n",
    "#                 x, y = int(hand_landmarks.landmark[0].x * frame.shape[1]), int(hand_landmarks.landmark[0].y * frame.shape[0])\n",
    "#                 cv2.putText(frame, \"POLLICE SX\", (x, y-50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                \n",
    "#             # elif  fuuu(hand_landmarks):\n",
    "#             #     # Visualizza sul frame\n",
    "#             #     x, y = int(hand_landmarks.landmark[0].x * frame.shape[1]), int(hand_landmarks.landmark[0].y * frame.shape[0])\n",
    "#             #     cv2.putText(frame, \"FANC**\", (x, y-50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "#             #     # Stampa sul terminale\n",
    "#             #     print(\"FANC**\")\n",
    "\n",
    "#     # Display the output\n",
    "#     cv2.imshow(\"Hand Tracking Check - no functions\", frame)\n",
    "\n",
    "#     # Exit when 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codice per controllare la musica tramite gesture\n",
    "- Esegui i passi iniziali contenuti nel primo markdown\n",
    "- Ricorda che la cam si chiude premendo `q` o, in caso non funzionasse, `restartando` il kernel\n",
    "- Ricorda di commentare la cella precendente o di avviare solo quella sottostante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Comando 'pl_pause' eseguito\n",
      "OPEN_HAND RILEVATO!\n",
      "[✓] Comando 'pl_next' eseguito\n",
      "THUMBS_RX RILEVATO!\n",
      "[✓] Comando 'pl_pause' eseguito\n",
      "OPEN_HAND RILEVATO!\n"
     ]
    }
   ],
   "source": [
    "#Er codice\n",
    "\n",
    "# Variabili globali\n",
    "last_trigger_time = 0\n",
    "cooldown = 1 # Tempo di attesa tra i comandi (in secondi)\n",
    "detection_start_time = 0\n",
    "is_detecting = False\n",
    "current_gesture = None\n",
    "detection_delay = 1.3  # Delay prima di eseguire l'azione dopo il riconoscimento del gesto (in secondi)\n",
    "\n",
    "# Nuove variabili per tener traccia delle ripetizioni consecutive\n",
    "consecutive_thumbs_up_count = 0\n",
    "consecutive_thumbs_down_count = 0\n",
    "last_gesture = None\n",
    "\n",
    "# Percorsi dei file audio per i feedback sonori\n",
    "# Sostituisci questi percorsi con i file audio reali sul tuo sistema\n",
    "\n",
    "path_start_sound = r\"feedbacksounds\\start.mp3\"\n",
    "path_completed_sound = r\"feedbacksounds\\stop.mp3\"\n",
    "# Initialize pygame mixer\n",
    "pygame.mixer.init()\n",
    "# Load the sound file\n",
    "DETECTION_START_SOUND  = pygame.mixer.Sound(path_start_sound)\n",
    "GESTURE_COMPLETED_SOUND = pygame.mixer.Sound(path_completed_sound)\n",
    "# Set volume (0.0 to 1.0)\n",
    "DETECTION_START_SOUND.set_volume(1)\n",
    "GESTURE_COMPLETED_SOUND.set_volume(1)\n",
    "# Play the sound\n",
    "# sound.play()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def handle_gesture(name, action_fn, hand_landmarks, frame):\n",
    "    global last_trigger_time, detection_start_time, is_detecting, current_gesture\n",
    "    global consecutive_thumbs_up_count, consecutive_thumbs_down_count, last_gesture\n",
    "    \n",
    "    # Se non stiamo già rilevando un gesto, inizia il processo di rilevamento\n",
    "    if not is_detecting:\n",
    "        is_detecting = True\n",
    "        detection_start_time = time.time()\n",
    "        current_gesture = name\n",
    "        # Riproduci il suono di inizio rilevamento\n",
    "        DETECTION_START_SOUND.play()\n",
    "        return\n",
    "    \n",
    "    # Se stiamo già rilevando e il gesto è cambiato, resetta il timer\n",
    "    if current_gesture != name:\n",
    "        is_detecting = True\n",
    "        detection_start_time = time.time()\n",
    "        current_gesture = name\n",
    "        # Riproduci il suono di inizio rilevamento per il nuovo gesto\n",
    "        DETECTION_START_SOUND.play()\n",
    "        return\n",
    "    \n",
    "    # Calcola il tempo trascorso dall'inizio del rilevamento\n",
    "    elapsed_time = time.time() - detection_start_time\n",
    "    \n",
    "    # Posizione per visualizzare il nome del gesto e il cerchio\n",
    "    x, y = int(hand_landmarks.landmark[0].x * frame.shape[1]), int(hand_landmarks.landmark[0].y * frame.shape[0])\n",
    "    \n",
    "    # Disegna il nome del gesto\n",
    "    cv2.putText(frame, name.upper(), (x, y-70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Disegna il cerchio di caricamento\n",
    "    radius = 30\n",
    "    center = (x, y-20)\n",
    "    # Disegna il cerchio di sfondo (grigio)\n",
    "    cv2.circle(frame, center, radius, (100, 100, 100), 3)\n",
    "    \n",
    "    # Calcola l'angolo in base al tempo trascorso (da 0 a 360 gradi)\n",
    "    angle = min(elapsed_time / detection_delay * 360, 360)\n",
    "    \n",
    "    # Disegna l'arco di caricamento (verde)\n",
    "    start_angle = -90  # Inizia dall'alto\n",
    "    end_angle = start_angle + angle\n",
    "    \n",
    "    # Disegna l'arco di caricamento punto per punto\n",
    "    for i in range(int(start_angle), int(end_angle)):\n",
    "        rad = math.radians(i)\n",
    "        x1 = int(center[0] + radius * math.cos(rad))\n",
    "        y1 = int(center[1] + radius * math.sin(rad))\n",
    "        cv2.circle(frame, (x1, y1), 1, (0, 255, 0), 3)\n",
    "    \n",
    "    # Se il tempo di attesa è completato, esegui l'azione\n",
    "    if elapsed_time >= detection_delay:\n",
    "        action_fn()\n",
    "        print(f\"{name.upper()} RILEVATO!\")\n",
    "        \n",
    "        GESTURE_COMPLETED_SOUND.play()  # Riproduci il suono di completamento gesto\n",
    "        \n",
    "        \n",
    "        # Aggiorna i contatori per i gesti consecutivi\n",
    "        if name == \"thumbs_up\":\n",
    "            if last_gesture == \"thumbs_up\":\n",
    "                consecutive_thumbs_up_count += 1\n",
    "            else:\n",
    "                consecutive_thumbs_up_count = 1\n",
    "            consecutive_thumbs_down_count = 0\n",
    "        elif name == \"thumbs_down\":\n",
    "            if last_gesture == \"thumbs_down\":\n",
    "                consecutive_thumbs_down_count += 1\n",
    "            else:\n",
    "                consecutive_thumbs_down_count = 1\n",
    "            consecutive_thumbs_up_count = 0\n",
    "        else:\n",
    "            consecutive_thumbs_up_count = 0\n",
    "            consecutive_thumbs_down_count = 0\n",
    "            \n",
    "        last_gesture = name\n",
    "        last_trigger_time = time.time()\n",
    "        is_detecting = False\n",
    "        current_gesture = None\n",
    "\n",
    "# Verifica se i file audio esistono o crea file audio di default\n",
    "def create_default_sounds():\n",
    "    if not os.path.exists(path_start_sound):\n",
    "        print(f\"File audio di inizio rilevamento non trovato: {path_start_sound}\")\n",
    "        print(\"Si consiglia di scaricare o creare file audio per i feedback sonori.\")\n",
    "    \n",
    "    if not os.path.exists(path_completed_sound):\n",
    "        print(f\"File audio di completamento gesto non trovato: {path_completed_sound}\")\n",
    "        print(\"Si consiglia di scaricare o creare file audio per i feedback sonori.\")\n",
    "\n",
    "\n",
    "def estimate_hand_side(landmarks, handedness):\n",
    "    WRIST = 0\n",
    "    INDEX_MCP = 5\n",
    "    PINKY_MCP = 17\n",
    "\n",
    "    wrist = np.array([landmarks[WRIST].x, landmarks[WRIST].y, landmarks[WRIST].z])\n",
    "    index_mcp = np.array([landmarks[INDEX_MCP].x, landmarks[INDEX_MCP].y, landmarks[INDEX_MCP].z])\n",
    "    pinky_mcp = np.array([landmarks[PINKY_MCP].x, landmarks[PINKY_MCP].y, landmarks[PINKY_MCP].z])\n",
    "\n",
    "    vec1 = index_mcp - wrist\n",
    "    vec2 = pinky_mcp - wrist\n",
    "\n",
    "    normal = np.cross(vec1, vec2)\n",
    "\n",
    "    # Se la mano è sinistra, invertiamo la normale\n",
    "    if handedness == 'Left':\n",
    "        normal = -normal\n",
    "\n",
    "    if normal[2] > 0:\n",
    "        return \"PALM\"\n",
    "    else:\n",
    "        return \"BACK\"\n",
    "\n",
    "\n",
    "# Inizializzazione di MediaPipe e della webcam\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=1,\n",
    "    model_complexity=1,\n",
    "    min_detection_confidence=0.7, \n",
    "    min_tracking_confidence=0.7)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Verifica i file audio all'avvio\n",
    "create_default_sounds()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "    \n",
    "    # Resetta il flag di rilevamento se è passato troppo tempo senza rilevare lo stesso gesto\n",
    "    if is_detecting and (time.time() - detection_start_time > detection_delay * 1.5):\n",
    "        is_detecting = False\n",
    "        current_gesture = None\n",
    "    \n",
    "    if results.multi_hand_landmarks and results.multi_handedness:\n",
    "        for hand_landmarks, hand_handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "            # Controlla se possiamo saltare il cooldown per i gesti \"thumbs_up\" e \"thumbs_down\"\n",
    "            skip_cooldown = False\n",
    "            \n",
    "            if last_gesture == \"thumbs_up\" and consecutive_thumbs_up_count >= 2:\n",
    "                if check_thumbs_up(hand_landmarks):\n",
    "                    skip_cooldown = True\n",
    "            \n",
    "            if last_gesture == \"thumbs_down\" and consecutive_thumbs_down_count >= 2:\n",
    "                if check_thumbs_down(hand_landmarks):\n",
    "                    skip_cooldown = True\n",
    "            \n",
    "            # Verifica il cooldown o se possiamo saltarlo\n",
    "            if ((time.time() - last_trigger_time) > cooldown) or skip_cooldown:\n",
    "                if check_open_hand(hand_landmarks) and estimate_hand_side(hand_landmarks.landmark, hand_handedness.classification[0].label) == \"PALM\" and ((estimate_hand_side(hand_landmarks.landmark, hand_handedness.classification[0].label) == \"BACK\")==False):\n",
    "                    handle_gesture(\"open_hand\", play_pause, hand_landmarks, frame)\n",
    "                elif check_thumbs_up(hand_landmarks):\n",
    "                    handle_gesture(\"thumbs_up\", vol_up, hand_landmarks, frame)\n",
    "                elif check_thumbs_rx(hand_landmarks) :\n",
    "                    handle_gesture(\"thumbs_rx\", next, hand_landmarks, frame)\n",
    "                elif check_thumbs_sx(hand_landmarks) :\n",
    "                    handle_gesture(\"thumbs_sx\", prev, hand_landmarks, frame)\n",
    "                elif check_thumbs_down(hand_landmarks):\n",
    "                    handle_gesture(\"thumbs_down\", vol_dw, hand_landmarks, frame)\n",
    "    \n",
    "    # Visualizza il contatore di utilizzi consecutivi (opzionale)\n",
    "    if consecutive_thumbs_up_count >= 2:\n",
    "        cv2.putText(frame, f\"Thumbs UP mode: {consecutive_thumbs_up_count}\", (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    if consecutive_thumbs_down_count >= 2:\n",
    "        cv2.putText(frame, f\"Thumbs DOWN mode: {consecutive_thumbs_down_count}\", (10, 60), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imshow(\"Handle music with gestures + palm \", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Er codice senza back palm detection\n",
    "\n",
    "\n",
    "# # Variabili globali\n",
    "# last_trigger_time = 0\n",
    "# cooldown = 1\n",
    "# detection_start_time = 0\n",
    "# is_detecting = False\n",
    "# current_gesture = None\n",
    "# detection_delay = 1.2  # Delay di 1 secondo\n",
    "\n",
    "# # Nuove variabili per tener traccia delle ripetizioni consecutive\n",
    "# consecutive_thumbs_up_count = 0\n",
    "# consecutive_thumbs_down_count = 0\n",
    "# last_gesture = None\n",
    "\n",
    "# # Percorsi dei file audio per i feedback sonori\n",
    "# # Sostituisci questi percorsi con i file audio reali sul tuo sistema\n",
    "\n",
    "# path_start_sound = r\"feedbacksounds\\start.mp3\"\n",
    "# path_completed_sound = r\"feedbacksounds\\stop.mp3\"\n",
    "\n",
    "# # Initialize pygame mixer\n",
    "# pygame.mixer.init()\n",
    "# # Load the sound file\n",
    "# DETECTION_START_SOUND  = pygame.mixer.Sound(path_start_sound)\n",
    "# GESTURE_COMPLETED_SOUND = pygame.mixer.Sound(path_completed_sound)\n",
    "# # Set volume (0.0 to 1.0)\n",
    "# DETECTION_START_SOUND.set_volume(1)\n",
    "# GESTURE_COMPLETED_SOUND.set_volume(1)\n",
    "# # Play the sound\n",
    "# # sound.play()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def handle_gesture(name, action_fn, hand_landmarks, frame):\n",
    "#     global last_trigger_time, detection_start_time, is_detecting, current_gesture\n",
    "#     global consecutive_thumbs_up_count, consecutive_thumbs_down_count, last_gesture\n",
    "    \n",
    "#     # Se non stiamo già rilevando un gesto, inizia il processo di rilevamento\n",
    "#     if not is_detecting:\n",
    "#         is_detecting = True\n",
    "#         detection_start_time = time.time()\n",
    "#         current_gesture = name\n",
    "#         # Riproduci il suono di inizio rilevamento\n",
    "#         DETECTION_START_SOUND.play()\n",
    "#         return\n",
    "    \n",
    "#     # Se stiamo già rilevando e il gesto è cambiato, resetta il timer\n",
    "#     if current_gesture != name:\n",
    "#         is_detecting = True\n",
    "#         detection_start_time = time.time()\n",
    "#         current_gesture = name\n",
    "#         # Riproduci il suono di inizio rilevamento per il nuovo gesto\n",
    "#         DETECTION_START_SOUND.play()\n",
    "#         return\n",
    "    \n",
    "#     # Calcola il tempo trascorso dall'inizio del rilevamento\n",
    "#     elapsed_time = time.time() - detection_start_time\n",
    "    \n",
    "#     # Posizione per visualizzare il nome del gesto e il cerchio\n",
    "#     x, y = int(hand_landmarks.landmark[0].x * frame.shape[1]), int(hand_landmarks.landmark[0].y * frame.shape[0])\n",
    "    \n",
    "#     # Disegna il nome del gesto\n",
    "#     cv2.putText(frame, name.upper(), (x, y-70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "#     # Disegna il cerchio di caricamento\n",
    "#     radius = 30\n",
    "#     center = (x, y-20)\n",
    "#     # Disegna il cerchio di sfondo (grigio)\n",
    "#     cv2.circle(frame, center, radius, (100, 100, 100), 3)\n",
    "    \n",
    "#     # Calcola l'angolo in base al tempo trascorso (da 0 a 360 gradi)\n",
    "#     angle = min(elapsed_time / detection_delay * 360, 360)\n",
    "    \n",
    "#     # Disegna l'arco di caricamento (verde)\n",
    "#     start_angle = -90  # Inizia dall'alto\n",
    "#     end_angle = start_angle + angle\n",
    "    \n",
    "#     # Disegna l'arco di caricamento punto per punto\n",
    "#     for i in range(int(start_angle), int(end_angle)):\n",
    "#         rad = math.radians(i)\n",
    "#         x1 = int(center[0] + radius * math.cos(rad))\n",
    "#         y1 = int(center[1] + radius * math.sin(rad))\n",
    "#         cv2.circle(frame, (x1, y1), 1, (0, 255, 0), 3)\n",
    "    \n",
    "#     # Se il tempo di attesa è completato, esegui l'azione\n",
    "#     if elapsed_time >= detection_delay:\n",
    "#         action_fn()\n",
    "#         print(f\"{name.upper()} RILEVATO!\")\n",
    "        \n",
    "#         GESTURE_COMPLETED_SOUND.play()  # Riproduci il suono di completamento gesto\n",
    "        \n",
    "        \n",
    "#         # Aggiorna i contatori per i gesti consecutivi\n",
    "#         if name == \"thumbs_up\":\n",
    "#             if last_gesture == \"thumbs_up\":\n",
    "#                 consecutive_thumbs_up_count += 1\n",
    "#             else:\n",
    "#                 consecutive_thumbs_up_count = 1\n",
    "#             consecutive_thumbs_down_count = 0\n",
    "#         elif name == \"thumbs_down\":\n",
    "#             if last_gesture == \"thumbs_down\":\n",
    "#                 consecutive_thumbs_down_count += 1\n",
    "#             else:\n",
    "#                 consecutive_thumbs_down_count = 1\n",
    "#             consecutive_thumbs_up_count = 0\n",
    "#         else:\n",
    "#             consecutive_thumbs_up_count = 0\n",
    "#             consecutive_thumbs_down_count = 0\n",
    "            \n",
    "#         last_gesture = name\n",
    "#         last_trigger_time = time.time()\n",
    "#         is_detecting = False\n",
    "#         current_gesture = None\n",
    "\n",
    "# # Verifica se i file audio esistono o crea file audio di default\n",
    "# def create_default_sounds():\n",
    "#     if not os.path.exists(path_start_sound):\n",
    "#         print(f\"File audio di inizio rilevamento non trovato: {path_start_sound}\")\n",
    "#         print(\"Si consiglia di scaricare o creare file audio per i feedback sonori.\")\n",
    "    \n",
    "#     if not os.path.exists(path_completed_sound):\n",
    "#         print(f\"File audio di completamento gesto non trovato: {path_completed_sound}\")\n",
    "#         print(\"Si consiglia di scaricare o creare file audio per i feedback sonori.\")\n",
    "\n",
    "# # Inizializzazione di MediaPipe e della webcam\n",
    "# mp_hands = mp.solutions.hands\n",
    "# mp_draw = mp.solutions.drawing_utils\n",
    "# hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Verifica i file audio all'avvio\n",
    "# create_default_sounds()\n",
    "\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "    \n",
    "#     frame = cv2.flip(frame, 1)\n",
    "#     rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     results = hands.process(rgb_frame)\n",
    "    \n",
    "#     # Resetta il flag di rilevamento se è passato troppo tempo senza rilevare lo stesso gesto\n",
    "#     if is_detecting and (time.time() - detection_start_time > detection_delay * 1.5):\n",
    "#         is_detecting = False\n",
    "#         current_gesture = None\n",
    "    \n",
    "#     if results.multi_hand_landmarks:\n",
    "#         for hand_landmarks in results.multi_hand_landmarks:\n",
    "#             mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "#             # Controlla se possiamo saltare il cooldown per i gesti \"thumbs_up\" e \"thumbs_down\"\n",
    "#             skip_cooldown = False\n",
    "            \n",
    "#             if last_gesture == \"thumbs_up\" and consecutive_thumbs_up_count >= 2:\n",
    "#                 if check_thumbs_up(hand_landmarks):\n",
    "#                     skip_cooldown = True\n",
    "            \n",
    "#             if last_gesture == \"thumbs_down\" and consecutive_thumbs_down_count >= 2:\n",
    "#                 if check_thumbs_down(hand_landmarks):\n",
    "#                     skip_cooldown = True\n",
    "            \n",
    "#             # Verifica il cooldown o se possiamo saltarlo\n",
    "#             if ((time.time() - last_trigger_time) > cooldown) or skip_cooldown:\n",
    "#                 if check_open_hand(hand_landmarks):\n",
    "#                     handle_gesture(\"open_hand\", play_pause, hand_landmarks, frame)\n",
    "#                 elif check_thumbs_up(hand_landmarks):\n",
    "#                     handle_gesture(\"thumbs_up\", vol_up, hand_landmarks, frame)\n",
    "#                 elif check_thumbs_rx(hand_landmarks):\n",
    "#                     handle_gesture(\"thumbs_rx\", next, hand_landmarks, frame)\n",
    "#                 elif check_thumbs_sx(hand_landmarks):\n",
    "#                     handle_gesture(\"thumbs_sx\", prev, hand_landmarks, frame)\n",
    "#                 elif check_thumbs_down(hand_landmarks):\n",
    "#                     handle_gesture(\"thumbs_down\", vol_dw, hand_landmarks, frame)\n",
    "    \n",
    "#     # Visualizza il contatore di utilizzi consecutivi (opzionale)\n",
    "#     if consecutive_thumbs_up_count >= 2:\n",
    "#         cv2.putText(frame, f\"Thumbs UP mode: {consecutive_thumbs_up_count}\", (10, 30), \n",
    "#                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "#     if consecutive_thumbs_down_count >= 2:\n",
    "#         cv2.putText(frame, f\"Thumbs DOWN mode: {consecutive_thumbs_down_count}\", (10, 60), \n",
    "#                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "#     cv2.imshow(\"Handle music with gestures\", frame)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # implementazione di un algoritmo per determinare se la mano è palmo o dorso\n",
    "\n",
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "# import numpy as np\n",
    "\n",
    "# # Inizializzazione MediaPipe Hands\n",
    "# mp_hands = mp.solutions.hands\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# hands = mp_hands.Hands(\n",
    "#     max_num_hands=1,\n",
    "#     model_complexity=1,\n",
    "#     min_detection_confidence=0.7,\n",
    "#     min_tracking_confidence=0.7\n",
    "# )\n",
    "\n",
    "# def estimate_hand_side(landmarks, handedness):\n",
    "#     WRIST = 0\n",
    "#     INDEX_MCP = 5\n",
    "#     PINKY_MCP = 17\n",
    "\n",
    "#     wrist = np.array([landmarks[WRIST].x, landmarks[WRIST].y, landmarks[WRIST].z])\n",
    "#     index_mcp = np.array([landmarks[INDEX_MCP].x, landmarks[INDEX_MCP].y, landmarks[INDEX_MCP].z])\n",
    "#     pinky_mcp = np.array([landmarks[PINKY_MCP].x, landmarks[PINKY_MCP].y, landmarks[PINKY_MCP].z])\n",
    "\n",
    "#     vec1 = index_mcp - wrist\n",
    "#     vec2 = pinky_mcp - wrist\n",
    "\n",
    "#     normal = np.cross(vec1, vec2)\n",
    "\n",
    "#     # Se la mano è sinistra, invertiamo la normale\n",
    "#     if handedness == 'Left':\n",
    "#         normal = -normal\n",
    "\n",
    "#     if normal[2] > 0:\n",
    "#         return \"PALM\"\n",
    "#     else:\n",
    "#         return \"BACK\"\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# while cap.isOpened():\n",
    "#     success, frame = cap.read()\n",
    "#     if not success:\n",
    "#         print(\"Ignoring empty frame.\")\n",
    "#         continue\n",
    "\n",
    "#     frame = cv2.flip(frame, 1)\n",
    "#     frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     results = hands.process(frame_rgb)\n",
    "\n",
    "#     if results.multi_hand_landmarks and results.multi_handedness:\n",
    "#         for hand_landmarks, hand_handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "#             # Ottieni se la mano è destra o sinistra\n",
    "#             handedness_label = hand_handedness.classification[0].label\n",
    "\n",
    "#             # Stima palmo o dorso correttamente\n",
    "#             hand_side = estimate_hand_side(hand_landmarks.landmark, handedness_label)\n",
    "\n",
    "#             # Disegna la mano\n",
    "#             mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "#             # Scrivi l'informazione\n",
    "#             cv2.putText(frame, f\"{handedness_label} Hand - {hand_side}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                         1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "#     cv2.imshow('Palm vs Back Detection', frame)\n",
    "\n",
    "#     if cv2.waitKey(5) & 0xFF == 27:\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n",
    "# hands.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hciw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
